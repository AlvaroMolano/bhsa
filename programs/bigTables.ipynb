{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BHSA as a Big Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook exports the [BHSA](etcbc.png) database to an R data frame.\n",
    "The nodes are exported as rows, they correspond to the text objects such as word, phrase, clause, sentence, verse, chapter, book and a few others.\n",
    "\n",
    "The BHSA features become the columns, so each row tells what values the features have for the corresponding object.\n",
    "\n",
    "The edges corresponding to the etcbc features *mother*, *functional_parent*, *distributional_parent* are\n",
    "exported as extra columns. For each row, such a column indicates the target of a corresponding outgoing edge.\n",
    "\n",
    "We also write the data that says which objects are contained in which.\n",
    "To each row we add the following columns:\n",
    "\n",
    "* for each object type, except `word` there is a column with name that object type and containing\n",
    "  the identifier of the containing object of that type of the row object (if any).\n",
    "\n",
    "Extra data such as lexicon (including frequency and rank features), phonetic transcription, and ketiv-qere are also included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compose the bg table and save it as a tab delimited files.\n",
    "The result can be processed by R and Pandas,\n",
    "who may converted the table to internal formats\n",
    "for quicker loading.\n",
    "It turns out that for this size of the data Pandas is a bit quicker than R.\n",
    "\n",
    "Also, because we remain in a Python environment, working with Pandas \n",
    "is easier when you want to use configurations ad libraries from the text-fabric sphere.\n",
    "\n",
    "See \n",
    "[bigTablesR](bigTablesR.ipynb)\n",
    "and\n",
    "[bigTablesP](bigTablesP.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations = '~/github/etcbc'\n",
    "coreModule = 'bhsa'\n",
    "sources = [coreModule, 'phono']\n",
    "version = '2017'\n",
    "tempDir = os.path.expanduser('{}/{}/_temp/{}/r'.format(locations, coreModule, version))\n",
    "tableFile = '{}/{}{}.txt'.format(tempDir, coreModule, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 3.0.9\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "117 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "modules = ['{}/tf/{}'.format(s, version) for s in sources]\n",
    "TF = Fabric(locations=locations, modules=modules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ALL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.00s Feature overview: 110 for nodes; 5 for edges; 2 configs; 7 computed\n",
      "  5.91s All features loaded/computed - for details use loadLog()\n",
      "   |     0.00s Feature overview: 110 for nodes; 5 for edges; 2 configs; 7 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.03s B code                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.19s B det                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.19s B dist                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.23s B dist_unit            from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     1.61s B distributional_parent from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.02s B domain               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B freq_lex             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.10s B freq_occ             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B function             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     3.08s B functional_parent    from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.10s B g_nme                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B g_nme_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_pfm                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.10s B g_pfm_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_prs                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_prs_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.08s B g_uvf                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.07s B g_uvf_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.08s B g_vbe                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_vbe_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_vbs                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B g_vbs_utf8           from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B gloss                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B gn                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B instruction          from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B is_root              from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.04s B kind                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B kq_hybrid            from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B kq_hybrid_utf8       from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.02s B label                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B language             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.24s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B lexeme_count         from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.22s B ls                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     1.48s B mother               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.06s B mother_object_type   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s B nametype             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B nme                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B nu                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.26s B number               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.90s B omap@2016-2017       from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B pargr                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B pdp                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B pfm                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B prs                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B prs_gn               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B prs_nu               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.16s B prs_ps               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.23s B ps                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.18s B rank_lex             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B rank_occ             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.37s B rela                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B root                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B sp                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B st                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B suffix_gender        from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B suffix_number        from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B suffix_person        from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.02s B tab                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B txt                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.26s B typ                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B uvf                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B vbe                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B vbs                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B voc_lex              from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B voc_lex_utf8         from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.17s B vs                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B vt                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s Feature overview: 110 for nodes; 5 for edges; 2 configs; 7 computed\n",
      "    18s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('')\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing R data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2h 34m 57s  100000 nodes written\n",
      " 2h 35m 21s  200000 nodes written\n",
      " 2h 35m 44s  300000 nodes written\n",
      " 2h 36m 10s  400000 nodes written\n",
      " 2h 36m 32s  500000 nodes written\n",
      " 2h 36m 54s  600000 nodes written\n",
      " 2h 37m 18s  700000 nodes written\n",
      " 2h 37m 41s  800000 nodes written\n",
      " 2h 38m 04s  900000 nodes written\n",
      " 2h 38m 27s 1000000 nodes written\n",
      " 2h 38m 49s 1100000 nodes written\n",
      " 2h 39m 14s 1200000 nodes written\n",
      " 2h 39m 36s 1300000 nodes written\n",
      " 2h 39m 58s 1400000 nodes written\n",
      " 2h 40m 09s 1446635 nodes written and done\n"
     ]
    }
   ],
   "source": [
    "## info(\"Writing R feature data\")\n",
    "\n",
    "if not os.path.exists(tempDir):\n",
    "    os.makedirs(tempDir)\n",
    "\n",
    "hr = open(tableFile, 'w')\n",
    "\n",
    "skipFeatures = '''\n",
    "    otype\n",
    "    oslots\n",
    "'''.strip().split()\n",
    "for f in (Fall() + Eall()):\n",
    "    if '@' in f: skipFeatures.append(f)\n",
    "\n",
    "levelFeatures = '''\n",
    "    subphrase phrase_atom phrase clause_atom clause sentence_atom sentence\n",
    "    half_verse verse chapter book\n",
    "'''.strip().split()\n",
    "inLevelFeatures = ['in.'+x for x in levelFeatures]\n",
    "\n",
    "allNodeFeatures = sorted(set(Fall()) - set(skipFeatures))\n",
    "allEdgeFeatures = sorted(set(Eall()) - set(skipFeatures))\n",
    "\n",
    "hr.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
    "    'n',\n",
    "    'otype',\n",
    "    '\\t'.join(inLevelFeatures),\n",
    "    '\\t'.join(allEdgeFeatures),\n",
    "    '\\t'.join(allNodeFeatures),\n",
    "))\n",
    "chunkSize = 100000\n",
    "i = 0\n",
    "s = 0\n",
    "NA = ['']\n",
    "NAe = [['']]\n",
    "for n in N():\n",
    "    levelValues = [(L.u(n, otype=level) or NA)[0] for level in levelFeatures]\n",
    "    edgeValues = [str((Es(f).f(n) or NA)[0]) for f in allEdgeFeatures]\n",
    "    nodeValues = [(str(Fs(f).v(n) or '')) for f in allNodeFeatures]\n",
    "    hr.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(\n",
    "        n,\n",
    "        F.otype.v(n),\n",
    "        ('\\t'.join(str(x) for x in levelValues)),\n",
    "        ('\\t'.join(edgeValues)),\n",
    "        ('\\t'.join(nodeValues)).replace('\\n',''),\n",
    "    ))\n",
    "    i += 1\n",
    "    s += 1\n",
    "    if s == chunkSize:\n",
    "        s = 0\n",
    "        info('{:>7} nodes written'.format(i))\n",
    "hr.close()\n",
    "info('{:>7} nodes written and done'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 758624\r\n",
      "-rw-r--r--  1 dirk  staff    41M Oct 13 12:20 bhsa2017.rds\r\n",
      "-rw-r--r--@ 1 dirk  staff   324M Oct 13 14:11 bhsa2017.txt\r\n",
      "-rw-r--r--  1 dirk  staff   5.1M Oct 13 12:24 plainTextFromR.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {tempDir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R export is ready now, but it is a bit large.\n",
    "We can get a much leaner file by using R to load this file and save it in .rds format.\n",
    "\n",
    "We do that in a separate notebook, not running Python, but R: bigTablesR in this same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
