{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal pairs\n",
    "\n",
    "## Task\n",
    "\n",
    "We produce all pairs of Hebrew vocalized lexemes that satisfy these conditions:\n",
    "\n",
    "1. both members of the pair are equally long\n",
    "2. the edit distance between the members of the pair is exactly 1\n",
    "3. either `(p1, p2)` or `(p2, p1)` is in the pair but not both\n",
    "\n",
    "These are the so-called minimal pairs.\n",
    "They can be used to find phonological rules and to train language learners.\n",
    "\n",
    "See http://www.ibiblio.org/bgreek/forum/viewtopic.php?f=17&t=4308&p=29117#p29117.\n",
    "\n",
    "Thanks to Jonathan Robie for pointing me to this question.\n",
    "\n",
    "## Method\n",
    "\n",
    "We use the Levenshtein edit distance to check condition 2.\n",
    "\n",
    "Install Levenshtein module:\n",
    "\n",
    "```\n",
    "sudo -H pip3 install python-Levenshtein\n",
    "```\n",
    "\n",
    "Documentation of [Levenshtein module](http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html)\n",
    "\n",
    "## Data\n",
    "\n",
    "We grab raw text-fabric data from this repo, in particular the data that corresponds to the \n",
    "[voc_lex_utf8](https://etcbc.github.io/bhsa/features/hebrew/2017/voc_lex_utf8) feature.\n",
    "\n",
    "This file contains all 9000+ lexemes of the Hebrew Bible.\n",
    "The file starts with a few metadata lines, preceded by a `@`, then has an empty line, and the\n",
    "subsequent lines contain each a lexeme, possibly preceded by a number that we ignore:\n",
    "\n",
    "```\n",
    "@node\n",
    "@author=Eep Talstra Centre for Bible and Computer\n",
    "@dataset=BHSA\n",
    "@datasetName=Biblia Hebraica Stuttgartensia Amstelodamensis\n",
    "@email=shebanq@ancient-data.org\n",
    "@encoders=Constantijn Sikkel (QDF), and Dirk Roorda (TF)\n",
    "@valueType=str\n",
    "@version=2017\n",
    "@website=https://shebanq.ancient-data.org\n",
    "@writtenBy=Text-Fabric\n",
    "@dateWritten=2017-10-10T10:55:32Z\n",
    "\n",
    "1437403\tבְּ\n",
    "רֵאשִׁית\n",
    "ברא\n",
    "אֱלֹהִים\n",
    "אֵת\n",
    "הַ\n",
    "```\n",
    "...\n",
    "\n",
    "Note that we do not need the package Text-Fabric to handle this data.\n",
    "However, by using TF it would have been easy to pick up the *node* numbers of the lexemes, and from there\n",
    "to find all occurrences of the lexemes. That way, we could enrich each minimal pair with a set of concrete examples.\n",
    "\n",
    "## Result\n",
    "The result is a tab-delimited file of 22000+ minimal pairs:\n",
    "\n",
    "```\n",
    "בְּ\tכְּ\n",
    "בְּ\tכְּ\n",
    "ברא\tקרא\n",
    "ברא\tברך\n",
    "ברא\tבוא\n",
    "ברא\tירא\n",
    "ברא\tקרא\n",
    "ברא\tברח\n",
    "ברא\tברך\n",
    "ברא\tבטא\n",
    "ברא\tברה\n",
    "ברא\tברה\n",
    "ברא\tברר\n",
    "ברא\tבדא\n",
    "ברא\tבזא\n",
    "ברא\tברד\n",
    "ברא\tפרא\n",
    "ברא\tמרא\n",
    "ברא\tברק\n",
    "ברא\tמרא\n",
    "ברא\tברך\n",
    "ברא\tקרא\n",
    "ברא\tברך\n",
    "אֵת\tאֵד\n",
    "אֵת\tאֵם\n",
    "אֵת\tאֵי\n",
    "אֵת\tעֵת\n",
    "אֵת\tחֵת\n",
    "```\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unicodedata import normalize\n",
    "from Levenshtein import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFD = 'NFD'\n",
    "REPO = os.path.expanduser('~/github/etcbc/bhsa')\n",
    "TEMP = '{}/_temp'.format(REPO)\n",
    "VERSION = '2017'\n",
    "TFDIR = '{}/tf/{}'.format(REPO, VERSION)\n",
    "lexemeData = '{}/voc_lex_utf8.tf'.format(TFDIR)\n",
    "pairFile = '{}/minimalPairs.tsv'.format(TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTfData(dataFile):\n",
    "    items = []\n",
    "    with open(dataFile) as d:\n",
    "        inMeta = True\n",
    "        for line in d:\n",
    "            if inMeta:\n",
    "                if not line.startswith('@'):\n",
    "                    inMeta = False\n",
    "                continue\n",
    "            comps = line.rstrip('\\n').split('\\t', 1)\n",
    "            item = comps[1] if len(comps) == 2 else comps[0]\n",
    "            nitem = normalize(NFD, item)\n",
    "            items.append(item)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlexs = readTfData(lexemeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9233"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vlexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinimalPairs(items):\n",
    "    pairs = []\n",
    "    nItems = len(items)\n",
    "    for i in range(nItems):\n",
    "        for j in range(i, nItems):\n",
    "            itemI = items[i]\n",
    "            itemJ = items[j]\n",
    "            if len(itemI) != len(itemJ): continue\n",
    "            d = distance(itemI, itemJ)\n",
    "            if d == 1:\n",
    "                pairs.append((itemI, itemJ))\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes 10 seconds or so\n",
    "minimalPairs = getMinimalPairs(vlexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22197"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minimalPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writePairs(pairs, pFile):\n",
    "    with open(pFile, 'w') as f:\n",
    "        for (item1, item2) in pairs:\n",
    "            f.write('{}\\t{}\\n'.format(item1, item2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "writePairs(minimalPairs, pairFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
