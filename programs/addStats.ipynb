{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Add Statistics\n",
    "\n",
    "This notebook can add statistical features to a \n",
    "[BHSA](https://github.com/ETCBC/bhsa) dataset in\n",
    "[text-Fabric](https://github.com/ETCBC/text-fabric)\n",
    "format.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "We add the features\n",
    "`freq_occ freq_lex rank_occ rank_lex`.\n",
    "\n",
    "We assume that the dataset has these features present:\n",
    "\n",
    "* `language` for determining if the word is Hebrew or Aramaic \n",
    "* `g_cons` to get the word string in consonantal transcription\n",
    "* `lex` to get the lexical identifier in consonantal transcription\n",
    "\n",
    "This program works for all datasets and versions that have these features with the\n",
    "intended meanings.\n",
    "\n",
    "#### Languages\n",
    "We will not identify lexemes and word occurrences across language.\n",
    "So if two occurrences or lexemes exhibit the same string, but htey are categorized as belonging\n",
    "to different languages, they will not be identified.\n",
    "\n",
    "#### Occurrences\n",
    "We group occurrences by their consonantal transcriptions. \n",
    "So if two occurrences differ only in pointing, we count them as two occurrences of the same value.\n",
    "\n",
    "#### Lexemes\n",
    "Lexemes are identified by the `lex` feature within a biblical language.\n",
    "We will not identify lexemes across language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "import utils\n",
    "from tf.fabric import Fabric\n",
    "from blang import bookLangs, bookNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION= 'c'\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newFeaturesStr = '''\n",
    "    freq_occ\n",
    "    freq_lex\n",
    "    rank_occ\n",
    "    rank_lex\n",
    "'''\n",
    "newFeatures = newFeaturesStr.strip().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(None, '{}/.tf/{}.tfx'.format(thisTf, newFeatures[0]), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the TF slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Collect\n",
    "\n",
    "We collect the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Loading felevant features                                                      .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.15\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "\n",
      "101 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.14s B g_cons               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.15s B language             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.16s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 96 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  5.63s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Loading felevant features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('language lex g_cons')\n",
    "api.makeAvailableIn(globals())\n",
    "\n",
    "hasLex = 'lex' in set(F.otype.all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         14s Counting occurrences\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Counting occurrences')\n",
    "wstats = {\n",
    "    'freqs': {\n",
    "        'lex': collections.defaultdict(lambda: collections.Counter()),\n",
    "        'occ': collections.defaultdict(lambda: collections.Counter()),\n",
    "    },\n",
    "    'ranks': {\n",
    "        'lex': collections.defaultdict(lambda: {}),\n",
    "        'occ': collections.defaultdict(lambda: {}),\n",
    "    },\n",
    "}\n",
    "langs = set()\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    occ = F.g_cons.v(w)\n",
    "    lex = F.lex.v(w)\n",
    "    lan = F.language.v(w)\n",
    "    wstats['freqs']['lex'][lan][lex] += 1\n",
    "    wstats['freqs']['occ'][lan][occ] += 1\n",
    "    langs.add(lan)\n",
    "for lan in langs:\n",
    "    for tp in ['lex', 'occ']:\n",
    "        rank = -1\n",
    "        prev_n = -1\n",
    "        amount = 1\n",
    "        for (x, n) in sorted(wstats['freqs'][tp][lan].items(), key=lambda y: (-y[1], y[0])):\n",
    "            if n == prev_n:\n",
    "                amount += 1\n",
    "            else:\n",
    "                rank += amount\n",
    "                amount = 1\n",
    "            prev_n = n\n",
    "            wstats['ranks'][tp][lan][x] = rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         17s Making statistical features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Making statistical features')\n",
    "metaData={}\n",
    "nodeFeatures = {}\n",
    "edgeFeatures = {}\n",
    "\n",
    "for ft in (newFeatures):\n",
    "    nodeFeatures[ft] = {}\n",
    "    metaData.setdefault(ft, {})['valueType'] = 'int'\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    lan = F.language.v(w)\n",
    "    occ = F.g_cons.v(w)\n",
    "    lex = F.lex.v(w)\n",
    "    nodeFeatures['freq_occ'][w] = str(wstats['freqs']['occ'][lan][occ])\n",
    "    nodeFeatures['rank_occ'][w] = str(wstats['ranks']['occ'][lan][occ])\n",
    "    nodeFeatures['freq_lex'][w] = str(wstats['freqs']['lex'][lan][lex])\n",
    "    nodeFeatures['rank_lex'][w] = str(wstats['ranks']['lex'][lan][lex])\n",
    "\n",
    "if hasLex:\n",
    "    for lx in F.otype.s('lex'):\n",
    "        firstOcc = L.d(lx, otype='word')[0]\n",
    "        nodeFeatures['freq_lex'][lx] = nodeFeatures['freq_lex'][firstOcc]\n",
    "        nodeFeatures['rank_lex'][lx] = nodeFeatures['rank_lex'][firstOcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         30s Write statistical features as TF                                               .\n",
      "..............................................................................................\n",
      "   |     0.86s T freq_lex             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.72s T freq_occ             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.74s T rank_lex             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.94s T rank_occ             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Write statistical features as TF')\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Diffs\n",
    "\n",
    "Check differences with previous versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         43s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|         43s \t4 features to add\n",
      "|         43s \t\tfreq_lex\n",
      "|         43s \t\tfreq_occ\n",
      "|         43s \t\trank_lex\n",
      "|         43s \t\trank_occ\n",
      "|         43s \tno features to delete\n",
      "|         43s \t0 features in common\n",
      "|         43s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=set(newFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Deliver \n",
    "\n",
    "Copy the new TF features from the temporary location where they have been created to their final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         58s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/c                         .\n",
      "..............................................................................................\n",
      "|         58s \tfreq_occ\n",
      "|         58s \tfreq_lex\n",
      "|         58s \trank_occ\n",
      "|         58s \trank_lex\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, newFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Compile TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      1m 05s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.15\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "\n",
      "105 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.18s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.87s T freq_occ             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.93s T freq_lex             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.96s T rank_occ             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.94s T rank_lex             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 100 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  9.30s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile the new TF features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('lex '+newFeaturesStr)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      1m 19s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "|      1m 19s Top 10 freqent lexemes (computed on otype=word)\n",
      "|      1m 19s W           50272x\n",
      "|      1m 19s H           30384x\n",
      "|      1m 19s L           20069x\n",
      "|      1m 19s B           15542x\n",
      "|      1m 19s >T          11002x\n",
      "|      1m 19s MN           7562x\n",
      "|      1m 19s JHWH/        6828x\n",
      "|      1m 19s <L           5766x\n",
      "|      1m 19s >L           5517x\n",
      "|      1m 19s >CR          5500x\n",
      "..............................................................................................\n",
      ".      1m 19s Top 10 freqent lexemes (computed on otype=lex)                                 .\n",
      "..............................................................................................\n",
      "|      1m 19s W           50272x\n",
      "|      1m 19s H           30384x\n",
      "|      1m 19s L           20069x\n",
      "|      1m 19s B           15542x\n",
      "|      1m 19s >T          11002x\n",
      "|      1m 19s MN           7562x\n",
      "|      1m 19s JHWH/        6828x\n",
      "|      1m 19s <L           5766x\n",
      "|      1m 19s >L           5517x\n",
      "|      1m 19s >CR          5500x\n",
      "|      1m 19s \tINFO: Same lexeme frequencies computed by lex vs by word\n",
      "|      1m 19s Done\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Basic test')\n",
    "\n",
    "mostFrequent = set()\n",
    "\n",
    "topX = 10\n",
    "\n",
    "lexIndex = {}\n",
    "\n",
    "utils.caption(0, 'Top {} freqent lexemes (computed on otype=word)'.format(topX))\n",
    "for w in sorted(F.otype.s('word'), key=lambda w: -F.freq_lex.v(w)):\n",
    "    lex = F.lex.v(w)\n",
    "    mostFrequent.add(lex)\n",
    "    lexIndex[lex] = w\n",
    "    if len(mostFrequent) == topX: break\n",
    "\n",
    "mostFrequentWord = sorted((-F.freq_lex.v(lexIndex[lex]), lex) for lex in mostFrequent)\n",
    "for (freq, lex) in mostFrequentWord:\n",
    "    utils.caption(0, '{:<10} {:>6}x'.format(lex, -freq))\n",
    "\n",
    "if hasLex:\n",
    "    utils.caption(4, 'Top {} freqent lexemes (computed on otype=lex)'.format(topX))\n",
    "    mostFrequentLex = sorted((-F.freq_lex.v(lx), F.lex.v(lx)) for lx in F.otype.s('lex'))[0:10]\n",
    "    for (freq, lex) in mostFrequentLex:\n",
    "        utils.caption(0, '{:<10} {:>6}x'.format(lex, -freq))\n",
    "    \n",
    "    if mostFrequentWord != mostFrequentLex:\n",
    "        utils.caption(0, '\\tWARNING: Mismatch in lexeme frequencies computed by lex vs by word')\n",
    "    else:\n",
    "        utils.caption(0, '\\tINFO: Same lexeme frequencies computed by lex vs by word')\n",
    "utils.caption(0, 'Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
