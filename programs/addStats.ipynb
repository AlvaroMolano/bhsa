{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Add Statistics\n",
    "\n",
    "This notebook can add statistical features to a \n",
    "[BHSA](https://github.com/ETCBC/bhsa) dataset in\n",
    "[text-Fabric](https://github.com/ETCBC/text-fabric)\n",
    "format.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "We add the features\n",
    "`freq_occ freq_lex rank_occ rank_lex`.\n",
    "\n",
    "We assume that the dataset has these features present:\n",
    "\n",
    "* `language` for determining if the word is Hebrew or Aramaic \n",
    "* `g_cons` to get the word string in consonantal transcription\n",
    "* `lex` to get the lexical identifier in consonantal transcription\n",
    "\n",
    "This program works for all datasets and versions that have these features with the\n",
    "intended meanings.\n",
    "\n",
    "#### Languages\n",
    "We will not identify lexemes and word occurrences across language.\n",
    "So if two occurrences or lexemes exhibit the same string, but htey are categorized as belonging\n",
    "to different languages, they will not be identified.\n",
    "\n",
    "#### Occurrences\n",
    "We group occurrences by their consonantal transcriptions. \n",
    "So if two occurrences differ only in pointing, we count them as two occurrences of the same value.\n",
    "\n",
    "#### Lexemes\n",
    "Lexemes are identified by the `lex` feature within a biblical language.\n",
    "We will not identify lexemes across language.\n",
    "\n",
    "# Execution mode\n",
    "See the notebook tfFromMQL in this directory for an explantion of the `SCRIPT` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from glob import glob\n",
    "from shutil import rmtree, copytree\n",
    "from tf.fabric import Fabric\n",
    "from utils import bunzip, startNow, tprint\n",
    "from blang import bookLangs, bookNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    SOURCE_NAME = 'bhsa'\n",
    "    VERSION= 'd'\n",
    "    TF_MODULE ='core' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/bhsa')\n",
    "\n",
    "sourceBase = '{}/source'.format(repoBase)\n",
    "targetBase = '{}/tf'.format(repoBase)\n",
    "\n",
    "tfLocation = '{}/{}'.format(targetBase, VERSION)\n",
    "tfSave = '{}/{}/{}'.format(targetBase, VERSION, TF_MODULE)\n",
    "tfDeliver = '{}/{}'.format(tfLocation, TF_MODULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newFeaturesStr = '''\n",
    "    freq_occ\n",
    "    freq_lex\n",
    "    rank_occ\n",
    "    rank_lex\n",
    "'''\n",
    "newFeatures = newFeaturesStr.strip().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = MUSTRUN(None, '{}/.tf/{}.tfx'.format(tfDeliver, newFeatures[0]))\n",
    "    if not good: sys.exit(1)\n",
    "    if not work: sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the TF slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Collect\n",
    "\n",
    "We collect the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def collect():\n",
    "    startNow()\n",
    "    tprint('Computing statistics')\n",
    "\n",
    "    TF = Fabric(locations=tfLocation, modules=TF_MODULE)\n",
    "    api = TF.load('language lex g_cons')\n",
    "    F = api.F\n",
    "    \n",
    "    tprint('Counting')\n",
    "    wstats = {\n",
    "        'freqs': {\n",
    "            'lex': collections.defaultdict(lambda: collections.Counter()),\n",
    "            'occ': collections.defaultdict(lambda: collections.Counter()),\n",
    "        },\n",
    "        'ranks': {\n",
    "            'lex': collections.defaultdict(lambda: {}),\n",
    "            'occ': collections.defaultdict(lambda: {}),\n",
    "        },\n",
    "    }\n",
    "    langs = set()\n",
    "\n",
    "    for w in F.otype.s('word'):\n",
    "        occ = F.g_cons.v(w)\n",
    "        lex = F.lex.v(w)\n",
    "        lan = F.language.v(w)\n",
    "        wstats['freqs']['lex'][lan][lex] += 1\n",
    "        wstats['freqs']['occ'][lan][occ] += 1\n",
    "        langs.add(lan)\n",
    "    for lan in langs:\n",
    "        for tp in ['lex', 'occ']:\n",
    "            rank = -1\n",
    "            prev_n = -1\n",
    "            amount = 1\n",
    "            for (x, n) in sorted(wstats['freqs'][tp][lan].items(), key=lambda y: (-y[1], y[0])):\n",
    "                if n == prev_n:\n",
    "                    amount += 1\n",
    "                else:\n",
    "                    rank += amount\n",
    "                    amount = 1\n",
    "                prev_n = n\n",
    "                wstats['ranks'][tp][lan][x] = rank\n",
    "\n",
    "    tprint('Making features')\n",
    "    metaData={}\n",
    "    nodeFeatures = {}\n",
    "    edgeFeatures = {}\n",
    "    \n",
    "    for ft in (newFeatures):\n",
    "        nodeFeatures[ft] = {}\n",
    "        metaData.setdefault(ft, {})['valueType'] = 'int'\n",
    "\n",
    "    for w in F.otype.s('word'):\n",
    "        lan = F.language.v(w)\n",
    "        occ = F.g_cons.v(w)\n",
    "        lex = F.lex.v(w)\n",
    "        nodeFeatures['freq_occ'][w] = str(wstats['freqs']['occ'][lan][occ])\n",
    "        nodeFeatures['rank_occ'][w] = str(wstats['ranks']['occ'][lan][occ])\n",
    "        nodeFeatures['freq_lex'][w] = str(wstats['freqs']['lex'][lan][lex])\n",
    "        nodeFeatures['rank_lex'][w] = str(wstats['ranks']['lex'][lan][lex])\n",
    "\n",
    "    tprint('Write out')\n",
    "    TF = Fabric(locations=tfSave)\n",
    "    TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)\n",
    "    \n",
    "    tprint('Compile and test')\n",
    "    TF = Fabric(locations=tfLocation, modules=TF_MODULE)\n",
    "    api = TF.load('lex '+newFeaturesStr)\n",
    "    F = api.F\n",
    "    mostFrequent = set()\n",
    "    \n",
    "    topX = 10\n",
    "    for w in sorted(F.otype.s('word'), key=lambda w: -F.freq_lex.v(w)):\n",
    "        mostFrequent.add(F.lex.v(w))\n",
    "        if len(mostFrequent) == topX: break\n",
    "            \n",
    "    print('Top {} freqent lexemes = {}'.format(\n",
    "        topX,\n",
    "        '\\n\\t'.join(mostFrequent),\n",
    "    ))\n",
    "    tprint('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.00s Computing statistics\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "99 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.13s B g_cons               from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.13s B lex                  from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.13s B language             from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.00s Feature overview: 94 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  5.07s All features loaded/computed - for details use loadLog()\n",
      "      5.08s Counting\n",
      "      6.31s Making features\n",
      "      8.17s Write out\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Grid feature \"otype\" not found in\n",
      "\n",
      "  0.00s Grid feature \"oslots\" not found in\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Grid feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Exporting 4 node and 0 edge and 0 config features to /Users/dirk/github/bhsa/tf/d/core:\n",
      "   |     0.81s T freq_lex             to /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.87s T freq_occ             to /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.79s T rank_lex             to /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.76s T rank_occ             to /Users/dirk/github/bhsa/tf/d/core\n",
      "  3.24s Exported 4 node features and 0 edge features and 0 config features to /Users/dirk/github/bhsa/tf/d/core\n",
      "        11s Compile and test\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "99 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.17s B lex                  from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.92s T freq_occ             from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.90s T freq_lex             from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     1.17s T rank_occ             from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     1.12s T rank_lex             from /Users/dirk/github/bhsa/tf/d/core\n",
      "   |     0.00s Feature overview: 94 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "    11s All features loaded/computed - for details use loadLog()\n",
      "Top 10 freqent lexemes = L\n",
      "\tB\n",
      "\t>L\n",
      "\tW\n",
      "\t<L\n",
      "\t>CR\n",
      "\tH\n",
      "\t>T\n",
      "\tJHWH/\n",
      "\tMN\n",
      "        23s Done\n"
     ]
    }
   ],
   "source": [
    "collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If in script mode, we should tell whether the execution was successful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT: sys.exit(0 if good else 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
