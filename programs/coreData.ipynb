{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "![mql](images/emdros.png)\n",
    "\n",
    "# TF from MQL\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the [BHSA](https://github.com/ETCBC/bhsa) Hebrew Text Database\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric)\n",
    "resource.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The principled way of going about such a conversion is to import the MQL source into\n",
    "an [Emdros](https://emdros.org) database, and use it to retrieve objects and features from there.\n",
    "\n",
    "Because the syntax of an MQL file leaves some freedom, it is error prone to do a text-to-text conversion from\n",
    "MQL to something else.\n",
    "\n",
    "Yet this is what we do, the error-prone thing. We then avoid installing and configuring and managing Emdros, MySQL/sqLite3.\n",
    "Aside the upfront work to get this going, the going after that would also be much slower.\n",
    "\n",
    "So here you are, a smallish script to do an awful lot of work, mostly correct, if careful used.\n",
    "\n",
    "# Caveat\n",
    "\n",
    "This notebook makes use of a new feature of text-fabric, first present in 2.3.12.\n",
    "Make sure to upgrade first.\n",
    "\n",
    "```sudo -H pip3 install --upgrade text-fabric\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from shutil import rmtree\n",
    "from tf.fabric import Fabric\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION = '3'\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "mqlzFile = '{}/{}.mql.bz2'.format(thisSource, CORE_NAME)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempSource = '{}/source'.format(thisTemp)\n",
    "mqlFile = '{}/{}.mql'.format(thisTempSource, CORE_NAME)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    testFile = '{}/.tf/otype.tfx'.format(thisTf)\n",
    "    (good, work) = utils.mustRun(mqlzFile, '{}/.tf/otype.tfx'.format(thisTf), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the TF slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slotType = 'word'\n",
    "\n",
    "featureMetaData = dict(\n",
    "    dataset='BHSA',\n",
    "    version=VERSION,\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), Ulrik Petersen (MQL) and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    '': {\n",
    "        '': '''\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "@fmt:text-orig-full={g_word_utf8}{g_suffix_utf8}\n",
    "''',\n",
    "    },\n",
    "    '3': '''\n",
    "@fmt:lex-orig-full={graphical_lexeme_utf8} \n",
    "@fmt:lex-orig-plain={lexeme_utf8} \n",
    "@fmt:lex-trans-full={graphical_lexeme} \n",
    "@fmt:lex-trans-plain={lexeme} \n",
    "@fmt:text-orig-full={text}{suffix}\n",
    "@fmt:text-orig-plain={surface_consonants_utf8}{suffix}\n",
    "@fmt:text-trans-full={graphical_word} \n",
    "@fmt:text-trans-plain={surface_consonants} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '4': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '4b': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    'c': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '2016': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '2017': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper otext material, falling back on a default if nothing \n",
    "appropriate has been specified in `oText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s INFO: otext feature information found\n",
      "|       0.00s \tfmt:lex-orig-full    = \"{graphical_lexeme_utf8} \"\n",
      "|       0.00s \tfmt:lex-orig-plain   = \"{lexeme_utf8} \"\n",
      "|       0.00s \tfmt:lex-trans-full   = \"{graphical_lexeme} \"\n",
      "|       0.00s \tfmt:lex-trans-plain  = \"{lexeme} \"\n",
      "|       0.00s \tfmt:text-orig-full   = \"{text}{suffix}\"\n",
      "|       0.00s \tfmt:text-orig-plain  = \"{surface_consonants_utf8}{suffix}\"\n",
      "|       0.00s \tfmt:text-trans-full  = \"{graphical_word} \"\n",
      "|       0.00s \tfmt:text-trans-plain = \"{surface_consonants} \"\n",
      "|       0.00s \tsectionFeatures      = \"book,chapter,verse\"\n",
      "|       0.00s \tsectionTypes         = \"book,chapter,verse\"\n"
     ]
    }
   ],
   "source": [
    "thisOtext = oText.get(VERSION, oText[''])\n",
    "\n",
    "if thisOtext is oText['']:\n",
    "    utils.caption(0, 'WARNING: no otext feature info provided, using a meager default value')\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, 'INFO: otext feature information found')\n",
    "    otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip('\\n').split('\\n'))\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '\\t{:<20} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The program has several stages:\n",
    "   \n",
    "1. **prepare** the source (utils.bunzip if needed)\n",
    "1. **convert** convert the MQL file into a text-fabric dataset\n",
    "1. **differences** (informational)\n",
    "1. **deliver** the tf data at its destination directory\n",
    "1. **compile** all tf features to binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "Check the source, utils.bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.02s bunzipping /Users/dirk/github/etcbc/bhsa/source/3/bhsa.mql.bz2 ...\n",
      "|       0.02s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|       0.02s Done\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(thisTempSource):\n",
    "    os.makedirs(thisTempSource)\n",
    "\n",
    "utils.caption(0, 'bunzipping {} ...'.format(mqlzFile))\n",
    "utils.bunzip(mqlzFile, mqlFile)\n",
    "utils.caption(0, 'Done')\n",
    "\n",
    "if os.path.exists(thisTempTf): rmtree(thisTempTf)\n",
    "os.makedirs(thisTempTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL to Text-Fabric\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Parsing mql source ...\n",
      "  0.00s \t\tenum boolean\n",
      "  0.00s \t\tenum language_e\n",
      "  0.01s \t\tenum paradigmatic_preformative_e\n",
      "  0.01s \t\tenum paradigmatic_root_formation_e\n",
      "  0.01s \t\tenum paradigmatic_verbal_ending_e\n",
      "  0.01s \t\tenum paradigmatic_nominal_ending_e\n",
      "  0.01s \t\tenum paradigmatic_pron_suffix_e\n",
      "  0.01s \t\tenum locative_e\n",
      "  0.02s \t\tenum aramaic_definite_article_e\n",
      "  0.02s \t\tenum lexical_set_e\n",
      "  0.02s \t\tenum part_of_speech_e\n",
      "  0.02s \t\tenum gender_e\n",
      "  0.02s \t\tenum suffix_gender_e\n",
      "  0.02s \t\tenum number_e\n",
      "  0.03s \t\tenum suffix_number_e\n",
      "  0.03s \t\tenum person_e\n",
      "  0.03s \t\tenum suffix_person_e\n",
      "  0.03s \t\tenum noun_type_e\n",
      "  0.03s \t\tenum state_e\n",
      "  0.03s \t\tenum determination_e\n",
      "  0.03s \t\tenum pronoun_type_e\n",
      "  0.04s \t\tenum stem_e\n",
      "  0.04s \t\tenum tense_e\n",
      "  0.04s \t\tenum mood_e\n",
      "  0.04s \t\tenum phrase_type_e\n",
      "  0.04s \t\tenum phrase_atom_type_e\n",
      "  0.05s \t\tenum phrase_function_e\n",
      "  0.05s \t\tenum book_name_e\n",
      "  0.05s \t\tenum phrase_atom_relation_e\n",
      "  0.05s \t\tenum subphrase_type_e\n",
      "  0.05s \t\tenum subphrase_kind_e\n",
      "  0.05s \t\tenum clause_type_e\n",
      "  0.06s \t\tenum clause_atom_type_e\n",
      "  0.06s \t\tenum clause_constituent_relation_e\n",
      "  0.06s \t\tenum clause_atom_relation_tense_of_verbal_predicate_e\n",
      "  0.06s \t\tenum clause_atom_relation_preposition_class_e\n",
      "  0.06s \t\tenum clause_atom_relation_kind_e\n",
      "  0.06s \t\tenum domain_e\n",
      "  0.07s \t\tenum embedding_domain_e\n",
      "  0.07s \t\totype word\n",
      "  0.07s \t\t\tfeature word_number_within_book (int) =def= 0 : node\n",
      "  0.07s \t\t\tfeature graphical_aramaic_definite_article_plain (str) =def=  : node\n",
      "  0.07s \t\t\tfeature graphical_aramaic_definite_article (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_locative_plain (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_locative (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_pron_suffix_plain (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_pron_suffix (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_nominal_ending_plain (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_nominal_ending (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_verbal_ending_plain (str) =def=  : node\n",
      "  0.08s \t\t\tfeature graphical_verbal_ending (str) =def=  : node\n",
      "  0.09s \t\t\tfeature graphical_root_formation_plain (str) =def=  : node\n",
      "  0.09s \t\t\tfeature graphical_root_formation (str) =def=  : node\n",
      "  0.09s \t\t\tfeature graphical_preformative_plain (str) =def=  : node\n",
      "  0.09s \t\t\tfeature graphical_preformative (str) =def=  : node\n",
      "  0.09s \t\t\tfeature surface_consonants_utf8 (str) =def=  : node\n",
      "  0.09s \t\t\tfeature surface_consonants (str) =def=  : node\n",
      "  0.10s \t\t\tfeature vocalized_lexeme_utf8 (str) =def=  : node\n",
      "  0.10s \t\t\tfeature vocalized_lexeme (str) =def=  : node\n",
      "  0.10s \t\t\tfeature old_lexeme_utf8 (str) =def=  : node\n",
      "  0.10s \t\t\tfeature old_lexeme (str) =def=  : node\n",
      "  0.10s \t\t\tfeature graphical_lexeme_utf8 (str) =def=  : node\n",
      "  0.10s \t\t\tfeature graphical_lexeme (str) =def=  : node\n",
      "  0.11s \t\t\tfeature graphical_word (str) =def=  : node\n",
      "  0.11s \t\t\tfeature lexeme_utf8 (str) =def=  : node\n",
      "  0.11s \t\t\tfeature lexeme (str) =def=  : node\n",
      "  0.11s \t\t\tfeature suffix (str) =def=  : node\n",
      "  0.11s \t\t\tfeature text_plain (str) =def=  : node\n",
      "  0.11s \t\t\tfeature text (str) =def=  : node\n",
      "  0.11s \t\t\tfeature language (str) =def= Hebrew : node\n",
      "  0.12s \t\t\tfeature aramaic_definite_article (str) =def=  : node\n",
      "  0.12s \t\t\tfeature locative (str) =def=  : node\n",
      "  0.12s \t\t\tfeature paradigmatic_pron_suffix (str) =def=  : node\n",
      "  0.12s \t\t\tfeature paradigmatic_nominal_ending (str) =def=  : node\n",
      "  0.12s \t\t\tfeature paradigmatic_verbal_ending (str) =def=  : node\n",
      "  0.12s \t\t\tfeature paradigmatic_root_formation (str) =def=  : node\n",
      "  0.12s \t\t\tfeature paradigmatic_preformative (str) =def=  : node\n",
      "  0.13s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.13s \t\t\tfeature lexical_set (str) =def= Absent_lexical_set : node\n",
      "  0.13s \t\t\tfeature pronoun_type (str) =def= none : node\n",
      "  0.13s \t\t\tfeature noun_type (str) =def= none : node\n",
      "  0.13s \t\t\tfeature suffix_gender (str) =def= none : node\n",
      "  0.13s \t\t\tfeature suffix_number (str) =def= none : node\n",
      "  0.13s \t\t\tfeature suffix_person (str) =def= none : node\n",
      "  0.14s \t\t\tfeature state (str) =def= none : node\n",
      "  0.14s \t\t\tfeature gender (str) =def= none : node\n",
      "  0.14s \t\t\tfeature number (str) =def= none : node\n",
      "  0.14s \t\t\tfeature person (str) =def= none : node\n",
      "  0.14s \t\t\tfeature tense (str) =def= none : node\n",
      "  0.14s \t\t\tfeature stem (str) =def= none : node\n",
      "  0.15s \t\t\tfeature phrase_dependent_part_of_speech (str) =def= none : node\n",
      "  0.15s \t\t\tfeature part_of_speech (str) =def= none : node\n",
      "  0.15s \t\totype sentence\n",
      "  0.15s \t\t\tfeature number_within_chapter (int) =def= 0 : node\n",
      "  0.15s \t\totype clause_atom\n",
      "  0.15s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.15s \t\t\tfeature indentation (int) =def= 0 : node\n",
      "  0.16s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.16s \t\t\tfeature clause_atom_relation_daughter_tense (str) =def= unknown : node\n",
      "  0.16s \t\t\tfeature clause_atom_relation_mother_tense (str) =def= unknown : node\n",
      "  0.16s \t\t\tfeature clause_atom_relation_preposition_class (str) =def= none : node\n",
      "  0.16s \t\t\tfeature clause_atom_relation_kind (str) =def= No_relation : node\n",
      "  0.17s \t\t\tfeature clause_atom_relation (int) =def= 0 : node\n",
      "  0.17s \t\t\tfeature clause_atom_type (str) =def= none : node\n",
      "  0.17s \t\t\tfeature clause_atom_number (int) =def= 0 : node\n",
      "  0.17s \t\totype phrase_atom\n",
      "  0.17s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.18s \t\t\tfeature phrase_atom_relation (str) =def= Appo : node\n",
      "  0.18s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.18s \t\t\tfeature determination (str) =def= NA : node\n",
      "  0.18s \t\t\tfeature is_apposition (str) =def= false : node\n",
      "  0.18s \t\t\tfeature phrase_atom_type (str) =def= VP : node\n",
      "  0.18s \t\t\tfeature phrase_atom_number (int) =def= 0 : node\n",
      "  0.18s \t\totype phrase\n",
      "  0.18s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.19s \t\t\tfeature phrase_function (str) =def= none : node\n",
      "  0.19s \t\t\tfeature determination (str) =def= NA : node\n",
      "  0.19s \t\t\tfeature is_apposition (str) =def= false : node\n",
      "  0.19s \t\t\tfeature phrase_type (str) =def= VP : node\n",
      "  0.19s \t\t\tfeature number_within_clause (int) =def= 0 : node\n",
      "  0.20s \t\totype subphrase\n",
      "  0.20s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.20s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.20s \t\t\tfeature subphrase_kind (str) =def= mother : node\n",
      "  0.20s \t\t\tfeature subphrase_type (str) =def= ADJ : node\n",
      "  0.20s \t\totype chapter\n",
      "  0.21s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.21s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.21s \t\totype book\n",
      "  0.21s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.21s \t\totype sentence_atom\n",
      "  0.21s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.22s \t\t\tfeature sentence_atom_number (int) =def= 0 : node\n",
      "  0.22s \t\totype clause\n",
      "  0.22s \t\t\tfeature parents (str) =def= id_d : node\n",
      "  0.22s \t\t\tfeature clause_type (str) =def= none : node\n",
      "  0.23s \t\t\tfeature levels_of_embedding (int) =def= 0 : node\n",
      "  0.23s \t\t\tfeature embedding_domain (str) =def= none : node\n",
      "  0.23s \t\t\tfeature domain (str) =def= Unknown : node\n",
      "  0.23s \t\t\tfeature text_type (str) =def=  : node\n",
      "  0.23s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.23s \t\t\tfeature clause_constituent_relation (str) =def= none : node\n",
      "  0.23s \t\t\tfeature number_within_sentence (int) =def= 0 : node\n",
      "  0.24s \t\totype verse\n",
      "  0.24s \t\t\tfeature verse_label (str) =def=  : node\n",
      "  0.24s \t\t\tfeature verse (int) =def= 0 : node\n",
      "  0.24s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.24s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.24s \t\totype half_verse\n",
      "  0.25s \t\t\tfeature half_verse (str) =def=  : node\n",
      "  0.25s \t\tobjects in word\n",
      "  8.32s \tline   1000000\n",
      "    14s \tline   2000000\n",
      "    19s \t\tobjects in word\n",
      "    20s \tline   3000000\n",
      "    26s \tline   4000000\n",
      "    32s \tline   5000000\n",
      "    36s \t\tobjects in word\n",
      "    38s \tline   6000000\n",
      "    44s \tline   7000000\n",
      "    50s \tline   8000000\n",
      "    53s \t\tobjects in word\n",
      "    56s \tline   9000000\n",
      " 1m 02s \tline  10000000\n",
      " 1m 08s \tline  11000000\n",
      " 1m 10s \t\tobjects in word\n",
      " 1m 14s \tline  12000000\n",
      " 1m 20s \tline  13000000\n",
      " 1m 27s \tline  14000000\n",
      " 1m 27s \t\tobjects in word\n",
      " 1m 32s \tline  15000000\n",
      " 1m 38s \tline  16000000\n",
      " 1m 43s \t\tobjects in word\n",
      " 1m 44s \tline  17000000\n",
      " 1m 51s \tline  18000000\n",
      " 1m 57s \tline  19000000\n",
      " 2m 00s \t\tobjects in word\n",
      " 2m 03s \tline  20000000\n",
      " 2m 09s \tline  21000000\n",
      " 2m 15s \tline  22000000\n",
      " 2m 17s \t\tobjects in word\n",
      " 2m 21s \tline  23000000\n",
      " 2m 26s \t\tobjects in sentence\n",
      " 2m 27s \tline  24000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2m 27s \t\tobjects in sentence\n",
      " 2m 28s \t\tobjects in clause_atom\n",
      " 2m 30s \t\tobjects in clause_atom\n",
      " 2m 31s \tline  25000000\n",
      " 2m 32s \t\tobjects in phrase_atom\n",
      " 2m 34s \tline  26000000\n",
      " 2m 34s \t\tobjects in phrase_atom\n",
      " 2m 36s \t\tobjects in phrase_atom\n",
      " 2m 38s \tline  27000000\n",
      " 2m 38s \t\tobjects in phrase_atom\n",
      " 2m 40s \t\tobjects in phrase_atom\n",
      " 2m 41s \tline  28000000\n",
      " 2m 42s \t\tobjects in phrase_atom\n",
      " 2m 43s \t\tobjects in phrase\n",
      " 2m 45s \t\tobjects in phrase\n",
      " 2m 45s \tline  29000000\n",
      " 2m 47s \t\tobjects in phrase\n",
      " 2m 48s \t\tobjects in phrase\n",
      " 2m 48s \tline  30000000\n",
      " 2m 50s \t\tobjects in phrase\n",
      " 2m 52s \t\tobjects in phrase\n",
      " 2m 52s \tline  31000000\n",
      " 2m 52s \t\tobjects in subphrase\n",
      " 2m 54s \t\tobjects in subphrase\n",
      " 2m 55s \t\tobjects in subphrase\n",
      " 2m 55s \t\tobjects in chapter\n",
      " 2m 55s \t\tobjects in book\n",
      " 2m 55s \t\tobjects in sentence_atom\n",
      " 2m 56s \tline  32000000\n",
      " 2m 56s \t\tobjects in sentence_atom\n",
      " 2m 57s \t\tobjects in clause\n",
      " 3m 00s \tline  33000000\n",
      " 3m 00s \t\tobjects in clause\n",
      " 3m 02s \t\tobjects in verse\n",
      " 3m 03s \t\tobjects in half_verse\n",
      " 3m 04s 33910385 lines parsed\n",
      " 3m 04s 426499 objects of type word\n",
      " 3m 04s 71354 objects of type sentence\n",
      " 3m 04s 90061 objects of type clause_atom\n",
      " 3m 04s 269638 objects of type phrase_atom\n",
      " 3m 04s 257109 objects of type phrase\n",
      " 3m 04s 109536 objects of type subphrase\n",
      " 3m 04s 929 objects of type chapter\n",
      " 3m 04s 39 objects of type book\n",
      " 3m 04s 71727 objects of type sentence_atom\n",
      " 3m 04s 88387 objects of type clause\n",
      " 3m 04s 23213 objects of type verse\n",
      " 3m 04s 44683 objects of type half_verse\n",
      " 3m 04s Making TF data ...\n",
      " 3m 04s Monad - idd mapping ...\n",
      " 3m 04s Removing holes in the monad sequence\n",
      " 3m 04s maxSlot=426499\n",
      " 3m 04s Node mapping and otype ...\n",
      " 3m 05s oslots ...\n",
      " 3m 09s metadata ...\n",
      " 3m 09s features ...\n",
      " 3m 09s \tfeatures from words\n",
      " 3m 13s \t   100000 words\n",
      " 3m 17s \t   200000 words\n",
      " 3m 21s \t   300000 words\n",
      " 3m 26s \t   400000 words\n",
      " 3m 27s \t   426499 words\n",
      " 3m 27s \tfeatures from books\n",
      " 3m 27s \t       39 books\n",
      " 3m 27s \tfeatures from chapters\n",
      " 3m 27s \t      929 chapters\n",
      " 3m 27s \tfeatures from clauses\n",
      " 3m 27s \t    88387 clauses\n",
      " 3m 27s \tfeatures from clause_atoms\n",
      " 3m 28s \t    90061 clause_atoms\n",
      " 3m 28s \tfeatures from half_verses\n",
      " 3m 28s \t    44683 half_verses\n",
      " 3m 28s \tfeatures from phrases\n",
      " 3m 29s \t   100000 phrases\n",
      " 3m 29s \t   200000 phrases\n",
      " 3m 29s \t   257109 phrases\n",
      " 3m 29s \tfeatures from phrase_atoms\n",
      " 3m 30s \t   100000 phrase_atoms\n",
      " 3m 30s \t   200000 phrase_atoms\n",
      " 3m 31s \t   269638 phrase_atoms\n",
      " 3m 31s \tfeatures from sentences\n",
      " 3m 31s \t    71354 sentences\n",
      " 3m 31s \tfeatures from sentence_atoms\n",
      " 3m 31s \t    71727 sentence_atoms\n",
      " 3m 31s \tfeatures from subphrases\n",
      " 3m 31s \t   100000 subphrases\n",
      " 3m 31s \t   109536 subphrases\n",
      " 3m 31s \tfeatures from verses\n",
      " 3m 31s \t    23213 verses\n",
      "   |     0.76s T aramaic_definite_article to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.05s T book                 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.04s T chapter              to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T clause_atom_number   to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T clause_atom_relation to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T clause_atom_relation_daughter_tense to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T clause_atom_relation_kind to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T clause_atom_relation_mother_tense to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T clause_atom_relation_preposition_class to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T clause_atom_type     to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T clause_constituent_relation to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.19s T clause_type          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.97s T determination        to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.21s T domain               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T embedding_domain     to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.82s T gender               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.71s T graphical_aramaic_definite_article to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T graphical_aramaic_definite_article_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.85s T graphical_lexeme     to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.82s T graphical_lexeme_utf8 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.72s T graphical_locative   to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.69s T graphical_locative_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.71s T graphical_nominal_ending to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.75s T graphical_nominal_ending_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.70s T graphical_preformative to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.72s T graphical_preformative_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.71s T graphical_pron_suffix to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.76s T graphical_pron_suffix_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.70s T graphical_root_formation to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.73s T graphical_root_formation_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.69s T graphical_verbal_ending to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.69s T graphical_verbal_ending_plain to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.78s T graphical_word       to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.08s T half_verse           to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T indentation          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.89s T is_apposition        to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.79s T language             to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.18s T levels_of_embedding  to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.79s T lexeme               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.81s T lexeme_utf8          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.80s T lexical_set          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.76s T locative             to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T noun_type            to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.85s T number               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T number_within_chapter to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.45s T number_within_clause to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.15s T number_within_sentence to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.79s T old_lexeme           to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.85s T old_lexeme_utf8      to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.64s T otype                to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.82s T paradigmatic_nominal_ending to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T paradigmatic_preformative to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.83s T paradigmatic_pron_suffix to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.84s T paradigmatic_root_formation to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.78s T paradigmatic_verbal_ending to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     2.46s T parents              to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.85s T part_of_speech       to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.80s T person               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.58s T phrase_atom_number   to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.59s T phrase_atom_relation to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.51s T phrase_atom_type     to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.83s T phrase_dependent_part_of_speech to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.48s T phrase_function      to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.63s T phrase_type          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T pronoun_type         to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.14s T sentence_atom_number to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.81s T state                to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.83s T stem                 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.20s T subphrase_kind       to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.19s T subphrase_type       to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.74s T suffix               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.81s T suffix_gender        to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.79s T suffix_number        to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T suffix_person        to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.77s T surface_consonants   to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.84s T surface_consonants_utf8 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.83s T tense                to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.87s T text                 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.86s T text_plain           to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.16s T text_type            to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.04s T verse                to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.04s T verse_label          to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.92s T vocalized_lexeme     to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.81s T vocalized_lexeme_utf8 to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.79s T word_number_within_book to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.48s T mother               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     4.09s T oslots               to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/bhsa/_temp/3/tf\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.importMQL(mqlFile, slotType=slotType, otext=otextInfo, meta=featureMetaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      5m 41s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|      5m 41s \tno features to add\n",
      "|      5m 41s \tno features to delete\n",
      "|      5m 41s \t88 features in common\n",
      "|      5m 41s aramaic_definite_article  ... differences after the metadata\n",
      "|      5m 41s \tline  28737 OLD -->28800\tAbsent<--\n",
      "|      5m 41s \tline  28737 NEW -->Absent<--\n",
      "|      5m 41s \tline  52485 OLD -->52600\tAbsent<--\n",
      "|      5m 41s \tline  52485 NEW -->Absent<--\n",
      "|      5m 41s \tline  69584 OLD -->69800\tAbsent<--\n",
      "|      5m 41s \tline  69584 NEW -->Absent<--\n",
      "|      5m 41s \tline  92770 OLD -->93100\tAbsent<--\n",
      "|      5m 41s \tline  92770 NEW -->Absent<--\n",
      "\n",
      "|      5m 41s book                      ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->430157\tGenesis<--\n",
      "|      5m 41s \tline      2 NEW -->426500\tGenesis<--\n",
      "|      5m 41s \tline    970 OLD -->1433620\tGenesis<--\n",
      "|      5m 41s \tline    970 NEW -->1429963\tGenesis<--\n",
      "\n",
      "|      5m 41s chapter                   ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->430196\t1<--\n",
      "|      5m 41s \tline      2 NEW -->426539\t1<--\n",
      "|      5m 41s \tline    931 OLD -->1433620\t1<--\n",
      "|      5m 41s \tline    931 NEW -->1429963\t1<--\n",
      "\n",
      "|      5m 41s clause_atom_number        ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\t1<--\n",
      "|      5m 41s \tline      2 NEW -->515855\t1<--\n",
      "\n",
      "|      5m 41s clause_atom_relation      ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\t0<--\n",
      "|      5m 41s \tline      2 NEW -->515855\t0<--\n",
      "\n",
      "|      5m 41s clause_atom_relation_daughter_tense ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\tunknown<--\n",
      "|      5m 41s \tline      2 NEW -->515855\tunknown<--\n",
      "\n",
      "|      5m 41s clause_atom_relation_kind ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\tNo_relation<--\n",
      "|      5m 41s \tline      2 NEW -->515855\tNo_relation<--\n",
      "\n",
      "|      5m 41s clause_atom_relation_mother_tense ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\tunknown<--\n",
      "|      5m 41s \tline      2 NEW -->515855\tunknown<--\n",
      "\n",
      "|      5m 41s clause_atom_relation_preposition_class ... differences after the metadata\n",
      "|      5m 41s \tline      2 OLD -->519512\tnone<--\n",
      "|      5m 41s \tline      2 NEW -->515855\tnone<--\n",
      "\n",
      "|      5m 42s clause_atom_type          ... differences after the metadata\n",
      "|      5m 42s \tline      2 OLD -->519512\txQtl<--\n",
      "|      5m 42s \tline      2 NEW -->515855\txQtl<--\n",
      "\n",
      "|      5m 42s clause_constituent_relation ... differences after the metadata\n",
      "|      5m 42s \tline      2 OLD -->431125\tnone<--\n",
      "|      5m 42s \tline      2 NEW -->427468\tnone<--\n",
      "\n",
      "|      5m 42s clause_type               ... differences after the metadata\n",
      "|      5m 42s \tline      2 OLD -->431125\txQtl<--\n",
      "|      5m 42s \tline      2 NEW -->427468\txQtl<--\n",
      "\n",
      "|      5m 42s determination             ... differences after the metadata\n",
      "|      5m 42s \tline      2 OLD -->654256\tindetermined<--\n",
      "|      5m 42s \tline      2 NEW -->650599\tindetermined<--\n",
      "\n",
      "|      5m 42s domain                    ... differences after the metadata\n",
      "|      5m 42s \tline      2 OLD -->431125\tUnknown<--\n",
      "|      5m 42s \tline      2 NEW -->427468\tUnknown<--\n",
      "\n",
      "|      5m 42s embedding_domain          ... differences after the metadata\n",
      "|      5m 43s \tline      2 OLD -->431125\tnone<--\n",
      "|      5m 43s \tline      2 NEW -->427468\tnone<--\n",
      "\n",
      "|      5m 43s gender                    ... differences after the metadata\n",
      "|      5m 43s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 43s \tline  28737 NEW -->none<--\n",
      "|      5m 43s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 43s \tline  52485 NEW -->none<--\n",
      "|      5m 43s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 43s \tline  69584 NEW -->none<--\n",
      "|      5m 43s \tline  92770 OLD -->93100\tunknown<--\n",
      "|      5m 43s \tline  92770 NEW -->unknown<--\n",
      "\n",
      "|      5m 43s graphical_aramaic_definite_article ... differences after the metadata\n",
      "|      5m 43s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 43s \tline  28737 NEW --><--\n",
      "|      5m 43s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 43s \tline  52485 NEW --><--\n",
      "|      5m 43s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 43s \tline  69584 NEW --><--\n",
      "|      5m 43s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 43s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 43s graphical_aramaic_definite_article_plain ... differences after the metadata\n",
      "|      5m 43s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 43s \tline  28737 NEW --><--\n",
      "|      5m 43s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 43s \tline  52485 NEW --><--\n",
      "|      5m 43s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 43s \tline  69584 NEW --><--\n",
      "|      5m 43s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 43s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 43s graphical_lexeme          ... differences after the metadata\n",
      "|      5m 43s \tline  28737 OLD -->28800\tW:-<--\n",
      "|      5m 43s \tline  28737 NEW -->W:-<--\n",
      "|      5m 43s \tline  52485 OLD -->52600\tWA-<--\n",
      "|      5m 43s \tline  52485 NEW -->WA-<--\n",
      "|      5m 43s \tline  69584 OLD -->69800\tWA-<--\n",
      "|      5m 43s \tline  69584 NEW -->WA-<--\n",
      "|      5m 43s \tline  92770 OLD -->93100\t>;74L.EH<--\n",
      "|      5m 43s \tline  92770 NEW -->>;74L.EH<--\n",
      "\n",
      "|      5m 43s graphical_lexeme_utf8     ... differences after the metadata\n",
      "|      5m 43s \tline  28737 OLD -->28800\tוְ<--\n",
      "|      5m 43s \tline  28737 NEW -->וְ<--\n",
      "|      5m 43s \tline  52485 OLD -->52600\tוַ<--\n",
      "|      5m 43s \tline  52485 NEW -->וַ<--\n",
      "|      5m 43s \tline  69584 OLD -->69800\tוַ<--\n",
      "|      5m 43s \tline  69584 NEW -->וַ<--\n",
      "|      5m 43s \tline  92770 OLD -->93100\tאֵ֣לֶּה<--\n",
      "|      5m 43s \tline  92770 NEW -->אֵ֣לֶּה<--\n",
      "\n",
      "|      5m 44s graphical_locative        ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_locative_plain  ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_nominal_ending  ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_nominal_ending_plain ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_preformative    ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_preformative_plain ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 44s graphical_pron_suffix     ... differences after the metadata\n",
      "|      5m 44s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 44s \tline  28737 NEW --><--\n",
      "|      5m 44s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 44s \tline  52485 NEW --><--\n",
      "|      5m 44s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 44s \tline  69584 NEW --><--\n",
      "|      5m 44s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 44s \tline  92770 NEW --><--\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      5m 44s graphical_pron_suffix_plain ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 45s \tline  28737 NEW --><--\n",
      "|      5m 45s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 45s \tline  52485 NEW --><--\n",
      "|      5m 45s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 45s \tline  69584 NEW --><--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 45s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 45s graphical_root_formation  ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 45s \tline  28737 NEW --><--\n",
      "|      5m 45s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 45s \tline  52485 NEW --><--\n",
      "|      5m 45s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 45s \tline  69584 NEW --><--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 45s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 45s graphical_root_formation_plain ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 45s \tline  28737 NEW --><--\n",
      "|      5m 45s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 45s \tline  52485 NEW --><--\n",
      "|      5m 45s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 45s \tline  69584 NEW --><--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 45s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 45s graphical_verbal_ending   ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 45s \tline  28737 NEW --><--\n",
      "|      5m 45s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 45s \tline  52485 NEW --><--\n",
      "|      5m 45s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 45s \tline  69584 NEW --><--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 45s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 45s graphical_verbal_ending_plain ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 45s \tline  28737 NEW --><--\n",
      "|      5m 45s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 45s \tline  52485 NEW --><--\n",
      "|      5m 45s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 45s \tline  69584 NEW --><--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t<--\n",
      "|      5m 45s \tline  92770 NEW --><--\n",
      "\n",
      "|      5m 45s graphical_word            ... differences after the metadata\n",
      "|      5m 45s \tline  28737 OLD -->28800\tW:-<--\n",
      "|      5m 45s \tline  28737 NEW -->W:-<--\n",
      "|      5m 45s \tline  52485 OLD -->52600\tWA-<--\n",
      "|      5m 45s \tline  52485 NEW -->WA-<--\n",
      "|      5m 45s \tline  69584 OLD -->69800\tWA-<--\n",
      "|      5m 45s \tline  69584 NEW -->WA-<--\n",
      "|      5m 45s \tline  92770 OLD -->93100\t>;74L.EH<--\n",
      "|      5m 45s \tline  92770 NEW -->>;74L.EH<--\n",
      "\n",
      "|      5m 45s half_verse                ... differences after the metadata\n",
      "|      5m 46s \tline      2 OLD -->609573\tA<--\n",
      "|      5m 46s \tline      2 NEW -->605916\tA<--\n",
      "\n",
      "|      5m 46s indentation               ... differences after the metadata\n",
      "|      5m 46s \tline      2 OLD -->519512\t0<--\n",
      "|      5m 46s \tline      2 NEW -->515855\t0<--\n",
      "\n",
      "|      5m 46s is_apposition             ... differences after the metadata\n",
      "|      5m 46s \tline      2 OLD -->654256\tfalse<--\n",
      "|      5m 46s \tline      2 NEW -->650599\tfalse<--\n",
      "\n",
      "|      5m 46s language                  ... differences after the metadata\n",
      "|      5m 46s \tline  28737 OLD -->28800\tHebrew<--\n",
      "|      5m 46s \tline  28737 NEW -->Hebrew<--\n",
      "|      5m 46s \tline  52485 OLD -->52600\tHebrew<--\n",
      "|      5m 46s \tline  52485 NEW -->Hebrew<--\n",
      "|      5m 46s \tline  69584 OLD -->69800\tHebrew<--\n",
      "|      5m 46s \tline  69584 NEW -->Hebrew<--\n",
      "|      5m 46s \tline  92770 OLD -->93100\tHebrew<--\n",
      "|      5m 46s \tline  92770 NEW -->Hebrew<--\n",
      "\n",
      "|      5m 46s levels_of_embedding       ... differences after the metadata\n",
      "|      5m 46s \tline      2 OLD -->431125\t0<--\n",
      "|      5m 46s \tline      2 NEW -->427468\t0<--\n",
      "\n",
      "|      5m 47s lexeme                    ... differences after the metadata\n",
      "|      5m 47s \tline  28737 OLD -->28800\tW<--\n",
      "|      5m 47s \tline  28737 NEW -->W<--\n",
      "|      5m 47s \tline  52485 OLD -->52600\tW<--\n",
      "|      5m 47s \tline  52485 NEW -->W<--\n",
      "|      5m 47s \tline  69584 OLD -->69800\tW<--\n",
      "|      5m 47s \tline  69584 NEW -->W<--\n",
      "|      5m 47s \tline  92770 OLD -->93100\t>LH<--\n",
      "|      5m 47s \tline  92770 NEW -->>LH<--\n",
      "\n",
      "|      5m 47s lexeme_utf8               ... differences after the metadata\n",
      "|      5m 47s \tline  28737 OLD -->28800\tו<--\n",
      "|      5m 47s \tline  28737 NEW -->ו<--\n",
      "|      5m 47s \tline  52485 OLD -->52600\tו<--\n",
      "|      5m 47s \tline  52485 NEW -->ו<--\n",
      "|      5m 47s \tline  69584 OLD -->69800\tו<--\n",
      "|      5m 47s \tline  69584 NEW -->ו<--\n",
      "|      5m 47s \tline  92770 OLD -->93100\tאלה<--\n",
      "|      5m 47s \tline  92770 NEW -->אלה<--\n",
      "\n",
      "|      5m 47s lexical_set               ... differences after the metadata\n",
      "|      5m 47s \tline  28737 OLD -->28800\tAbsent_lexical_set<--\n",
      "|      5m 47s \tline  28737 NEW -->Absent_lexical_set<--\n",
      "|      5m 47s \tline  52485 OLD -->52600\tAbsent_lexical_set<--\n",
      "|      5m 47s \tline  52485 NEW -->Absent_lexical_set<--\n",
      "|      5m 47s \tline  69584 OLD -->69800\tAbsent_lexical_set<--\n",
      "|      5m 47s \tline  69584 NEW -->Absent_lexical_set<--\n",
      "|      5m 47s \tline  92770 OLD -->93100\tAbsent_lexical_set<--\n",
      "|      5m 47s \tline  92770 NEW -->Absent_lexical_set<--\n",
      "\n",
      "|      5m 47s locative                  ... differences after the metadata\n",
      "|      5m 47s \tline  28737 OLD -->28800\tAbsent<--\n",
      "|      5m 47s \tline  28737 NEW -->Absent<--\n",
      "|      5m 47s \tline  52485 OLD -->52600\tAbsent<--\n",
      "|      5m 47s \tline  52485 NEW -->Absent<--\n",
      "|      5m 47s \tline  69584 OLD -->69800\tAbsent<--\n",
      "|      5m 47s \tline  69584 NEW -->Absent<--\n",
      "|      5m 47s \tline  92770 OLD -->93100\tAbsent<--\n",
      "|      5m 47s \tline  92770 NEW -->Absent<--\n",
      "\n",
      "|      5m 47s mother                    ... differences after the metadata\n",
      "|      5m 47s \tline      2 OLD -->431133\t431132<--\n",
      "|      5m 47s \tline      2 NEW -->427476\t427475<--\n",
      "|      5m 47s \tline      3 OLD -->431145\t105<--\n",
      "|      5m 47s \tline      3 NEW -->427488\t105<--\n",
      "|      5m 47s \tline      5 OLD -->431159\t431158<--\n",
      "|      5m 47s \tline      5 NEW -->427502\t427501<--\n",
      "|      5m 47s \tline      6 OLD -->431162\t654375<--\n",
      "|      5m 47s \tline      6 NEW -->427505\t650718<--\n",
      "\n",
      "|      5m 47s noun_type                 ... differences after the metadata\n",
      "|      5m 48s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 48s \tline  28737 NEW -->none<--\n",
      "|      5m 48s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 48s \tline  52485 NEW -->none<--\n",
      "|      5m 48s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 48s \tline  69584 NEW -->none<--\n",
      "|      5m 48s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 48s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 48s number                    ... differences after the metadata\n",
      "|      5m 48s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 48s \tline  28737 NEW -->none<--\n",
      "|      5m 48s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 48s \tline  52485 NEW -->none<--\n",
      "|      5m 48s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 48s \tline  69584 NEW -->none<--\n",
      "|      5m 48s \tline  92770 OLD -->93100\tplural<--\n",
      "|      5m 48s \tline  92770 NEW -->plural<--\n",
      "\n",
      "|      5m 48s number_within_chapter     ... differences after the metadata\n",
      "|      5m 48s \tline      2 OLD -->1181003\t1<--\n",
      "|      5m 48s \tline      2 NEW -->1177346\t1<--\n",
      "\n",
      "|      5m 48s number_within_clause      ... differences after the metadata\n",
      "|      5m 48s \tline      2 OLD -->654256\t1<--\n",
      "|      5m 48s \tline      2 NEW -->650599\t1<--\n",
      "\n",
      "|      5m 48s number_within_sentence    ... differences after the metadata\n",
      "|      5m 48s \tline      2 OLD -->431125\t1<--\n",
      "|      5m 48s \tline      2 NEW -->427468\t1<--\n",
      "\n",
      "|      5m 48s old_lexeme                ... differences after the metadata\n",
      "|      5m 48s \tline  28737 OLD -->28800\tW<--\n",
      "|      5m 48s \tline  28737 NEW -->W<--\n",
      "|      5m 48s \tline  52485 OLD -->52600\tW<--\n",
      "|      5m 48s \tline  52485 NEW -->W<--\n",
      "|      5m 48s \tline  69584 OLD -->69800\tW<--\n",
      "|      5m 48s \tline  69584 NEW -->W<--\n",
      "|      5m 48s \tline  92770 OLD -->93100\t>LH<--\n",
      "|      5m 48s \tline  92770 NEW -->>LH<--\n",
      "\n",
      "|      5m 48s old_lexeme_utf8           ... differences after the metadata\n",
      "|      5m 49s \tline  28737 OLD -->28800\tו<--\n",
      "|      5m 49s \tline  28737 NEW -->ו<--\n",
      "|      5m 49s \tline  52485 OLD -->52600\tו<--\n",
      "|      5m 49s \tline  52485 NEW -->ו<--\n",
      "|      5m 49s \tline  69584 OLD -->69800\tו<--\n",
      "|      5m 49s \tline  69584 NEW -->ו<--\n",
      "|      5m 49s \tline  92770 OLD -->93100\tאלה<--\n",
      "|      5m 49s \tline  92770 NEW -->אלה<--\n",
      "\n",
      "|      5m 49s oslots                    ... differences after the metadata\n",
      "|      5m 49s \tline      2 OLD -->430157\t1-28735<--\n",
      "|      5m 49s \tline      2 NEW -->426500\t1-28735<--\n",
      "|      5m 49s \tline      3 OLD -->28800-52547<--\n",
      "|      5m 49s \tline      3 NEW -->28736-52483<--\n",
      "|      5m 49s \tline      4 OLD -->52600-69698<--\n",
      "|      5m 49s \tline      4 NEW -->52484-69582<--\n",
      "|      5m 49s \tline      5 OLD -->69800-92985<--\n",
      "|      5m 49s \tline      5 NEW -->69583-92768<--\n",
      "\n",
      "|      5m 49s otext                     ... differences\n",
      "|      5m 49s \tline     19 OLD -->@dateWritten=2017-10-05T06:29:41Z<--\n",
      "|      5m 49s \tline     19 NEW -->@dateWritten=2017-10-05T07:06:44Z<--\n",
      "\n",
      "|      5m 49s otype                     ... differences after the metadata\n",
      "|      5m 49s \tline      2 OLD -->1-28735,28800-52547,52600-69698,69800-92 ...<--\n",
      "|      5m 49s \tline      2 NEW -->1-426499\tword<--\n",
      "|      5m 49s \tline      3 OLD -->430157-430195\tbook<--\n",
      "|      5m 49s \tline      3 NEW -->426500-426538\tbook<--\n",
      "|      5m 49s \tline      4 OLD -->430196-431124\tchapter<--\n",
      "|      5m 49s \tline      4 NEW -->426539-427467\tchapter<--\n",
      "|      5m 49s \tline      5 OLD -->431125-519511\tclause<--\n",
      "|      5m 49s \tline      5 NEW -->427468-515854\tclause<--\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      5m 49s paradigmatic_nominal_ending ... differences after the metadata\n",
      "|      5m 49s \tline  28737 OLD -->28800\tNot_applicable<--\n",
      "|      5m 49s \tline  28737 NEW -->Not_applicable<--\n",
      "|      5m 49s \tline  52485 OLD -->52600\tNot_applicable<--\n",
      "|      5m 49s \tline  52485 NEW -->Not_applicable<--\n",
      "|      5m 49s \tline  69584 OLD -->69800\tNot_applicable<--\n",
      "|      5m 49s \tline  69584 NEW -->Not_applicable<--\n",
      "|      5m 49s \tline  92770 OLD -->93100\tNot_applicable<--\n",
      "|      5m 49s \tline  92770 NEW -->Not_applicable<--\n",
      "\n",
      "|      5m 49s paradigmatic_preformative ... differences after the metadata\n",
      "|      5m 49s \tline  28737 OLD -->28800\tNA<--\n",
      "|      5m 49s \tline  28737 NEW -->NA<--\n",
      "|      5m 49s \tline  52485 OLD -->52600\tNA<--\n",
      "|      5m 49s \tline  52485 NEW -->NA<--\n",
      "|      5m 49s \tline  69584 OLD -->69800\tNA<--\n",
      "|      5m 49s \tline  69584 NEW -->NA<--\n",
      "|      5m 49s \tline  92770 OLD -->93100\tNA<--\n",
      "|      5m 49s \tline  92770 NEW -->NA<--\n",
      "\n",
      "|      5m 49s paradigmatic_pron_suffix  ... differences after the metadata\n",
      "|      5m 50s \tline  28737 OLD -->28800\tNot_applicable<--\n",
      "|      5m 50s \tline  28737 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  52485 OLD -->52600\tNot_applicable<--\n",
      "|      5m 50s \tline  52485 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  69584 OLD -->69800\tNot_applicable<--\n",
      "|      5m 50s \tline  69584 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  92770 OLD -->93100\tNot_applicable<--\n",
      "|      5m 50s \tline  92770 NEW -->Not_applicable<--\n",
      "\n",
      "|      5m 50s paradigmatic_root_formation ... differences after the metadata\n",
      "|      5m 50s \tline  28737 OLD -->28800\tNot_applicable<--\n",
      "|      5m 50s \tline  28737 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  52485 OLD -->52600\tNot_applicable<--\n",
      "|      5m 50s \tline  52485 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  69584 OLD -->69800\tNot_applicable<--\n",
      "|      5m 50s \tline  69584 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  92770 OLD -->93100\tNot_applicable<--\n",
      "|      5m 50s \tline  92770 NEW -->Not_applicable<--\n",
      "\n",
      "|      5m 50s paradigmatic_verbal_ending ... differences after the metadata\n",
      "|      5m 50s \tline  28737 OLD -->28800\tNot_applicable<--\n",
      "|      5m 50s \tline  28737 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  52485 OLD -->52600\tNot_applicable<--\n",
      "|      5m 50s \tline  52485 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  69584 OLD -->69800\tNot_applicable<--\n",
      "|      5m 50s \tline  69584 NEW -->Not_applicable<--\n",
      "|      5m 50s \tline  92770 OLD -->93100\tNot_applicable<--\n",
      "|      5m 50s \tline  92770 NEW -->Not_applicable<--\n",
      "\n",
      "|      5m 50s parents                   ... differences after the metadata\n",
      "|      5m 50s \tline  28737 OLD -->28800\t(130519)<--\n",
      "|      5m 50s \tline  28737 NEW -->(130519)<--\n",
      "|      5m 50s \tline  52485 OLD -->52600\t(197877)<--\n",
      "|      5m 50s \tline  52485 NEW -->(197877)<--\n",
      "|      5m 50s \tline  69584 OLD -->69800\t(259441)<--\n",
      "|      5m 50s \tline  69584 NEW -->(259441)<--\n",
      "|      5m 50s \tline  92770 OLD -->93100\t(329559)<--\n",
      "|      5m 50s \tline  92770 NEW -->(329559)<--\n",
      "\n",
      "|      5m 50s part_of_speech            ... differences after the metadata\n",
      "|      5m 51s \tline  28737 OLD -->28800\tconjunction<--\n",
      "|      5m 51s \tline  28737 NEW -->conjunction<--\n",
      "|      5m 51s \tline  52485 OLD -->52600\tconjunction<--\n",
      "|      5m 51s \tline  52485 NEW -->conjunction<--\n",
      "|      5m 51s \tline  69584 OLD -->69800\tconjunction<--\n",
      "|      5m 51s \tline  69584 NEW -->conjunction<--\n",
      "|      5m 51s \tline  92770 OLD -->93100\tpronoun<--\n",
      "|      5m 51s \tline  92770 NEW -->pronoun<--\n",
      "\n",
      "|      5m 51s person                    ... differences after the metadata\n",
      "|      5m 51s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 51s \tline  28737 NEW -->none<--\n",
      "|      5m 51s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 51s \tline  52485 NEW -->none<--\n",
      "|      5m 51s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 51s \tline  69584 NEW -->none<--\n",
      "|      5m 51s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 51s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 51s phrase_atom_number        ... differences after the metadata\n",
      "|      5m 51s \tline      2 OLD -->911365\t1<--\n",
      "|      5m 51s \tline      2 NEW -->907708\t1<--\n",
      "\n",
      "|      5m 51s phrase_atom_relation      ... differences after the metadata\n",
      "|      5m 51s \tline      2 OLD -->911365\tnone<--\n",
      "|      5m 51s \tline      2 NEW -->907708\tnone<--\n",
      "\n",
      "|      5m 51s phrase_atom_type          ... differences after the metadata\n",
      "|      5m 51s \tline      2 OLD -->911365\tPP<--\n",
      "|      5m 51s \tline      2 NEW -->907708\tPP<--\n",
      "\n",
      "|      5m 52s phrase_dependent_part_of_speech ... differences after the metadata\n",
      "|      5m 52s \tline  28737 OLD -->28800\tconjunction<--\n",
      "|      5m 52s \tline  28737 NEW -->conjunction<--\n",
      "|      5m 52s \tline  52485 OLD -->52600\tconjunction<--\n",
      "|      5m 52s \tline  52485 NEW -->conjunction<--\n",
      "|      5m 52s \tline  69584 OLD -->69800\tconjunction<--\n",
      "|      5m 52s \tline  69584 NEW -->conjunction<--\n",
      "|      5m 52s \tline  92770 OLD -->93100\tpronoun<--\n",
      "|      5m 52s \tline  92770 NEW -->pronoun<--\n",
      "\n",
      "|      5m 52s phrase_function           ... differences after the metadata\n",
      "|      5m 52s \tline      2 OLD -->654256\tTime<--\n",
      "|      5m 52s \tline      2 NEW -->650599\tTime<--\n",
      "\n",
      "|      5m 52s phrase_type               ... differences after the metadata\n",
      "|      5m 52s \tline      2 OLD -->654256\tPP<--\n",
      "|      5m 52s \tline      2 NEW -->650599\tPP<--\n",
      "\n",
      "|      5m 52s pronoun_type              ... differences after the metadata\n",
      "|      5m 53s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 53s \tline  28737 NEW -->none<--\n",
      "|      5m 53s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 53s \tline  52485 NEW -->none<--\n",
      "|      5m 53s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 53s \tline  69584 NEW -->none<--\n",
      "|      5m 53s \tline  92770 OLD -->93100\tdemonstrative<--\n",
      "|      5m 53s \tline  92770 NEW -->demonstrative<--\n",
      "\n",
      "|      5m 53s sentence_atom_number      ... differences after the metadata\n",
      "|      5m 53s \tline      2 OLD -->1252357\t0<--\n",
      "|      5m 53s \tline      2 NEW -->1248700\t0<--\n",
      "\n",
      "|      5m 53s state                     ... differences after the metadata\n",
      "|      5m 53s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 53s \tline  28737 NEW -->none<--\n",
      "|      5m 53s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 53s \tline  52485 NEW -->none<--\n",
      "|      5m 53s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 53s \tline  69584 NEW -->none<--\n",
      "|      5m 53s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 53s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 53s stem                      ... differences after the metadata\n",
      "|      5m 53s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 53s \tline  28737 NEW -->none<--\n",
      "|      5m 53s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 53s \tline  52485 NEW -->none<--\n",
      "|      5m 53s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 53s \tline  69584 NEW -->none<--\n",
      "|      5m 53s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 53s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 53s subphrase_kind            ... differences after the metadata\n",
      "|      5m 53s \tline      2 OLD -->1324084\tmother<--\n",
      "|      5m 53s \tline      2 NEW -->1320427\tmother<--\n",
      "\n",
      "|      5m 53s subphrase_type            ... differences after the metadata\n",
      "|      5m 53s \tline      2 OLD -->1324084\tPAR<--\n",
      "|      5m 53s \tline      2 NEW -->1320427\tPAR<--\n",
      "\n",
      "|      5m 53s suffix                    ... differences after the metadata\n",
      "|      5m 54s \tline  28737 OLD -->28800\t<--\n",
      "|      5m 54s \tline  28737 NEW --><--\n",
      "|      5m 54s \tline  52485 OLD -->52600\t<--\n",
      "|      5m 54s \tline  52485 NEW --><--\n",
      "|      5m 54s \tline  69584 OLD -->69800\t<--\n",
      "|      5m 54s \tline  69584 NEW --><--\n",
      "|      5m 54s \tline  92770 OLD -->93100\t <--\n",
      "|      5m 54s \tline  92770 NEW --> <--\n",
      "\n",
      "|      5m 54s suffix_gender             ... differences after the metadata\n",
      "|      5m 54s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 54s \tline  28737 NEW -->none<--\n",
      "|      5m 54s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 54s \tline  52485 NEW -->none<--\n",
      "|      5m 54s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 54s \tline  69584 NEW -->none<--\n",
      "|      5m 54s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 54s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 54s suffix_number             ... differences after the metadata\n",
      "|      5m 54s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 54s \tline  28737 NEW -->none<--\n",
      "|      5m 54s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 54s \tline  52485 NEW -->none<--\n",
      "|      5m 54s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 54s \tline  69584 NEW -->none<--\n",
      "|      5m 54s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 54s \tline  92770 NEW -->none<--\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      5m 54s suffix_person             ... differences after the metadata\n",
      "|      5m 54s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 54s \tline  28737 NEW -->none<--\n",
      "|      5m 54s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 54s \tline  52485 NEW -->none<--\n",
      "|      5m 54s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 54s \tline  69584 NEW -->none<--\n",
      "|      5m 54s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 54s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 54s surface_consonants        ... differences after the metadata\n",
      "|      5m 54s \tline  28737 OLD -->28800\tW<--\n",
      "|      5m 54s \tline  28737 NEW -->W<--\n",
      "|      5m 54s \tline  52485 OLD -->52600\tW<--\n",
      "|      5m 54s \tline  52485 NEW -->W<--\n",
      "|      5m 54s \tline  69584 OLD -->69800\tW<--\n",
      "|      5m 54s \tline  69584 NEW -->W<--\n",
      "|      5m 54s \tline  92770 OLD -->93100\t>LH<--\n",
      "|      5m 54s \tline  92770 NEW -->>LH<--\n",
      "\n",
      "|      5m 54s surface_consonants_utf8   ... differences after the metadata\n",
      "|      5m 55s \tline  28737 OLD -->28800\tו<--\n",
      "|      5m 55s \tline  28737 NEW -->ו<--\n",
      "|      5m 55s \tline  52485 OLD -->52600\tו<--\n",
      "|      5m 55s \tline  52485 NEW -->ו<--\n",
      "|      5m 55s \tline  69584 OLD -->69800\tו<--\n",
      "|      5m 55s \tline  69584 NEW -->ו<--\n",
      "|      5m 55s \tline  92770 OLD -->93100\tאלה<--\n",
      "|      5m 55s \tline  92770 NEW -->אלה<--\n",
      "\n",
      "|      5m 55s tense                     ... differences after the metadata\n",
      "|      5m 55s \tline  28737 OLD -->28800\tnone<--\n",
      "|      5m 55s \tline  28737 NEW -->none<--\n",
      "|      5m 55s \tline  52485 OLD -->52600\tnone<--\n",
      "|      5m 55s \tline  52485 NEW -->none<--\n",
      "|      5m 55s \tline  69584 OLD -->69800\tnone<--\n",
      "|      5m 55s \tline  69584 NEW -->none<--\n",
      "|      5m 55s \tline  92770 OLD -->93100\tnone<--\n",
      "|      5m 55s \tline  92770 NEW -->none<--\n",
      "\n",
      "|      5m 55s text                      ... differences after the metadata\n",
      "|      5m 55s \tline  28737 OLD -->28800\tוְ<--\n",
      "|      5m 55s \tline  28737 NEW -->וְ<--\n",
      "|      5m 55s \tline  52485 OLD -->52600\tוַ<--\n",
      "|      5m 55s \tline  52485 NEW -->וַ<--\n",
      "|      5m 55s \tline  69584 OLD -->69800\tוַ<--\n",
      "|      5m 55s \tline  69584 NEW -->וַ<--\n",
      "|      5m 55s \tline  92770 OLD -->93100\tאֵ֣לֶּה<--\n",
      "|      5m 55s \tline  92770 NEW -->אֵ֣לֶּה<--\n",
      "\n",
      "|      5m 55s text_plain                ... differences after the metadata\n",
      "|      5m 55s \tline  28737 OLD -->28800\tו<--\n",
      "|      5m 55s \tline  28737 NEW -->ו<--\n",
      "|      5m 55s \tline  52485 OLD -->52600\tו<--\n",
      "|      5m 55s \tline  52485 NEW -->ו<--\n",
      "|      5m 55s \tline  69584 OLD -->69800\tו<--\n",
      "|      5m 55s \tline  69584 NEW -->ו<--\n",
      "|      5m 55s \tline  92770 OLD -->93100\tאלה<--\n",
      "|      5m 55s \tline  92770 NEW -->אלה<--\n",
      "\n",
      "|      5m 55s text_type                 ... differences after the metadata\n",
      "|      5m 55s \tline      2 OLD -->431125\t?<--\n",
      "|      5m 55s \tline      2 NEW -->427468\t?<--\n",
      "\n",
      "|      5m 56s verse                     ... differences after the metadata\n",
      "|      5m 56s \tline      2 OLD -->1433620\t1<--\n",
      "|      5m 56s \tline      2 NEW -->1429963\t1<--\n",
      "\n",
      "|      5m 56s verse_label               ... differences after the metadata\n",
      "|      5m 56s \tline      2 OLD -->1433620\t GEN 01,01<--\n",
      "|      5m 56s \tline      2 NEW -->1429963\t GEN 01,01<--\n",
      "\n",
      "|      5m 56s vocalized_lexeme          ... differences after the metadata\n",
      "|      5m 56s \tline  28737 OLD -->28800\tW:<--\n",
      "|      5m 56s \tline  28737 NEW -->W:<--\n",
      "|      5m 56s \tline  52485 OLD -->52600\tW:<--\n",
      "|      5m 56s \tline  52485 NEW -->W:<--\n",
      "|      5m 56s \tline  69584 OLD -->69800\tW:<--\n",
      "|      5m 56s \tline  69584 NEW -->W:<--\n",
      "|      5m 56s \tline  92770 OLD -->93100\t>;L.EH<--\n",
      "|      5m 56s \tline  92770 NEW -->>;L.EH<--\n",
      "\n",
      "|      5m 56s vocalized_lexeme_utf8     ... differences after the metadata\n",
      "|      5m 56s \tline  28737 OLD -->28800\tוְ<--\n",
      "|      5m 56s \tline  28737 NEW -->וְ<--\n",
      "|      5m 56s \tline  52485 OLD -->52600\tוְ<--\n",
      "|      5m 56s \tline  52485 NEW -->וְ<--\n",
      "|      5m 56s \tline  69584 OLD -->69800\tוְ<--\n",
      "|      5m 56s \tline  69584 NEW -->וְ<--\n",
      "|      5m 56s \tline  92770 OLD -->93100\tאֵלֶּה<--\n",
      "|      5m 56s \tline  92770 NEW -->אֵלֶּה<--\n",
      "\n",
      "|      5m 56s word_number_within_book   ... differences after the metadata\n",
      "|      5m 56s \tline  28737 OLD -->28800\t1<--\n",
      "|      5m 56s \tline  28737 NEW -->1<--\n",
      "|      5m 56s \tline  52485 OLD -->52600\t1<--\n",
      "|      5m 56s \tline  52485 NEW -->1<--\n",
      "|      5m 56s \tline  69584 OLD -->69800\t1<--\n",
      "|      5m 56s \tline  69584 NEW -->1<--\n",
      "|      5m 56s \tline  92770 OLD -->93100\t1<--\n",
      "|      5m 56s \tline  92770 NEW -->1<--\n",
      "\n",
      "|      5m 56s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      6m 02s Deliver data set to /Users/dirk/github/etcbc/bhsa/tf/3                         .\n",
      "..............................................................................................\n"
     ]
    }
   ],
   "source": [
    "utils.deliverDataset(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "Just to see whether everything loads and the precomputing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the precomputing has already been done, and everything is quicker in subsequent runs.\n",
    "\n",
    "We issue load statement to trigger the precomputing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature,\n",
    "will be loaded, as well as the features for sections.\n",
    "\n",
    "At that point we have access to the full list of features.\n",
    "We grab them and are going to load them all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.6\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "118 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Feature overview: 115 for nodes; 2 for edges; 1 configs; 7 computed\n",
      "  4.33s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".       4.35s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 115 for nodes; 2 for edges; 1 configs; 7 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.13s B aramaic_definite_article from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B clause_atom_number   from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B clause_atom_relation from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_atom_relation_daughter_tense from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_atom_relation_kind from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_atom_relation_mother_tense from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_atom_relation_preposition_class from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_atom_type     from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_constituent_relation from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B clause_type          from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.17s B determination        from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.04s B domain               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B embedding_domain     from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.10s B freq_lex             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.10s B freq_occ             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.15s B gender               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_aramaic_definite_article from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_aramaic_definite_article_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_locative   from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_locative_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B graphical_nominal_ending from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B graphical_nominal_ending_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B graphical_preformative from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.08s B graphical_preformative_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.08s B graphical_pron_suffix from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.08s B graphical_pron_suffix_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_root_formation from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_root_formation_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.08s B graphical_verbal_ending from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B graphical_verbal_ending_plain from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.01s B half_verse           from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B indentation          from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.15s B is_apposition        from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.18s B language             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B levels_of_embedding  from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.18s B lexical_set          from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.15s B locative             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.27s B mother               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.14s B noun_type            from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.14s B number               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B number_within_chapter from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.06s B number_within_clause from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B number_within_sentence from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.16s B old_lexeme           from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.24s B old_lexeme_utf8      from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.14s B paradigmatic_nominal_ending from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.15s B paradigmatic_preformative from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.16s B paradigmatic_pron_suffix from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.19s B paradigmatic_root_formation from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.17s B paradigmatic_verbal_ending from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.45s B parents              from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.13s B part_of_speech       from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B person               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.05s B phrase_atom_number   from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B phrase_atom_relation from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.08s B phrase_atom_type     from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.13s B phrase_dependent_part_of_speech from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B phrase_function      from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.07s B phrase_type          from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B pronoun_type         from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B rank_lex             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B rank_occ             from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.01s B sentence_atom_number from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.13s B state                from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B stem                 from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.04s B subphrase_kind       from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.03s B subphrase_type       from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B suffix_gender        from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.13s B suffix_number        from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B suffix_person        from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.12s B tense                from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.19s B text_plain           from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.02s B text_type            from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.01s B verse_label          from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.14s B vocalized_lexeme     from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.19s B vocalized_lexeme_utf8 from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.09s B word_number_within_book from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.00s Feature overview: 115 for nodes; 2 for edges; 1 configs; 7 computed\n",
      "  7.85s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile standard TF features')\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('')\n",
    "\n",
    "utils.caption(4, 'Load and compile all other TF features')\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     10m 05s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     10m 05s First verse in all formats                                                     .\n",
      "..............................................................................................\n",
      "text-orig-plain\n",
      "\tבראשׁית ברא אלהימ את השׁמימ ואת הארצ׃\n",
      "lex-trans-plain\n",
      "\tB R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "lex-orig-full\n",
      "\tבְּ רֵאשִׁ֖י בָּרָ֣א אֱלֹה אֵ֥ת הַ שָּׁמ וְ אֵ֥ת הָ אָֽרֶץ \n",
      "lex-orig-plain\n",
      "\tב ראשׁית ברא אלהימ את ה שׁמימ ו את ה ארצ \n",
      "lex-trans-full\n",
      "\tB.:- R;>CI73J B.@R@74> >:ELOH >;71T HA- C.@M W:- >;71T H@- >@75REy \n",
      "text-trans-full\n",
      "\tB.:- R;>CI73JT B.@R@74> >:ELOHI92Jm >;71T HA- C.@MA73JIm W:- >;71T H@- >@75REy00 \n",
      "text-trans-plain\n",
      "\tB R>CJT BR> >LHJM >T H CMJM W >T H >RY \n",
      "text-orig-full\n",
      "\tבְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Basic test')\n",
    "utils.caption(4, 'First verse in all formats')\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, '{}'.format(fmt), continuation=True)\n",
    "    utils.caption(0, '\\t{}'.format(T.text(range(1,12), fmt=fmt)), continuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ADJ` `ATR` `DEM` `MOD` `PAR` `REG` `adj` `atr` `dem` `mod` `par` `rec`\n"
     ]
    }
   ],
   "source": [
    "f = 'subphrase_type'\n",
    "print('`' + '` `'.join(sorted(str(x[0]) for x in Fs(f).freqList())) + '`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
