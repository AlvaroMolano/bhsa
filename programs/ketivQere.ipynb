{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "# Ketiv Qere\n",
    "\n",
    "This notebook can read ketiv-qere info in files issued by the etcbc and transform them \n",
    "into new features.\n",
    "There will be new features at the word level.\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "There are already `qere` and `qere_utf8` features in the MQL of the core data.\n",
    "However, there are several problems with those:\n",
    "\n",
    "* features that contain the after-word material, `qere_trailer` and `qere_trailer_utf8`\n",
    "  are missing;\n",
    "* if there is no qere, both features are filled with the mepty string.\n",
    "  In this way we can make no distinction between a truly empty qere and the absence of a qere.\n",
    "\n",
    "That is why we reconstruct ketiv and qere from special files that are used by the ETCBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.transcription import Transcription\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION= 'c'\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeature = 'qere_trailer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(None, '{}/.tf/{}.tfx'.format(thisTf, testFeature), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material, \n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    " \n",
    "We do not do this for the older versions 4 and 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s New text formats\n",
      "|       0.00s fmt:text-orig-full             = \"{qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\"\n",
      "|       0.00s fmt:text-orig-full-ketiv       = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|       0.00s fmt:text-trans-full            = \"{qere/g_word}{qere_trailer/trailer}\"\n",
      "|       0.00s fmt:text-trans-full-ketiv      = \"{g_word}{trailer}\"\n"
     ]
    }
   ],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset='BHSA',\n",
    "    version=VERSION,\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    'c': '''\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}''',\n",
    "    '2016': '''\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}''',\n",
    "}\n",
    "    \n",
    "thisOtext = oText.get(VERSION, '')\n",
    "\n",
    "if thisOtext is '':\n",
    "    utils.caption(0, 'No additional text formats provided')\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, 'New text formats')\n",
    "    otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip('\\n').split('\\n'))\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '{:<30} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.01s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "101 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.16s B g_cons               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.22s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.10s B trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s B label                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 96 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  5.53s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load the existing TF dataset')\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('label g_word g_cons trailer_utf8')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse labels\n",
    "The ketiv-qere files deal with different verse labels.\n",
    "We make a mapping between verse labels and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.57s Mapping between verse labels and verse nodes\n",
      "|       5.61s 23213 verses\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Mapping between verse labels and verse nodes')\n",
    "nodeFromLabel = {}\n",
    "for vs in F.otype.s('verse'):\n",
    "    lab = F.label.v(vs)\n",
    "    nodeFromLabel[lab] = vs\n",
    "utils.caption(0, '{} verses'.format(len(nodeFromLabel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Ketiv-Qere file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       5.67s Parsing Ketiv-Qere data                                                        .\n",
      "..............................................................................................\n",
      "|       5.72s \tRead 1892 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Parsing Ketiv-Qere data')\n",
    "\n",
    "verseInfo = collections.defaultdict(lambda: [])\n",
    "notFound = set()\n",
    "missing = collections.defaultdict(lambda: [])\n",
    "missed = collections.defaultdict(lambda: [])\n",
    "\n",
    "error_limit = 10\n",
    "\n",
    "kqFile = '{}/ketivqere.txt'.format(thisSource)\n",
    "kqHandle = open(kqFile)\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "cur_label = None\n",
    "for line in kqHandle:\n",
    "    ln += 1\n",
    "    can += 1\n",
    "    vlab = line[0:10]\n",
    "    fields = line.rstrip('\\n')[10:].split()\n",
    "    (ketiv, qere) = fields[0:2]\n",
    "    (qtrim, qtrailer) = Transcription.suffix_and_finales(qere)\n",
    "    vnode = nodeFromLabel.get(vlab, None)\n",
    "    if vnode == None:\n",
    "        notFound.add(vlab)\n",
    "        continue\n",
    "    verseInfo[vnode].append((ketiv, qtrim, qtrailer))        \n",
    "kqHandle.close()\n",
    "utils.caption(0, '\\tRead {} ketiv-qere annotations'.format(ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.86s \tParsed 1892 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for vnode in verseInfo:\n",
    "    wlookup = collections.defaultdict(lambda: [])\n",
    "    wvisited = collections.defaultdict(lambda: -1)\n",
    "    wnodes = L.d(vnode, otype='word')\n",
    "    for w in wnodes:\n",
    "        gw = F.g_word.v(w)\n",
    "        if '*' in gw:\n",
    "            gw = F.g_cons.v(w)\n",
    "            if gw == '': gw = '.'\n",
    "            if F.trailer_utf8.v(w) == '': gw += '-'\n",
    "            wlookup[gw].append(w)\n",
    "    for (ketiv, qere, qtrailer) in verseInfo[vnode]:\n",
    "        wvisited[ketiv] += 1\n",
    "        windex = wvisited[ketiv]\n",
    "        ws = wlookup.get(ketiv, None)\n",
    "        if ws == None or windex > len(ws) - 1:\n",
    "            missing[vnode].append((windex, ketiv, qere))\n",
    "            continue\n",
    "        w = ws[windex]\n",
    "        qereU = Transcription.to_hebrew(qere)\n",
    "        qtrailerU = Transcription.to_hebrew(qtrailer)\n",
    "        data.append((\n",
    "            w,\n",
    "            ketiv,\n",
    "            qere,\n",
    "            qtrailer.replace('\\n', ''),\n",
    "            qereU,\n",
    "            qtrailerU.replace('\\n', ''),\n",
    "        ))\n",
    "    for ketiv in wlookup:\n",
    "        if ketiv not in wvisited or len(wlookup[ketiv]) - 1 > wvisited[ketiv]:\n",
    "            missed[vnode].append((len(wlookup[ketiv]) - (wvisited.get(ketiv, -1) + 1), ketiv))\n",
    "utils.caption(0, '\\tParsed {} ketiv-qere annotations'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297571, '<NWJ', '<:ANIJ.;J', '&', 'עֲנִיֵּי', '־')\n",
      "(297646, 'W-', 'W:', '', 'וְ', '')\n",
      "(297647, 'NCQH', 'NIC:Q:<@73H', ' ', 'נִשְׁקְעָ֖ה', ' ')\n",
      "(297937, 'M<LWTW', 'MA<:ALOWT@80JW', ' ', 'מַעֲלֹותָ֔יו', ' ')\n",
      "(370147, 'M>WM', 'MW.m04', ' ', 'מוּם֩', ' ')\n",
      "(370611, 'L-', 'L:', '', 'לְ', '')\n",
      "(370612, '<BDJK', '<AB:D@73k:', ' ', 'עַבְדָ֖ךְ', ' ')\n",
      "(370620, 'L-', 'L:', '', 'לְ', '')\n",
      "(370621, 'KFDJ>', 'KAF:D.@>;80J', ' ', 'כַשְׂדָּאֵ֔י', ' ')\n",
      "(370703, 'HZMNTWN', 'HIZ:D.:MIN:T.W.n03', ' ', 'הִזְדְּמִנְתּוּן֙', ' ')\n"
     ]
    }
   ],
   "source": [
    "if not SCRIPT:\n",
    "    print('\\n'.join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.93s \tAll verses entries found in index\n",
      "|       5.93s \tAll ketivs found in the text\n",
      "|       5.93s \tAll ketivs found in the data\n"
     ]
    }
   ],
   "source": [
    "if notFound:\n",
    "    utils.caption(0, '\\tWARNING: Could not find {} verses: {}'.format(len(notFound), sorted(notFound)))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll verses entries found in index')\n",
    "if missing:\n",
    "    utils.caption(0, '\\tWARNING: Could not locate ketivs in the text: {} verses'.format(len(missing)))\n",
    "    e = 0\n",
    "    for vnode in sorted(missing):\n",
    "        if e > error_limit: break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv, qere) in missing[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit: break\n",
    "            utils.caption(0, '\\t\\tNOT IN TEXT: {:<10} {:<20} #{} {}'.format(vlab, ketiv, windex, qere))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll ketivs found in the text')\n",
    "if missed:\n",
    "    utils.caption(0, '\\tCould not lookup qeres in the data: {} verses'.format(len(missed)))\n",
    "    e = 0\n",
    "    for vnode in sorted(missed):\n",
    "        if e > error_limit: break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv) in missed[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit: break\n",
    "            utils.caption(0, '\\t\\tNOT IN DATA: {:<10} {:<20} #{}'.format(vlab, ketiv, windex))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll ketivs found in the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features\n",
    "\n",
    "We now collect the lexical information into the features for nodes of type `lex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.95s Prepare TF ketiv qere features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Prepare TF ketiv qere features')\n",
    "\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = '''\n",
    "    qere\n",
    "    qere_trailer\n",
    "    qere_utf8\n",
    "    qere_trailer_utf8\n",
    "'''.strip().split()\n",
    "\n",
    "nodeFeatures = dict( \n",
    "    qere=dict(((x[0], x[2]) for x in data)),\n",
    "    qere_trailer=dict(((x[0], x[3]) for x in data)),\n",
    "    qere_utf8=dict(((x[0], x[4]) for x in data)),\n",
    "    qere_trailer_utf8=dict(((x[0], x[5]) for x in data))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `otext` feature with new/changed formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       5.97s Update the otext feature\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Update the otext feature')\n",
    "\n",
    "metaData = {}\n",
    "\n",
    "metaData['otext'] = dict()\n",
    "metaData['otext'].update(T.config)\n",
    "metaData['otext'].update(otextInfo)\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f].update(provenanceMetadata)\n",
    "    metaData[f]['valueType'] = 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changedDataFeatures = set(nodeFeatures)\n",
    "changedFeatures = changedDataFeatures | {'otext'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write new features\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       6.00s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n",
      "   |     0.01s T qere                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.01s T qere_trailer         to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.01s T qere_trailer_utf8    to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.01s T qere_utf8            to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'write new/changed features to TF ...')\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       6.06s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|       6.07s \t2 features to add\n",
      "|       6.07s \t\tqere_trailer\n",
      "|       6.07s \t\tqere_trailer_utf8\n",
      "|       6.07s \tno features to delete\n",
      "|       6.07s \t3 features in common\n",
      "|       6.07s otext                     ... differences\n",
      "|       6.07s \tline      5 OLD -->@dateWritten=2017-10-03T05:39:09Z<--\n",
      "|       6.07s \tline      5 NEW -->@dateWritten=2017-10-03T05:43:50Z<--\n",
      "|       6.07s \tline     12 OLD -->@fmt:text-orig-full={g_word_utf8}{traile ...<--\n",
      "|       6.07s \tline     12 NEW -->@fmt:text-orig-full={qere_utf8/g_word_ut ...<--\n",
      "|       6.07s \tline     13 OLD -->@fmt:text-orig-plain={g_cons_utf8}{trail ...<--\n",
      "|       6.07s \tline     13 NEW -->@fmt:text-orig-full-ketiv={g_word_utf8}{ ...<--\n",
      "|       6.07s \tline     14 OLD -->@fmt:text-trans-full={g_word}{trailer}<--\n",
      "|       6.07s \tline     14 NEW -->@fmt:text-orig-plain={g_cons_utf8}{trail ...<--\n",
      "\n",
      "|       6.07s qere                      ... differences after the metadata\n",
      "|       6.11s \tline      2 OLD --><--\n",
      "|       6.11s \tline      2 NEW -->3897\tHAJ:Y;74><--\n",
      "|       6.11s \tline      3 OLD --><--\n",
      "|       6.11s \tline      3 NEW -->4420\t>@H:@LO75W<--\n",
      "|       6.11s \tline      4 OLD --><--\n",
      "|       6.11s \tline      4 NEW -->5645\t>@H:@LO92W<--\n",
      "|       6.11s \tline      5 OLD --><--\n",
      "|       6.11s \tline      5 NEW -->5912\t>@95H:@LOW03<--\n",
      "\n",
      "|       6.11s qere_utf8                 ... differences after the metadata\n",
      "|       6.14s \tline      2 OLD --><--\n",
      "|       6.14s \tline      2 NEW -->3897\tהַיְצֵ֣א<--\n",
      "|       6.14s \tline      3 OLD --><--\n",
      "|       6.14s \tline      3 NEW -->4420\tאָהֳלֹֽו<--\n",
      "|       6.14s \tline      4 OLD --><--\n",
      "|       6.14s \tline      4 NEW -->5645\tאָהֳלֹ֑ו<--\n",
      "|       6.14s \tline      5 OLD --><--\n",
      "|       6.14s \tline      5 NEW -->5912\tאָֽהֳלֹו֙<--\n",
      "\n",
      "|       6.14s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       6.15s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/c                         .\n",
      "..............................................................................................\n",
      "|       6.15s \tqere\n",
      "|       6.15s \tqere_trailer\n",
      "|       6.16s \tqere_utf8\n",
      "|       6.16s \totext\n",
      "|       6.16s \tqere_trailer_utf8\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       6.17s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "103 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.18s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.25s B g_word_utf8          from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s T qere                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s T qere_trailer         from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s T qere_trailer_utf8    from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.01s T qere_utf8            from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.09s B trailer              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.10s B trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s M otext                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |      |     0.09s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s Feature overview: 98 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  5.57s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile the new TF features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('g_word_utf8 g_word trailer_utf8 trailer {}'.format(' '.join(changedDataFeatures)))\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         12s Basic tests                                                                    .\n",
      "..............................................................................................\n",
      "|         12s absence of qere               : NA WA J.I45C:T.AX:AW.75W. NA NA NA NA NA NA NA\n",
      "|         12s presence of qere trailer      : NA NA &   NA\n",
      "..............................................................................................\n",
      ".         12s Joshua 15:53 in all formats                                                    .\n",
      "..............................................................................................\n",
      "|         12s text-orig-plain                וינים ובית תפוח ואפקה׃ \n",
      "|         12s text-orig-full                 וְיָנ֥וּם וּבֵית־תַּפּ֖וּחַ וַאֲפֵֽקָה׃ \n",
      "|         12s lex-orig-plain                 ו ינום ו בית תפוח ו אפקה \n",
      "|         12s lex-orig-full                  ו ינים וּ בֵית תַּפּוּחַ וַ אֲפֵקָה \n",
      "|         12s text-orig-full-ketiv           וינים וּבֵית־תַּפּ֖וּחַ וַאֲפֵֽקָה׃ \n",
      "|         12s text-trans-full-ketiv          *W-*JNJM W.-B;JT&T.AP.73W.XA WA->:AP;75Q@H00 \n",
      "|         12s text-trans-full                W:J@N71W.m W.-B;JT&T.AP.73W.XA WA->:AP;75Q@H00 \n",
      "|         12s lex-trans-plain                TC</ TC</ TC</ TC</ TC</ TC</ \n",
      "|         12s lex-trans-full                 W- JNJM W.- B;JT_T.AP.W.XA WA- >:AP;Q@H \n",
      "|         12s text-trans-plain               WJNJM WBJT_TPWX W>PQH00 \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Basic tests')\n",
    "\n",
    "def showKq(w):\n",
    "    hw = F.g_word_utf8.v(w)\n",
    "    tw = F.g_word.v(w)\n",
    "    ht = F.trailer_utf8.v(w)\n",
    "    tt = F.trailer.v(w)\n",
    "    \n",
    "    qhw = F.qere_utf8.v(w)\n",
    "    qtw = F.qere.v(w)\n",
    "    qht = F.qere_trailer_utf8.v(w)\n",
    "    qtt = F.qere_trailer.v(w)\n",
    "    \n",
    "    utils.caption(0, '{:<20} {}'.format('hebrew', hw + ht))\n",
    "    utils.caption(0, '{:<20} {}'.format('hebrew qere', qhw + qht))\n",
    "    utils.caption(0, '{:<20} {}'.format('transcription', tw + tt))\n",
    "    utils.caption(0, '{:<20} {}'.format('transcription qere', qtw + qtt))\n",
    "    \n",
    "utils.caption(0, '{:<30}: {}'.format(\n",
    "    'absence of qere',\n",
    "    ' '.join('NA' if F.qere.v(w) == None else F.qere.v(w) for w in (range(24700,24710))),\n",
    "))\n",
    "utils.caption(0, '{:<30}: {}'.format(\n",
    "    'presence of qere trailer',\n",
    "    ' '.join('NA' if F.qere_trailer.v(w) == None else F.qere_trailer.v(w) for w in (range(30190,30195))),\n",
    "))\n",
    "\n",
    "showNode = L.u(122073, otype='verse')[0]\n",
    "showVerse = T.sectionFromNode(showNode)\n",
    "\n",
    "utils.caption(4, '{} {}:{} in all formats'.format(*showVerse))\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, '{:<30} {}'.format(fmt, T.text(L.d(showNode, otype='word'), fmt=fmt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
