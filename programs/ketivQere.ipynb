{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Ketiv Qere\n",
    "\n",
    "This notebook can read ketiv-qere info in files issued by the etcbc and transform them \n",
    "into new features.\n",
    "There will be new features at the word level.\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "There are already `qere` and `qere_utf8` features in the MQL of the core data.\n",
    "However, there are several problems with those:\n",
    "\n",
    "* features that contain the after-word material, `qere_trailer` and `qere_trailer_utf8`\n",
    "  are missing;\n",
    "* if there is no qere, both features are filled with the mepty string.\n",
    "  In this way we can make no distinction between a truly empty qere and the absence of a qere.\n",
    "\n",
    "That is why we reconstruct ketiv and qere from special files that are used by the ETCBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.transcription import Transcription\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION= 'c'\n",
    "    CORE_MODULE ='core' \n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "module = CORE_MODULE\n",
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisSave = '{}/{}'.format(thisTemp, module)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)\n",
    "thisDeliver = '{}/{}'.format(thisTf, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeature = 'qere_trailer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(None, '{}/.tf/{}.tfx'.format(thisDeliver, testFeature), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material, \n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    " \n",
    "We do not do this for the older versions 4 and 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s New text formats\n",
      "|       0.00s fmt:text-orig-full             = \"{qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\"\n",
      "|       0.00s fmt:text-orig-full-ketiv       = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|       0.00s fmt:text-trans-full            = \"{qere/g_word}{qere_trailer/trailer}\"\n",
      "|       0.00s fmt:text-trans-full-ketiv      = \"{g_word}{trailer}\"\n"
     ]
    }
   ],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset='BHSA',\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    'c': '''\n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}''',\n",
    "}\n",
    "\n",
    "thisOtext = oText.get(VERSION, '')\n",
    "otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip('\\n').split('\\n'))\n",
    "\n",
    "if thisOtext is '':\n",
    "    utils.caption(0, 'No additional text formats provided') \n",
    "else:\n",
    "    utils.caption(0, 'New text formats')\n",
    "for x in sorted(otextInfo.items()):\n",
    "    utils.caption(0, '{:<30} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       3.85s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "99 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.12s B g_cons               from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.14s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.10s B trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.01s B label                from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.00s Feature overview: 94 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  4.42s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load the existing TF dataset')\n",
    "TF = Fabric(locations=thisTf, modules=module)\n",
    "api = TF.load('label g_word g_cons trailer_utf8')\n",
    "F = api.F\n",
    "Fs = api.Fs\n",
    "T = api.T\n",
    "L = api.L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verse labels\n",
    "The ketiv-qere files deal with different verse labels.\n",
    "We make a mapping between verse labels and nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       9.99s Mapping between verse labels and verse nodes\n",
      "|         10s 23213 verses\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Mapping between verse labels and verse nodes')\n",
    "nodeFromLabel = {}\n",
    "for vs in F.otype.s('verse'):\n",
    "    lab = F.label.v(vs)\n",
    "    nodeFromLabel[lab] = vs\n",
    "utils.caption(0, '{} verses'.format(len(nodeFromLabel)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Ketiv-Qere file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         13s Parsing Ketiv-Qere data                                                        .\n",
      "..............................................................................................\n",
      "|         13s \tRead 1892 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Parsing Ketiv-Qere data')\n",
    "\n",
    "verseInfo = collections.defaultdict(lambda: [])\n",
    "notFound = set()\n",
    "missing = collections.defaultdict(lambda: [])\n",
    "missed = collections.defaultdict(lambda: [])\n",
    "\n",
    "error_limit = 10\n",
    "\n",
    "kqFile = '{}/ketivqere.txt'.format(thisSource)\n",
    "kqHandle = open(kqFile)\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "cur_label = None\n",
    "for line in kqHandle:\n",
    "    ln += 1\n",
    "    can += 1\n",
    "    vlab = line[0:10]\n",
    "    fields = line.rstrip('\\n')[10:].split()\n",
    "    (ketiv, qere) = fields[0:2]\n",
    "    (qtrim, qtrailer) = Transcription.suffix_and_finales(qere)\n",
    "    vnode = nodeFromLabel.get(vlab, None)\n",
    "    if vnode == None:\n",
    "        notFound.add(vlab)\n",
    "        continue\n",
    "    verseInfo[vnode].append((ketiv, qtrim, qtrailer))        \n",
    "kqHandle.close()\n",
    "utils.caption(0, '\\tRead {} ketiv-qere annotations'.format(ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         17s \tParsed 1892 ketiv-qere annotations\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for vnode in verseInfo:\n",
    "    wlookup = collections.defaultdict(lambda: [])\n",
    "    wvisited = collections.defaultdict(lambda: -1)\n",
    "    wnodes = L.d(vnode, otype='word')\n",
    "    for w in wnodes:\n",
    "        gw = F.g_word.v(w)\n",
    "        if '*' in gw:\n",
    "            gw = F.g_cons.v(w)\n",
    "            if gw == '': gw = '.'\n",
    "            if F.trailer_utf8.v(w) == '': gw += '-'\n",
    "            wlookup[gw].append(w)\n",
    "    for (ketiv, qere, qtrailer) in verseInfo[vnode]:\n",
    "        wvisited[ketiv] += 1\n",
    "        windex = wvisited[ketiv]\n",
    "        ws = wlookup.get(ketiv, None)\n",
    "        if ws == None or windex > len(ws) - 1:\n",
    "            missing[vnode].append((windex, ketiv, qere))\n",
    "            continue\n",
    "        w = ws[windex]\n",
    "        qereU = Transcription.to_hebrew(qere)\n",
    "        qtrailerU = Transcription.to_hebrew(qtrailer)\n",
    "        data.append((\n",
    "            w,\n",
    "            ketiv,\n",
    "            qere,\n",
    "            qtrailer.replace('\\n', ''),\n",
    "            qereU,\n",
    "            qtrailerU.replace('\\n', ''),\n",
    "        ))\n",
    "    for ketiv in wlookup:\n",
    "        if ketiv not in wvisited or len(wlookup[ketiv]) - 1 > wvisited[ketiv]:\n",
    "            missed[vnode].append((len(wlookup[ketiv]) - (wvisited.get(ketiv, -1) + 1), ketiv))\n",
    "utils.caption(0, '\\tParsed {} ketiv-qere annotations'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not SCRIPT:\n",
    "    print('\\n'.join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         22s \tAll verses entries found in index\n",
      "|         22s \tAll ketivs found in the text\n",
      "|         22s \tAll ketivs found in the data\n"
     ]
    }
   ],
   "source": [
    "if notFound:\n",
    "    utils.caption(0, '\\tWARNING: Could not find {} verses: {}'.format(len(notFound), sorted(notFound)))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll verses entries found in index')\n",
    "if missing:\n",
    "    utils.caption(0, '\\tWARNING: Could not locate ketivs in the text: {} verses'.format(len(missing)))\n",
    "    e = 0\n",
    "    for vnode in sorted(missing):\n",
    "        if e > error_limit: break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv, qere) in missing[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit: break\n",
    "            utils.caption(0, '\\t\\tNOT IN TEXT: {:<10} {:<20} #{} {}'.format(vlab, ketiv, windex, qere))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll ketivs found in the text')\n",
    "if missed:\n",
    "    utils.caption(0, '\\tCould not lookup qeres in the data: {} verses'.format(len(missed)))\n",
    "    e = 0\n",
    "    for vnode in sorted(missed):\n",
    "        if e > error_limit: break\n",
    "        vlab = F.label.v(vnode)\n",
    "        for (windex, ketiv) in missed[vnode]:\n",
    "            e += 1\n",
    "            if e > error_limit: break\n",
    "            utils.caption(0, '\\t\\tNOT IN DATA: {:<10} {:<20} #{}'.format(vlab, ketiv, windex))\n",
    "else:\n",
    "    utils.caption(0, '\\tAll ketivs found in the data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features\n",
    "\n",
    "We now collect the lexical information into the features for nodes of type `lex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         37s Prepare TF ketiv qere features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Prepare TF ketiv qere features')\n",
    "\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = '''\n",
    "    qere\n",
    "    qere_trailer\n",
    "    qere_utf8\n",
    "    qere_trailer_utf8\n",
    "'''.strip().split()\n",
    "\n",
    "nodeFeatures = dict( \n",
    "    qere=dict(((x[0], x[2]) for x in data)),\n",
    "    qere_trailer=dict(((x[0], x[3]) for x in data)),\n",
    "    qere_utf8=dict(((x[0], x[4]) for x in data)),\n",
    "    qere_trailer_utf8=dict(((x[0], x[5]) for x in data))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update the `otext` feature with new/changed formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         48s Update the otext feature\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Update the otext feature')\n",
    "\n",
    "metaData = {}\n",
    "\n",
    "metaData['otext'] = dict()\n",
    "metaData['otext'].update(T.config)\n",
    "metaData['otext'].update(otextInfo)\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f].update(provenanceMetadata)\n",
    "    metaData[f]['valueType'] = 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changedDataFeatures = set(nodeFeatures)\n",
    "changedFeatures = changedDataFeatures | {'otext'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: TF generation\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         56s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n",
      "   |     0.01s T qere                 to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n",
      "   |     0.01s T qere_trailer         to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n",
      "   |     0.01s T qere_trailer_utf8    to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n",
      "   |     0.01s T qere_utf8            to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'write new/changed features to TF ...')\n",
    "TF = Fabric(locations=thisSave, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     37m 26s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     37m 26s \t2 features to add\n",
      "|     37m 26s \t\tqere_trailer\n",
      "|     37m 26s \t\tqere_trailer_utf8\n",
      "|     37m 26s \tno features to delete\n",
      "|     37m 26s \t3 features in common\n",
      "|     37m 26s otext                     ... no changes\n",
      "|     37m 26s qere                      ... differencesafter the metadata\n",
      "|     37m 27s \tline      2 OLD --><--\n",
      "|     37m 27s \tline      2 NEW -->3897\tHAJ:Y;74><--\n",
      "|     37m 27s \tline      3 OLD --><--\n",
      "|     37m 27s \tline      3 NEW -->4420\t>@H:@LO75W<--\n",
      "|     37m 27s \tline      4 OLD --><--\n",
      "|     37m 27s \tline      4 NEW -->5645\t>@H:@LO92W<--\n",
      "|     37m 27s \tline      5 OLD --><--\n",
      "|     37m 27s \tline      5 NEW -->5912\t>@95H:@LOW03<--\n",
      "\n",
      "|     37m 27s qere_utf8                 ... differencesafter the metadata\n",
      "|     37m 27s \tline      2 OLD --><--\n",
      "|     37m 27s \tline      2 NEW -->3897\tהַיְצֵ֣א<--\n",
      "|     37m 27s \tline      3 OLD --><--\n",
      "|     37m 27s \tline      3 NEW -->4420\tאָהֳלֹֽו<--\n",
      "|     37m 27s \tline      4 OLD --><--\n",
      "|     37m 27s \tline      4 NEW -->5645\tאָהֳלֹ֑ו<--\n",
      "|     37m 27s \tline      5 OLD --><--\n",
      "|     37m 27s \tline      5 NEW -->5912\tאָֽהֳלֹו֙<--\n",
      "\n",
      "|     37m 27s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisSave, thisDeliver, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     16m 23s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/c/core                    .\n",
      "..............................................................................................\n",
      "|     16m 23s \tqere_utf8\n",
      "|     16m 23s \tqere\n",
      "|     16m 23s \totext\n",
      "|     16m 23s \tqere_trailer_utf8\n",
      "|     16m 23s \tqere_trailer\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisSave, thisDeliver, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     17m 48s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "101 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.14s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.21s B g_word_utf8          from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.01s T qere                 from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.01s T qere_trailer         from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.01s T qere_trailer_utf8    from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.02s T qere_utf8            from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.08s B trailer              from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.08s B trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.00s M otext                from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |      |     0.09s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s Feature overview: 96 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  4.39s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile the new TF features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=module)\n",
    "api = TF.load('g_word_utf8 g_word trailer_utf8 trailer {}'.format(' '.join(changedDataFeatures)))\n",
    "F = api.F\n",
    "Fs = api.Fs\n",
    "T = api.T\n",
    "L = api.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     47m 48s Basic tests                                                                    .\n",
      "..............................................................................................\n",
      "|     47m 48s absence of qere               : NA WA J.I45C:T.AX:AW.75W. NA NA NA NA NA NA NA\n",
      "|     47m 48s presence of qere trailer      : NA NA &   NA\n",
      "..............................................................................................\n",
      ".     47m 48s Joshua 15:53 in all formats                                                    .\n",
      "..............................................................................................\n",
      "|     47m 48s lex-orig-full                  ו ינים וּ בֵית תַּפּוּחַ וַ אֲפֵקָה \n",
      "|     47m 48s text-trans-full                W:J@N71W.m W.-B;JT&T.AP.73W.XA WA->:AP;75Q@H00 \n",
      "|     47m 48s text-orig-full                 וְיָנ֥וּם וּבֵית־תַּפּ֖וּחַ וַאֲפֵֽקָה׃ \n",
      "|     47m 48s lex-trans-full                 W- JNJM W.- B;JT_T.AP.W.XA WA- >:AP;Q@H \n",
      "|     47m 48s lex-trans-plain                TC</ TC</ TC</ TC</ TC</ TC</ \n",
      "|     47m 48s text-trans-plain               WJNJM WBJT_TPWX W>PQH00 \n",
      "|     47m 48s text-trans-full-ketiv          *W-*JNJM W.-B;JT&T.AP.73W.XA WA->:AP;75Q@H00 \n",
      "|     47m 48s text-orig-full-ketiv           וינים וּבֵית־תַּפּ֖וּחַ וַאֲפֵֽקָה׃ \n",
      "|     47m 48s text-orig-plain                וינים ובית תפוח ואפקה׃ \n",
      "|     47m 48s lex-orig-plain                 ו ינום ו בית תפוח ו אפקה \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Basic tests')\n",
    "\n",
    "def showKq(w):\n",
    "    hw = F.g_word_utf8.v(w)\n",
    "    tw = F.g_word.v(w)\n",
    "    ht = F.trailer_utf8.v(w)\n",
    "    tt = F.trailer.v(w)\n",
    "    \n",
    "    qhw = F.qere_utf8.v(w)\n",
    "    qtw = F.qere.v(w)\n",
    "    qht = F.qere_trailer_utf8.v(w)\n",
    "    qtt = F.qere_trailer.v(w)\n",
    "    \n",
    "    utils.caption(0, '{:<20} {}'.format('hebrew', hw + ht))\n",
    "    utils.caption(0, '{:<20} {}'.format('hebrew qere', qhw + qht))\n",
    "    utils.caption(0, '{:<20} {}'.format('transcription', tw + tt))\n",
    "    utils.caption(0, '{:<20} {}'.format('transcription qere', qtw + qtt))\n",
    "    \n",
    "utils.caption(0, '{:<30}: {}'.format(\n",
    "    'absence of qere',\n",
    "    ' '.join('NA' if F.qere.v(w) == None else F.qere.v(w) for w in (range(24700,24710))),\n",
    "))\n",
    "utils.caption(0, '{:<30}: {}'.format(\n",
    "    'presence of qere trailer',\n",
    "    ' '.join('NA' if F.qere_trailer.v(w) == None else F.qere_trailer.v(w) for w in (range(30190,30195))),\n",
    "))\n",
    "\n",
    "showNode = L.u(122073, otype='verse')[0]\n",
    "showVerse = T.sectionFromNode(showNode)\n",
    "\n",
    "utils.caption(4, '{} {}:{} in all formats'.format(*showVerse))\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, '{:<30} {}'.format(fmt, T.text(L.d(showNode, otype='word'), fmt=fmt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
