{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# TF from MQL\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the [BHSA](https://github.com/ETCBC/bhsa) Hebrew Text Database\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/ETCBC/text-fabric)\n",
    "resource.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The principled way of going about such a conversion is to import the MQL source into\n",
    "an [Emdros](https://emdros.org) database, and use it to retrieve objects and features from there.\n",
    "\n",
    "Because the syntax of an MQL file leaves some freedom, it is error prone to do a text-to-text conversion from\n",
    "MQL to something else.\n",
    "\n",
    "Yet this is what we do, the error-prone thing. We then avoid installing and configuring and managing Emdros, MySQL/sqLite3.\n",
    "Aside the upfront work to get this going, the going after that is also much slower.\n",
    "\n",
    "So here you are, a smallish script to do an awful lot of work, mostly correct, if careful used.\n",
    "\n",
    "# Caveat\n",
    "\n",
    "This notebook makes use of a new feature of text-fabric, first present in 2.3.12.\n",
    "Make sure to upgrade first.\n",
    "\n",
    "```sudo -H pip3 install text-fabric```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from glob import glob\n",
    "from shutil import rmtree, copytree\n",
    "from tf.fabric import Fabric\n",
    "from utils import bunzip, startNow, tprint\n",
    "from blang import bookLangs, bookNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "We pass the name of the data source, the version, and the name of a target TF module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SOURCE_NAME = 'x_etcbc'\n",
    "VERSION= '4b'\n",
    "TF_MODULE ='core' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "REPO_BASE = os.path.expanduser('~/github/bhsa')\n",
    "\n",
    "SOURCE_BASE = '{}/source'.format(REPO_BASE)\n",
    "TEMP_BASE = '{}/_temp'.format(REPO_BASE)\n",
    "TARGET_BASE = '{}/tf'.format(REPO_BASE)\n",
    "\n",
    "MQLZ_FILE = '{}/{}{}.mql.bz2'.format(SOURCE_BASE, SOURCE_NAME, VERSION)\n",
    "MQL_FILE = '{}/{}{}.mql'.format(TEMP_BASE, SOURCE_NAME, VERSION)\n",
    "\n",
    "TF_SAVE = '{}/{}/{}'.format(TEMP_BASE, VERSION, TF_MODULE)\n",
    "\n",
    "TF_LOCATION = '{}/{}'.format(TARGET_BASE, VERSION)\n",
    "TF_DELIVER = '{}/{}'.format(TF_LOCATION, TF_MODULE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the TF slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The OTEXT feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SLOT_TYPE = 'word'\n",
    "\n",
    "FEATURE_METADATA = dict(\n",
    "    dataset='BHSA',\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), Ulrik Petersen (MQL) and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")\n",
    "\n",
    "OTEXT = {\n",
    "    '': {\n",
    "        '': '''\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "@fmt:text-orig-full={g_word_utf8}{g_suffix_utf8}\n",
    "        ''',\n",
    "    },\n",
    "    'x_etcbc': {\n",
    "        '4': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "        ''',\n",
    "        '4b': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "        ''',\n",
    "        '4c': '''\n",
    "@config\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex0} \n",
    "@fmt:text-orig-full={qere_utf8/g_word_utf8}{qere_trailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={qere/g_word}{qere_trailer/trailer}\n",
    "@fmt:text-trans-full-ketiv={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "        ''',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper otext material, falling back on a default if nothing \n",
    "appropriate has been specified in `OTEXT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getOtext():\n",
    "    thisOtext = OTEXT.get(SOURCE_NAME, {}).get(VERSION, OTEXT[''][''])\n",
    "    otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip().split('\\n'))\n",
    "\n",
    "    if thisOtext is OTEXT['']['']:\n",
    "        print('WARNING: no otext feature info provided, using a meager default value') \n",
    "    else:\n",
    "        print('INFO: otext feature information found')\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        print('{:<20} = \"{}\"'.format(*x))\n",
    "    return otextInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program has two stages:\n",
    "   \n",
    "* parse the MQL and collect information in datastructures\n",
    "* transform the data structures and write them as TF features\n",
    "\n",
    "Both phases communicate with the help of several global variables:\n",
    "\n",
    "* data containers for the MQL kinds of data\n",
    "  * enumerations\n",
    "  * object types\n",
    "  * tables\n",
    "\n",
    "* data containers for the TF features to be generated,\n",
    "  * node features\n",
    "  * edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objectTypes = dict()\n",
    "tables = dict()\n",
    "\n",
    "edgeF = dict()\n",
    "nodeF = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the ground: check the source, bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare():\n",
    "    global thisOTEXT\n",
    "\n",
    "    presentMqlZ = os.path.exists(MQLZ_FILE)\n",
    "    presentMql = os.path.exists(MQL_FILE)\n",
    "    if not presentMqlZ and not presentMql:\n",
    "        print('MQL source file does not exist: {} or {}'.format(MQLZ_FILE, MQL_FILE))\n",
    "        sys.exit()\n",
    "    if presentMql: print('using existing bunzipped {}'.format(MQL_FILE))\n",
    "    else:\n",
    "        startNow()\n",
    "        tprint('bunzipping {} ...'.format(MQL_FILE))\n",
    "        bunzip(MQLZ_FILE, MQL_FILE)\n",
    "        tprint('Done')\n",
    "\n",
    "    if os.path.exists(TF_SAVE):\n",
    "        rmtree(TF_SAVE)\n",
    "        os.makedirs(TF_SAVE)\n",
    "\n",
    "    thisOTEXT = getOtext()\n",
    "\n",
    "    print('Ready to compile TF dataset\\n\\t{}\\nfrom MQL source\\n\\t{}'.format(TF_SAVE, MQL_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliver the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deliverDataset():\n",
    "    if os.path.exists(TF_DELIVER):\n",
    "        rmtree(TF_DELIVER)\n",
    "        copytree(TF_SAVE, TF_DELIVER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a monads specification (a comma separated sequence of numbers and number ranges)\n",
    "into a set of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def setFromSpec(spec):\n",
    "    covered = set()\n",
    "    for r_str in spec.split(','):\n",
    "        bounds = r_str.split('-')\n",
    "        if len(bounds) == 1:\n",
    "            covered.add(int(r_str))\n",
    "        else:\n",
    "            b = int(bounds[0])\n",
    "            e = int(bounds[1])\n",
    "            if (e < b): (b, e) = (e, b)\n",
    "            for n in range(b, e+1): covered.add(n)\n",
    "    return covered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: MQL parsing\n",
    "Plough through the MQL file and grab all relevant information\n",
    "and put it into the dedicated data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parseMql(fh):\n",
    "\n",
    "    startNow()\n",
    "    tprint('Parsing mql source ...')\n",
    "\n",
    "    curId = None\n",
    "    curEnum = None\n",
    "    curObjectType = None\n",
    "    curTable = None\n",
    "    curObject = None\n",
    "    curValue = None\n",
    "    curFeature = None\n",
    "\n",
    "    STRING_TYPES = {'ascii', 'string'}\n",
    "\n",
    "    enums = dict()\n",
    "\n",
    "    CHUNK_SIZE = 1000000\n",
    "    inThisChunk = 0\n",
    "\n",
    "    good = True\n",
    "\n",
    "    for (ln, line) in enumerate(fh):\n",
    "        inThisChunk += 1\n",
    "        if inThisChunk == CHUNK_SIZE:\n",
    "            tprint('\\tline {:>9}'.format(ln + 1))\n",
    "            inThisChunk = 0\n",
    "        if line.startswith('CREATE OBJECTS WITH OBJECT TYPE') or line.startswith('WITH OBJECT TYPE'):\n",
    "            comps = line.rstrip().rstrip(']').split('[', 1)\n",
    "            curTable = comps[1]\n",
    "            print('\\t\\tobjects in {}'.format(curTable))\n",
    "            curObject = None\n",
    "            if not curTable in tables:\n",
    "                tables[curTable] = dict()\n",
    "        elif curEnum != None:\n",
    "            if line.startswith('}'):\n",
    "                curEnum = None\n",
    "                continue\n",
    "            comps = line.strip().rstrip(',').split('=', 1)\n",
    "            comp = comps[0].strip()\n",
    "            words = comp.split()\n",
    "            if words[0] == 'DEFAULT':\n",
    "                enums[curEnum]['default'] = words[1]\n",
    "                value = words[1]\n",
    "            else:\n",
    "                value = words[0]\n",
    "            enums[curEnum]['values'].append(value)\n",
    "        elif curObjectType != None:\n",
    "            if line.startswith(']'):\n",
    "                curObjectType = None\n",
    "                continue\n",
    "            if curObjectType == True:\n",
    "                if line.startswith('['):\n",
    "                    curObjectType = line.rstrip()[1:]\n",
    "                    objectTypes[curObjectType] = dict()\n",
    "                    print('\\t\\totype {}'.format(curObjectType))\n",
    "                    continue\n",
    "            comps = line.strip().rstrip(';').split(':', 1)\n",
    "            feature = comps[0].strip()\n",
    "            fInfo = comps[1].strip()\n",
    "            fCleanInfo = fInfo.replace('FROM SET', '')\n",
    "            fInfoComps = fCleanInfo.split(' ', 1)\n",
    "            fMQLType = fInfoComps[0]\n",
    "            fDefault = fInfoComps[1].strip().split(' ', 1)[1] if len(fInfoComps) == 1 else None\n",
    "            if fDefault != None and fMQLType in STRING_TYPES:\n",
    "                fDefault = fDefault[1:-1]\n",
    "            default = enums.get(fMQLType, {}).get('default', fDefault)\n",
    "            ftype = 'str' if fMQLType in enums else\\\n",
    "                    'int' if fMQLType == 'integer' else\\\n",
    "                    'str' if fMQLType in STRING_TYPES else\\\n",
    "                    'int' if fInfo == 'id_d' else\\\n",
    "                    'str'\n",
    "            isEdge = fMQLType == 'id_d'\n",
    "            if isEdge:\n",
    "                edgeF.setdefault(curObjectType, set()).add(feature)\n",
    "            else:\n",
    "                nodeF.setdefault(curObjectType, set()).add(feature)\n",
    "\n",
    "            objectTypes[curObjectType][feature] = (ftype, default)\n",
    "            print('\\t\\t\\tfeature {} ({}) = {} : {}'.format(feature, ftype, default, 'edge' if isEdge else 'node'))\n",
    "        elif curTable != None:\n",
    "            if curObject != None:\n",
    "                if line.startswith(']'):\n",
    "                    objectType = objectTypes[curTable]\n",
    "                    for (feature, (ftype, default)) in objectType.items():\n",
    "                        if feature not in curObject['feats'] and default != None:\n",
    "                            curObject['feats'][feature] = default\n",
    "                    tables[curTable][curId] = curObject\n",
    "                    curObject = None\n",
    "                    continue\n",
    "                elif line.startswith('['):\n",
    "                    continue\n",
    "                elif line.startswith('FROM MONADS'):\n",
    "                    monads = line.split('=', 1)[1].replace('{', '').replace('}', '').replace(' ','').strip()\n",
    "                    curObject['monads'] = setFromSpec(monads)\n",
    "                elif line.startswith('WITH ID_D'):\n",
    "                    comps = line.replace('[', '').rstrip().split('=', 1)\n",
    "                    curId = int(comps[1])\n",
    "                elif line.startswith('GO'):\n",
    "                    continue\n",
    "                elif line.strip() == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    if curValue != None:\n",
    "                        toBeContinued = not line.rstrip().endswith('\";')\n",
    "                        if toBeContinued:\n",
    "                            curValue += line\n",
    "                        else:\n",
    "                            curValue += line.rstrip().rstrip(';').rstrip('\"')\n",
    "                            curObject['feats'][curFeature] = curValue\n",
    "                            curValue = None\n",
    "                            curFeature = None\n",
    "                        continue\n",
    "                    if ':=' in line:\n",
    "                        (featurePart, valuePart) = line.split('=', 1)\n",
    "                        feature = featurePart[0:-1].strip()\n",
    "                        isText = ':=\"' in line\n",
    "                        toBeContinued = isText and not line.rstrip().endswith('\";')\n",
    "                        if toBeContinued:\n",
    "                            # this happens if a feature value contains a new line\n",
    "                            # we must continue scanning lines until we meet the ned of the value\n",
    "                            curFeature = feature\n",
    "                            curValue = valuePart.lstrip('\"')\n",
    "                        else:\n",
    "                            value = valuePart.rstrip().rstrip(';').strip('\"')\n",
    "                            curObject['feats'][feature] = value\n",
    "                    else:\n",
    "                        tprint('ERROR: line {}: unrecognized line -->{}<--'.format(ln, line))\n",
    "                        good = False\n",
    "                        break\n",
    "            else:\n",
    "                if line.startswith('CREATE OBJECT'):\n",
    "                    curObject = dict(feats=dict(), monads=None)\n",
    "                    curId = None\n",
    "        else:\n",
    "            if line.startswith('CREATE ENUMERATION'):\n",
    "                words = line.split()\n",
    "                curEnum = words[2]\n",
    "                enums[curEnum] = dict(default=None, values=[])\n",
    "                print('\\t\\tenum {}'.format(curEnum))\n",
    "            elif line.startswith('CREATE OBJECT TYPE'):\n",
    "                curObjectType = True\n",
    "    tprint('{} lines parsed'.format(ln + 1))\n",
    "    for table in tables:\n",
    "        print('{} objects of type {}'.format(len(tables[table]), table))\n",
    "    return good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: TF generation\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tfFromData():\n",
    "    startNow()\n",
    "    tprint('Making TF data ...')\n",
    "    \n",
    "    NIL = {'nil', 'NIL', 'Nil'}\n",
    "\n",
    "    tableOrder = [SLOT_TYPE]+[t for t in sorted(tables) if t != SLOT_TYPE]\n",
    "\n",
    "    nodeFromIdd = dict()\n",
    "    iddFromNode = dict()\n",
    "\n",
    "    nodeFeatures = dict()\n",
    "    edgeFeatures = dict()\n",
    "    metaData = dict()\n",
    "\n",
    "    # metadata that ends up in every feature\n",
    "    metaData[''] = FEATURE_METADATA\n",
    "\n",
    "    # the config feature otext\n",
    "    metaData['otext'] = thisOTEXT\n",
    "\n",
    "    # multilingual book names\n",
    "    for (langCode, (langEnglish, langName)) in bookLangs.items():\n",
    "        metaData['book@{}'.format(langCode)] = {\n",
    "            'valueType': 'str',\n",
    "            'language': langName,\n",
    "            'languageCode': langCode,\n",
    "            'languageEnglish': langEnglish,\n",
    "        }\n",
    "\n",
    "    tprint('Monad - idd mapping ...')\n",
    "    otype = dict()\n",
    "    for idd in tables.get(SLOT_TYPE, {}):\n",
    "        monad = list(tables[SLOT_TYPE][idd]['monads'])[0]\n",
    "        nodeFromIdd[idd] = monad\n",
    "        iddFromNode[monad] = idd\n",
    "        otype[monad] = SLOT_TYPE\n",
    "\n",
    "    maxSlot = max(nodeFromIdd.values()) if len(nodeFromIdd) else 0\n",
    "    tprint('maxSlot={}'.format(maxSlot))\n",
    "\n",
    "    tprint('Node mapping and otype ...')\n",
    "    node = maxSlot\n",
    "    for t in tableOrder[1:]:\n",
    "        for idd in sorted(tables[t]):\n",
    "            node += 1\n",
    "            nodeFromIdd[idd] = node\n",
    "            iddFromNode[node] = idd\n",
    "            otype[node] = t\n",
    "\n",
    "    nodeFeatures['otype'] = otype\n",
    "    metaData['otype'] = dict(\n",
    "        valueType='str',\n",
    "    )\n",
    "\n",
    "    tprint('oslots ...')\n",
    "    oslots = dict()\n",
    "    for t in tableOrder[1:]:\n",
    "        for idd in tables.get(t, {}):\n",
    "            node = nodeFromIdd[idd]\n",
    "            monads = tables[t][idd]['monads']\n",
    "            oslots[node] = monads\n",
    "    edgeFeatures['oslots'] = oslots\n",
    "    metaData['oslots'] = dict(\n",
    "        valueType='str',\n",
    "    )\n",
    "\n",
    "    tprint('metadata ...')\n",
    "    for t in nodeF:\n",
    "        for f in nodeF[t]:\n",
    "            ftype = objectTypes[t][f][0]\n",
    "            metaData.setdefault(f, {})['valueType'] = ftype\n",
    "    for t in edgeF:\n",
    "        for f in edgeF[t]:\n",
    "            metaData.setdefault(f, {})['valueType'] = 'str'\n",
    "\n",
    "    tprint('features ...')\n",
    "    for t in tableOrder:\n",
    "        tprint('\\tfeatures from {}s'.format(t))\n",
    "        for idd in tables.get(t, {}):\n",
    "            node = nodeFromIdd[idd]\n",
    "            features = tables[t][idd]['feats']\n",
    "            for (f, v) in features.items():\n",
    "                isEdge = f in edgeF.get(t, set())\n",
    "                if isEdge:\n",
    "                    if v not in NIL:\n",
    "                        edgeFeatures.setdefault(f, {}).setdefault(node, set()).add(nodeFromIdd[int(v)])\n",
    "                else:\n",
    "                    nodeFeatures.setdefault(f, {})[node] = v\n",
    "\n",
    "\n",
    "    tprint('book names ...')\n",
    "    nodeFeatures['book@la'] = nodeFeatures.get('book', {})\n",
    "    bookNodes = sorted(nodeFeatures.get('book', {}))\n",
    "    for (langCode, langBookNames) in bookNames.items():\n",
    "        nodeFeatures['book@{}'.format(langCode)] = dict(zip(bookNodes, langBookNames))\n",
    "\n",
    "    tprint('write data set to TF ...')\n",
    "\n",
    "    TF = Fabric(locations=TF_SAVE)\n",
    "    TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing bunzipped /Users/dirk/github/bhsa/_temp/x_etcbc4b.mql\n",
      "INFO: otext feature information found\n",
      "fmt:lex-orig-full    = \"{g_lex_utf8} \"\n",
      "fmt:lex-orig-plain   = \"{lex_utf8} \"\n",
      "fmt:lex-trans-full   = \"{g_lex} \"\n",
      "fmt:lex-trans-plain  = \"{lex} \"\n",
      "fmt:text-orig-full   = \"{g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\"\n",
      "fmt:text-orig-full-ketiv = \"{g_word_utf8}{trailer_utf8}\"\n",
      "fmt:text-orig-plain  = \"{g_cons_utf8}{trailer_utf8}\"\n",
      "fmt:text-trans-full  = \"{g_word} \"\n",
      "fmt:text-trans-full-ketiv = \"{g_word} \"\n",
      "fmt:text-trans-plain = \"{g_cons} \"\n",
      "sectionFeatures      = \"book,chapter,verse\"\n",
      "sectionTypes         = \"book,chapter,verse\"\n",
      "Ready to compile TF dataset\n",
      "\t/Users/dirk/github/bhsa/_temp/4b/core\n",
      "from MQL source\n",
      "\t/Users/dirk/github/bhsa/_temp/x_etcbc4b.mql\n"
     ]
    }
   ],
   "source": [
    "prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.00s Parsing mql source ...\n",
      "\t\tenum boolean_t\n",
      "\t\tenum phrase_determination_t\n",
      "\t\tenum language_t\n",
      "\t\tenum book_name_t\n",
      "\t\tenum lexical_set_t\n",
      "\t\tenum verbal_stem_t\n",
      "\t\tenum verbal_tense_t\n",
      "\t\tenum person_t\n",
      "\t\tenum number_t\n",
      "\t\tenum gender_t\n",
      "\t\tenum state_t\n",
      "\t\tenum part_of_speech_t\n",
      "\t\tenum phrase_type_t\n",
      "\t\tenum phrase_atom_relation_t\n",
      "\t\tenum phrase_relation_t\n",
      "\t\tenum phrase_atom_unit_distance_to_mother_t\n",
      "\t\tenum subphrase_relation_t\n",
      "\t\tenum subphrase_mother_object_type_t\n",
      "\t\tenum phrase_function_t\n",
      "\t\tenum clause_atom_type_t\n",
      "\t\tenum clause_type_t\n",
      "\t\tenum clause_kind_t\n",
      "\t\tenum clause_constituent_relation_t\n",
      "\t\tenum clause_constituent_mother_object_type_t\n",
      "\t\tenum clause_constituent_unit_distance_to_mother_t\n",
      "\t\totype word\n",
      "\t\t\tfeature trailer_utf8 (str) = None : node\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature g_vbe (str) = None : node\n",
      "\t\t\tfeature g_word (str) = None : node\n",
      "\t\t\tfeature g_word_utf8 (str) = None : node\n",
      "\t\t\tfeature g_cons_utf8 (str) = None : node\n",
      "\t\t\tfeature g_cons (str) = None : node\n",
      "\t\t\tfeature g_pfm (str) = None : node\n",
      "\t\t\tfeature g_pfm_utf8 (str) = None : node\n",
      "\t\t\tfeature g_vbs (str) = None : node\n",
      "\t\t\tfeature g_vbs_utf8 (str) = None : node\n",
      "\t\t\tfeature lex (str) = None : node\n",
      "\t\t\tfeature lex_utf8 (str) = None : node\n",
      "\t\t\tfeature g_prs_utf8 (str) = None : node\n",
      "\t\t\tfeature g_prs (str) = None : node\n",
      "\t\t\tfeature g_lex (str) = None : node\n",
      "\t\t\tfeature g_uvf_utf8 (str) = None : node\n",
      "\t\t\tfeature g_uvf (str) = None : node\n",
      "\t\t\tfeature g_lex_utf8 (str) = None : node\n",
      "\t\t\tfeature g_nme_utf8 (str) = None : node\n",
      "\t\t\tfeature g_nme (str) = None : node\n",
      "\t\t\tfeature g_vbe_utf8 (str) = None : node\n",
      "\t\t\tfeature nme (str) = None : node\n",
      "\t\t\tfeature distributional_parent (str) = None : edge\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\t\tfeature vbe (str) = None : node\n",
      "\t\t\tfeature prs (str) = None : node\n",
      "\t\t\tfeature vbs (str) = None : node\n",
      "\t\t\tfeature pfm (str) = None : node\n",
      "\t\t\tfeature uvf (str) = None : node\n",
      "\t\t\tfeature language (str) = Hebrew : node\n",
      "\t\t\tfeature ls (str) = none : node\n",
      "\t\t\tfeature vs (str) = NA : node\n",
      "\t\t\tfeature vt (str) = NA : node\n",
      "\t\t\tfeature ps (str) = NA : node\n",
      "\t\t\tfeature nu (str) = NA : node\n",
      "\t\t\tfeature gn (str) = NA : node\n",
      "\t\t\tfeature st (str) = NA : node\n",
      "\t\t\tfeature sp (str) = art : node\n",
      "\t\t\tfeature pdp (str) = art : node\n",
      "\t\t\tfeature g_entry (str) = None : node\n",
      "\t\t\tfeature g_entry_heb (str) = None : node\n",
      "\t\t\tfeature g_qere_utf8 (str) = None : node\n",
      "\t\t\tfeature gloss (str) = None : node\n",
      "\t\t\tfeature nametype (str) = None : node\n",
      "\t\t\tfeature phono (str) = None : node\n",
      "\t\t\tfeature phono_sep (str) = None : node\n",
      "\t\t\tfeature qtrailer_utf8 (str) = None : node\n",
      "\t\totype clause_atom\n",
      "\t\t\tfeature tab (int) = None : node\n",
      "\t\t\tfeature code (int) = None : node\n",
      "\t\t\tfeature dist (int) = None : node\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature distributional_parent (str) = None : edge\n",
      "\t\t\tfeature mother (str) = None : edge\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\t\tfeature is_root (str) = false : node\n",
      "\t\t\tfeature typ (str) = Unkn : node\n",
      "\t\t\tfeature pargr (str) = None : node\n",
      "\t\totype sentence\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\totype subphrase\n",
      "\t\t\tfeature mother (str) = None : edge\n",
      "\t\t\tfeature rela (str) = NA : node\n",
      "\t\t\tfeature mother_object_type (str) = NA : node\n",
      "\t\totype phrase\n",
      "\t\t\tfeature dist (int) = None : node\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\t\tfeature mother (str) = None : edge\n",
      "\t\t\tfeature det (str) = NA : node\n",
      "\t\t\tfeature typ (str) = VP : node\n",
      "\t\t\tfeature rela (str) = NA : node\n",
      "\t\t\tfeature dist_unit (str) = clause_atoms : node\n",
      "\t\t\tfeature function (str) = Unkn : node\n",
      "\t\totype chapter\n",
      "\t\t\tfeature chapter (int) = None : node\n",
      "\t\t\tfeature book (str) = Genesis : node\n",
      "\t\totype book\n",
      "\t\t\tfeature book (str) = Genesis : node\n",
      "\t\totype clause\n",
      "\t\t\tfeature dist (int) = None : node\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature domain (str) = None : node\n",
      "\t\t\tfeature mother (str) = None : edge\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\t\tfeature txt (str) = None : node\n",
      "\t\t\tfeature typ (str) = Unkn : node\n",
      "\t\t\tfeature kind (str) = unknown : node\n",
      "\t\t\tfeature rela (str) = NA : node\n",
      "\t\t\tfeature mother_object_type (str) = clause : node\n",
      "\t\t\tfeature dist_unit (str) = clause_atoms : node\n",
      "\t\totype half_verse\n",
      "\t\t\tfeature label (str) = None : node\n",
      "\t\totype verse\n",
      "\t\t\tfeature verse (int) = None : node\n",
      "\t\t\tfeature chapter (int) = None : node\n",
      "\t\t\tfeature label (str) = None : node\n",
      "\t\t\tfeature book (str) = Genesis : node\n",
      "\t\totype sentence_atom\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\totype phrase_atom\n",
      "\t\t\tfeature number (int) = None : node\n",
      "\t\t\tfeature dist (int) = None : node\n",
      "\t\t\tfeature distributional_parent (str) = None : edge\n",
      "\t\t\tfeature mother (str) = None : edge\n",
      "\t\t\tfeature functional_parent (str) = None : edge\n",
      "\t\t\tfeature det (str) = NA : node\n",
      "\t\t\tfeature typ (str) = VP : node\n",
      "\t\t\tfeature rela (str) = NA : node\n",
      "\t\t\tfeature dist_unit (str) = clause_atoms : node\n",
      "\t\tobjects in word\n",
      "      4.22s \tline   1000000\n",
      "      8.38s \tline   2000000\n",
      "\t\tobjects in word\n",
      "        13s \tline   3000000\n",
      "        17s \tline   4000000\n",
      "        21s \tline   5000000\n",
      "\t\tobjects in word\n",
      "        25s \tline   6000000\n",
      "        29s \tline   7000000\n",
      "\t\tobjects in word\n",
      "        33s \tline   8000000\n",
      "        38s \tline   9000000\n",
      "        42s \tline  10000000\n",
      "\t\tobjects in word\n",
      "        46s \tline  11000000\n",
      "        50s \tline  12000000\n",
      "        54s \tline  13000000\n",
      "\t\tobjects in word\n",
      "        58s \tline  14000000\n",
      "     1m 03s \tline  15000000\n",
      "\t\tobjects in word\n",
      "     1m 07s \tline  16000000\n",
      "     1m 11s \tline  17000000\n",
      "     1m 15s \tline  18000000\n",
      "\t\tobjects in word\n",
      "     1m 19s \tline  19000000\n",
      "     1m 23s \tline  20000000\n",
      "\t\tobjects in word\n",
      "     1m 28s \tline  21000000\n",
      "     1m 32s \tline  22000000\n",
      "\t\tobjects in clause_atom\n",
      "\t\tobjects in clause_atom\n",
      "     1m 36s \tline  23000000\n",
      "\t\tobjects in sentence\n",
      "\t\tobjects in sentence\n",
      "\t\tobjects in subphrase\n",
      "     1m 40s \tline  24000000\n",
      "\t\tobjects in subphrase\n",
      "\t\tobjects in subphrase\n",
      "\t\tobjects in phrase\n",
      "     1m 43s \tline  25000000\n",
      "\t\tobjects in phrase\n",
      "\t\tobjects in phrase\n",
      "     1m 47s \tline  26000000\n",
      "\t\tobjects in phrase\n",
      "     1m 50s \tline  27000000\n",
      "\t\tobjects in phrase\n",
      "\t\tobjects in phrase\n",
      "\t\tobjects in chapter\n",
      "\t\tobjects in book\n",
      "\t\tobjects in clause\n",
      "     1m 55s \tline  28000000\n",
      "\t\tobjects in clause\n",
      "     1m 58s \tline  29000000\n",
      "\t\tobjects in half_verse\n",
      "\t\tobjects in verse\n",
      "\t\tobjects in sentence_atom\n",
      "\t\tobjects in sentence_atom\n",
      "     2m 03s \tline  30000000\n",
      "\t\tobjects in phrase_atom\n",
      "\t\tobjects in phrase_atom\n",
      "     2m 06s \tline  31000000\n",
      "\t\tobjects in phrase_atom\n",
      "\t\tobjects in phrase_atom\n",
      "     2m 10s \tline  32000000\n",
      "\t\tobjects in phrase_atom\n",
      "     2m 14s \tline  33000000\n",
      "\t\tobjects in phrase_atom\n",
      "     2m 16s 33479945 lines parsed\n",
      "426568 objects of type word\n",
      "90554 objects of type clause_atom\n",
      "63586 objects of type sentence\n",
      "113764 objects of type subphrase\n",
      "253161 objects of type phrase\n",
      "929 objects of type chapter\n",
      "39 objects of type book\n",
      "88011 objects of type clause\n",
      "45180 objects of type half_verse\n",
      "23213 objects of type verse\n",
      "64354 objects of type sentence_atom\n",
      "267499 objects of type phrase_atom\n"
     ]
    }
   ],
   "source": [
    "with open(MQL_FILE) as fh: good = parseMql(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0.00s Making TF data ...\n",
      "      0.00s Monad - idd mapping ...\n",
      "      0.48s maxSlot=426568\n",
      "      0.48s Node mapping and otype ...\n",
      "      1.09s oslots ...\n",
      "      1.46s metadata ...\n",
      "      1.46s features ...\n",
      "      1.46s \tfeatures from words\n",
      "        18s \tfeatures from books\n",
      "        18s \tfeatures from chapters\n",
      "        18s \tfeatures from clauses\n",
      "        19s \tfeatures from clause_atoms\n",
      "        20s \tfeatures from half_verses\n",
      "        20s \tfeatures from phrases\n",
      "        22s \tfeatures from phrase_atoms\n",
      "        26s \tfeatures from sentences\n",
      "        26s \tfeatures from sentence_atoms\n",
      "        26s \tfeatures from subphrases\n",
      "        27s \tfeatures from verses\n",
      "        27s book names ...\n",
      "        27s write data set to TF ...\n",
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Grid feature \"otype\" not found in\n",
      "\n",
      "  0.00s Grid feature \"oslots\" not found in\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01s Grid feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Exporting 91 node and 4 edge and 1 config features to /Users/dirk/github/bhsa/_temp/4b/core:\n",
      "   |     0.05s T book                 to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@am              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@ar              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@bn              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@da              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@de              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@el              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@en              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@es              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@fa              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@fr              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@he              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@hi              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@id              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@ja              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@ko              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@la              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@nl              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@pa              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@pt              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@ru              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@sw              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@syc             to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@tr              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@ur              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@yo              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s T book@zh              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.09s T chapter              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.16s T code                 to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.89s T det                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     1.15s T dist                 to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     1.00s T dist_unit            to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.15s T domain               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.44s T function             to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.75s T g_cons               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.79s T g_cons_utf8          to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.87s T g_entry              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.78s T g_entry_heb          to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.74s T g_lex                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.83s T g_lex_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T g_nme                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.71s T g_nme_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.69s T g_pfm                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.64s T g_pfm_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T g_prs                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.68s T g_prs_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.64s T g_qere_utf8          to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.65s T g_uvf                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T g_uvf_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.66s T g_vbe                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.68s T g_vbe_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T g_vbs                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T g_vbs_utf8           to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.77s T g_word               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.84s T g_word_utf8          to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.75s T gloss                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.76s T gn                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.17s T is_root              to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.16s T kind                 to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.11s T label                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.75s T language             to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.73s T lex                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.81s T lex_utf8             to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.76s T ls                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.38s T mother_object_type   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.65s T nametype             to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.74s T nme                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.75s T nu                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     2.12s T number               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.66s T otype                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.15s T pargr                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.76s T pdp                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.76s T pfm                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.78s T phono                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.69s T phono_sep            to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.77s T prs                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.75s T ps                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.67s T qtrailer_utf8        to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     1.31s T rela                 to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.76s T sp                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.70s T st                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.16s T tab                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.71s T trailer_utf8         to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.16s T txt                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     1.23s T typ                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.87s T uvf                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.72s T vbe                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.77s T vbs                  to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.05s T verse                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.77s T vs                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.72s T vt                   to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     2.62s T distributional_parent to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     3.90s T functional_parent    to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.62s T mother               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     4.28s T oslots               to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "   |     0.00s M otext                to /Users/dirk/github/bhsa/_temp/4b/core\n",
      "    55s Exported 91 node features and 4 edge features and 1 config features to /Users/dirk/github/bhsa/_temp/4b/core\n"
     ]
    }
   ],
   "source": [
    "if good: tfFromData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before continuing\n",
    "\n",
    "The new dataset has been created in a temporary directory, and not yet copied to its destination.\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no features to add\n",
      "no features to delete\n",
      "96 features in common\n"
     ]
    }
   ],
   "source": [
    "existingFiles = glob('{}/*.tf'.format(TF_DELIVER))\n",
    "newFiles = glob('{}/*.tf'.format(TF_SAVE))\n",
    "existingFeatures = {os.path.basename(os.path.splitext(f)[0]) for f in existingFiles}\n",
    "newFeatures = {os.path.basename(os.path.splitext(f)[0]) for f in newFiles}\n",
    "\n",
    "addedOnes = newFeatures - existingFeatures\n",
    "deletedOnes = existingFeatures - newFeatures\n",
    "commonOnes = newFeatures & existingFeatures\n",
    "\n",
    "if addedOnes:\n",
    "    print('{} features to add:\\n\\t{}'.format(len(addedOnes), ' '.join(sorted(addedOnes))))\n",
    "else:\n",
    "    print('no features to add')\n",
    "if deletedOnes:\n",
    "    print('{} features to delete:\\n\\t{}'.format(len(deletedOnes), ' '.join(sorted(deletedOnes))))\n",
    "else:\n",
    "    print('no features to delete')\n",
    "    \n",
    "print('{} features in common'.format(len(commonOnes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the common ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffFeature(f):\n",
    "    sys.stdout.write('{:<25} ... '.format(f))\n",
    "    existingPath = '{}/{}.tf'.format(TF_DELIVER, f)\n",
    "    newPath = '{}/{}.tf'.format(TF_SAVE, f)\n",
    "    with open(existingPath) as h: eLines = (d for d in h.readlines() if not d.startswith('@'))\n",
    "    with open(newPath) as h: nLines = (d for d in h.readlines() if not d.startswith('@'))\n",
    "    i = 0\n",
    "    equal = True\n",
    "    for (e, n) in zip(eLines, nLines):\n",
    "        i += 1\n",
    "        if e != n:\n",
    "            print('First diff in line {} after the  metadata'.format(i))\n",
    "            equal = False\n",
    "            continue\n",
    "    print('no changes' if equal else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book                      ... no changes\n",
      "book@am                   ... no changes\n",
      "book@ar                   ... no changes\n",
      "book@bn                   ... no changes\n",
      "book@da                   ... no changes\n",
      "book@de                   ... no changes\n",
      "book@el                   ... no changes\n",
      "book@en                   ... no changes\n",
      "book@es                   ... no changes\n",
      "book@fa                   ... no changes\n",
      "book@fr                   ... no changes\n",
      "book@he                   ... no changes\n",
      "book@hi                   ... no changes\n",
      "book@id                   ... no changes\n",
      "book@ja                   ... no changes\n",
      "book@ko                   ... no changes\n",
      "book@la                   ... no changes\n",
      "book@nl                   ... no changes\n",
      "book@pa                   ... no changes\n",
      "book@pt                   ... no changes\n",
      "book@ru                   ... no changes\n",
      "book@sw                   ... no changes\n",
      "book@syc                  ... no changes\n",
      "book@tr                   ... no changes\n",
      "book@ur                   ... no changes\n",
      "book@yo                   ... no changes\n",
      "book@zh                   ... no changes\n",
      "chapter                   ... no changes\n",
      "code                      ... no changes\n",
      "det                       ... no changes\n",
      "dist                      ... no changes\n",
      "dist_unit                 ... no changes\n",
      "distributional_parent     ... no changes\n",
      "domain                    ... no changes\n",
      "function                  ... no changes\n",
      "functional_parent         ... no changes\n",
      "g_cons                    ... no changes\n",
      "g_cons_utf8               ... no changes\n",
      "g_entry                   ... no changes\n",
      "g_entry_heb               ... no changes\n",
      "g_lex                     ... no changes\n",
      "g_lex_utf8                ... no changes\n",
      "g_nme                     ... no changes\n",
      "g_nme_utf8                ... no changes\n",
      "g_pfm                     ... no changes\n",
      "g_pfm_utf8                ... no changes\n",
      "g_prs                     ... no changes\n",
      "g_prs_utf8                ... no changes\n",
      "g_qere_utf8               ... no changes\n",
      "g_uvf                     ... no changes\n",
      "g_uvf_utf8                ... no changes\n",
      "g_vbe                     ... no changes\n",
      "g_vbe_utf8                ... no changes\n",
      "g_vbs                     ... no changes\n",
      "g_vbs_utf8                ... no changes\n",
      "g_word                    ... no changes\n",
      "g_word_utf8               ... no changes\n",
      "gloss                     ... no changes\n",
      "gn                        ... no changes\n",
      "is_root                   ... no changes\n",
      "kind                      ... no changes\n",
      "label                     ... no changes\n",
      "language                  ... no changes\n",
      "lex                       ... no changes\n",
      "lex_utf8                  ... no changes\n",
      "ls                        ... no changes\n",
      "mother                    ... no changes\n",
      "mother_object_type        ... no changes\n",
      "nametype                  ... no changes\n",
      "nme                       ... no changes\n",
      "nu                        ... no changes\n",
      "number                    ... no changes\n",
      "oslots                    ... no changes\n",
      "otext                     ... no changes\n",
      "otype                     ... no changes\n",
      "pargr                     ... no changes\n",
      "pdp                       ... no changes\n",
      "pfm                       ... no changes\n",
      "phono                     ... no changes\n",
      "phono_sep                 ... no changes\n",
      "prs                       ... no changes\n",
      "ps                        ... no changes\n",
      "qtrailer_utf8             ... no changes\n",
      "rela                      ... no changes\n",
      "sp                        ... no changes\n",
      "st                        ... no changes\n",
      "tab                       ... no changes\n",
      "trailer_utf8              ... no changes\n",
      "txt                       ... no changes\n",
      "typ                       ... no changes\n",
      "uvf                       ... no changes\n",
      "vbe                       ... no changes\n",
      "vbs                       ... no changes\n",
      "verse                     ... no changes\n",
      "vs                        ... no changes\n",
      "vt                        ... no changes\n"
     ]
    }
   ],
   "source": [
    "for f in sorted(commonOnes):\n",
    "    diffFeature(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all is well, the next cell will deliver the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if good: deliverDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Load all new TF features\n",
    "\n",
    "Just to see whether everything loads and the precomputing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the precomputing has already been done, and everything is quicker in subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.12\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "96 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations=TF_LOCATION, modules=TF_MODULE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a single feature to trigger the precomputing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature, will also be loaded,\n",
    "as well as the features for sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     2.89s T otype                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |       13s T oslots               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.12s T book                 from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.06s T chapter              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.06s T verse                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.79s T g_cons               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.68s T g_cons_utf8          from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.55s T g_lex                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.67s T g_lex_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.69s T g_qere_utf8          from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.57s T g_word               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.70s T g_word_utf8          from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.47s T lex                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.66s T lex_utf8             from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.68s T qtrailer_utf8        from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.19s T trailer_utf8         from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |      |     1.31s C __levels__           from otype, oslots\n",
      "   |      |       18s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.96s C __rank__             from otype, __order__\n",
      "   |      |       19s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     9.51s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     4.27s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s M otext                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |      |     0.16s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     1.56s T sp                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@am              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@ar              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@bn              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@da              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@de              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@el              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@en              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@es              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@fa              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@fr              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@he              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@hi              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@id              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@ja              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@ko              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@la              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@nl              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@pa              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@pt              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@ru              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@sw              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@syc             from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@tr              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@ur              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@yo              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s T book@zh              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s Feature overview: 91 for nodes; 4 for edges; 1 configs; 7 computed\n",
      " 1m 27s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have access to the full list of features.\n",
    "We grab them and are going to load them all!\n",
    "\n",
    "The next cell loads the data of some central features and the metadata of all features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.00s Feature overview: 91 for nodes; 4 for edges; 1 configs; 7 computed\n"
     ]
    }
   ],
   "source": [
    "allFeatures = TF.explore(silent=False, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to load the remaining features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book book@am book@ar book@bn book@da book@de book@el book@en book@es book@fa book@fr book@he book@hi book@id book@ja book@ko book@la book@nl book@pa book@pt book@ru book@sw book@syc book@tr book@ur book@yo book@zh chapter code det dist dist_unit domain function g_cons g_cons_utf8 g_entry g_entry_heb g_lex g_lex_utf8 g_nme g_nme_utf8 g_pfm g_pfm_utf8 g_prs g_prs_utf8 g_qere_utf8 g_uvf g_uvf_utf8 g_vbe g_vbe_utf8 g_vbs g_vbs_utf8 g_word g_word_utf8 gloss gn is_root kind label language lex lex_utf8 ls mother_object_type nametype nme nu number otype pargr pdp pfm phono phono_sep prs ps qtrailer_utf8 rela sp st tab trailer_utf8 txt typ uvf vbe vbs verse vs vt distributional_parent functional_parent mother oslots\n"
     ]
    }
   ],
   "source": [
    "loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "print(' '.join(loadableFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.18s T code                 from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.79s T det                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.36s T dist                 from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     2.09s T dist_unit            from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     4.13s T distributional_parent from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.30s T domain               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.92s T function             from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     7.15s T functional_parent    from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.58s T g_entry              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.75s T g_entry_heb          from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.99s T g_nme                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.07s T g_nme_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.78s T g_pfm                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.82s T g_pfm_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.76s T g_prs                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.80s T g_prs_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.75s T g_uvf                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.68s T g_uvf_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.88s T g_vbe                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.94s T g_vbe_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.75s T g_vbs                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.74s T g_vbs_utf8           from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.64s T gloss                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.48s T gn                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.33s T is_root              from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.31s T kind                 from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.23s T label                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.54s T language             from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.54s T ls                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.94s T mother               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.71s T mother_object_type   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.79s T nametype             from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.27s T nme                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.57s T nu                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     2.61s T number               from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.30s T pargr                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.59s T pdp                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.55s T pfm                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.82s T phono                from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.11s T phono_sep            from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.58s T prs                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.54s T ps                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     2.62s T rela                 from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.48s T st                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.19s T tab                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.31s T txt                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     2.64s T typ                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.53s T uvf                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.43s T vbe                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.58s T vbs                  from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.58s T vs                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     1.52s T vt                   from /Users/dirk/github/bhsa/tf/4b/core\n",
      "   |     0.00s Feature overview: 91 for nodes; 4 for edges; 1 configs; 7 computed\n",
      " 1m 14s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load(loadableFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
