{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Paragraphs\n",
    "\n",
    "This notebook can read ETCBC `.px` files with information\n",
    "about *paragraphs* in it.\n",
    "We distil a bunch of extra features at the `clause_atom` level, namely:\n",
    "* `pargr`\n",
    "* `instruction`\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "Somebody should tell in more detail what they are, and document it in the feature documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.transcription import Transcription\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION= 'c'\n",
    "    CORE_MODULE ='core' \n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "module = CORE_MODULE\n",
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisSave = '{}/{}'.format(thisTemp, module)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)\n",
    "thisDeliver = '{}/{}'.format(thisTf, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeature = 'pargr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(None, '{}/.tf/{}.tfx'.format(thisDeliver, testFeature), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material, \n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    " \n",
    "We do not do this for the older versions 4 and 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset='BHSA',\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 53s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.13\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "105 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.02s B label                from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.30s B number               from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.00s Feature overview: 100 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  4.69s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load the existing TF dataset')\n",
    "TF = Fabric(locations=thisTf, modules=module)\n",
    "api = TF.load('label number')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clause atom identifiers in .px\n",
    "We must map the way the clause_atoms are identified in the `.px` files\n",
    "to nodes in TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     18m 16s \tLabeling clause_atoms\n",
      "|     18m 18s \tOK: clause atoms succesfully labeled\n",
      "|     18m 18s \t90562 clause atoms\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, '\\tLabeling clause_atoms')\n",
    "\n",
    "labelNumberFromNode = {}\n",
    "nodeFromLabelNumber = {}\n",
    "for n in N():\n",
    "    otype = F.otype.v(n)\n",
    "    if otype == 'book':\n",
    "        curSubtract = 0\n",
    "        curChapterSeq = 0\n",
    "    elif otype == 'chapter':\n",
    "        curSubtract += curChapterSeq\n",
    "        curChapterSeq = 0\n",
    "    elif otype == 'verse':\n",
    "        curLabel = F.label.v(n)\n",
    "    elif otype == 'clause_atom':\n",
    "        curChapterSeq += 1\n",
    "        nm = int(F.number.v(n)) - curSubtract\n",
    "        nodeFromLabelNumber[(curLabel, nm)] = n\n",
    "        labelNumberFromNode[n] = (curLabel, nm)\n",
    "\n",
    "nLabs = len(nodeFromLabelNumber)\n",
    "nNodes = len(labelNumberFromNode)\n",
    "\n",
    "if nLabs == nNodes:\n",
    "    utils.caption(0, '\\tOK: clause atoms succesfully labeled')\n",
    "    utils.caption(0, '\\t{} clause atoms'.format(nNodes))\n",
    "else:\n",
    "    utils.caption(0, '\\tWARNING: clause atoms not uniquely labeled')\n",
    "    utils.caption(0, '\\t{} labels =/= {} nodes'.format(nLabs, nNodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the PX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     31m 29s Parsing paragraph data in PX                                                   .\n",
      "..............................................................................................\n",
      "|     31m 29s bunzipping /Users/dirk/github/etcbc/bhsa/source/c/paragraphs.txt.bz2 ...\n",
      "|     31m 29s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|     31m 29s \tRead 90562 paragraph annotations\n",
      "|     31m 29s \tOK: All label/line entries found in index\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Parsing paragraph data in PX')\n",
    "\n",
    "pxFile = '{}/paragraphs.txt'.format(thisTemp)\n",
    "pxzFile = '{}/paragraphs.txt.bz2'.format(thisSource)\n",
    "utils.caption(0, 'bunzipping {} ...'.format(pxzFile))\n",
    "utils.bunzip(pxzFile, pxFile)\n",
    "pxHandle = open(pxFile)\n",
    "\n",
    "data = []\n",
    "notFound = set()\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "featurescan = re.compile(r'0 0 (..) [0-9]+ LineNr\\s*([0-9]+).*?Pargr:\\s*([0-9.]+)')\n",
    "curLabel = None\n",
    "\n",
    "for line in pxHandle:\n",
    "    ln += 1\n",
    "    if line.strip()[0] != '*':\n",
    "        curLabel = line[0:10]\n",
    "        continue\n",
    "    can += 1\n",
    "    features = featurescan.findall(line)\n",
    "    if len(features) == 0:\n",
    "        utils.caption(0, '\\tWarning: line {}: no instruction, LineNr, Pargr found'.format(ln))\n",
    "    elif len(features) > 1:\n",
    "        utils.caption(0, '\\tWarning: line {}: multiple instruction, LineNr, Pargr found'.format(ln))\n",
    "    else:\n",
    "        feature = features[0]\n",
    "        theIns = feature[0]\n",
    "        theN = feature[1]\n",
    "        thePara = feature[2]\n",
    "        labNum = (curLabel, int(theN))\n",
    "        if labNum not in nodeFromLabelNumber:\n",
    "            notFound.add(labNum)\n",
    "            continue\n",
    "        data.append((nodeFromLabelNumber[labNum], theIns, theN, thePara))\n",
    "pxHandle.close()\n",
    "utils.caption(0, '\\tRead {} paragraph annotations'.format(len(data)))\n",
    "\n",
    "if notFound:\n",
    "    utils.caption(0, '\\tWARNING: Could not find {} label/line entries in index: {}'.format(\n",
    "        len(notFound), sorted({lab for lab in notFound}),\n",
    "    ))\n",
    "else:\n",
    "    utils.caption(0, '\\tOK: All label/line entries found in index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576266, '.N', '1', '1')\n",
      "(576267, '..', '2', '1')\n",
      "(576268, '..', '3', '1')\n",
      "(576269, '..', '4', '1')\n",
      "(576270, '.q', '5', '1.1')\n",
      "(576271, '..', '6', '1.1')\n",
      "(576272, '..', '7', '1.1')\n",
      "(576273, '..', '8', '1.1')\n",
      "(576274, '..', '9', '1.1')\n",
      "(576275, '.q', '10', '1.1.1')\n"
     ]
    }
   ],
   "source": [
    "if not SCRIPT:\n",
    "    print('\\n'.join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features\n",
    "\n",
    "We now collect the lexical information into the features for nodes of type `lex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     55m 16s Prepare TF paragraph features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Prepare TF paragraph features')\n",
    "\n",
    "metaData = {}\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = '''\n",
    "    pargr\n",
    "    instruction\n",
    "'''.strip().split()\n",
    "\n",
    "nodeFeatures = dict( \n",
    "    instruction=dict(((x[0], x[1]) for x in data)),\n",
    "    pargr=dict(((x[0], x[3]) for x in data)),\n",
    ")\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f].update(provenanceMetadata)\n",
    "    metaData[f]['valueType'] = 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changedFeatures = set(nodeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: TF generation\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     55m 26s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n",
      "   |     0.15s T instruction          to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n",
      "   |     0.14s T pargr                to /Users/dirk/github/etcbc/bhsa/_temp/c/core\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'write new/changed features to TF ...')\n",
    "TF = Fabric(locations=thisSave, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     55m 30s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     55m 30s \tno features to add\n",
      "|     55m 30s \tno features to delete\n",
      "|     55m 30s \t2 features in common\n",
      "|     55m 30s instruction               ... no changes\n",
      "|     55m 30s pargr                     ... differencesafter the metadata\n",
      "|     55m 30s \tline      3 OLD -->2<--\n",
      "|     55m 30s \tline      3 NEW -->1<--\n",
      "|     55m 30s \tline      4 OLD -->3<--\n",
      "|     55m 30s \tline      4 NEW -->1<--\n",
      "|     55m 30s \tline      5 OLD -->4<--\n",
      "|     55m 30s \tline      5 NEW -->1<--\n",
      "|     55m 30s \tline      6 OLD -->5<--\n",
      "|     55m 30s \tline      6 NEW -->1.1<--\n",
      "\n",
      "|     55m 30s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisSave, thisDeliver, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     55m 37s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/c/core                    .\n",
      "..............................................................................................\n",
      "|     55m 37s \tinstruction\n",
      "|     55m 37s \tpargr\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisSave, thisDeliver, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     55m 39s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.13\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "107 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.32s T instruction          from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.30s T pargr                from /Users/dirk/github/etcbc/bhsa/tf/c/core\n",
      "   |     0.00s Feature overview: 102 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  4.97s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile the new TF features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=module)\n",
    "api = TF.load(' '.join(changedFeatures))\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     56m 09s Test: paragraphs of the first verses                                           .\n",
      "..............................................................................................\n",
      "\tGenesis 1:1\n",
      "\t\t.N             1 בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "\t2\n",
      "\t\t..             1 וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ \n",
      "\t\t..             1 וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום \n",
      "\t\t..             1 וְר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל־פְּנֵ֥י הַמָּֽיִם׃ \n",
      "\t3\n",
      "\t\t.#           1.1 וַיֹּ֥אמֶר אֱלֹהִ֖ים \n",
      "\t\t.q         1.1.1 יְהִ֣י אֹ֑ור \n",
      "\t\t.#         1.1.2 וַֽיְהִי־אֹֽור׃ \n",
      "\t4\n",
      "\t\t.#         1.1.3 וַיַּ֧רְא אֱלֹהִ֛ים אֶת־הָאֹ֖ור \n",
      "\t\t..         1.1.3 כִּי־טֹ֑וב \n",
      "\t\t.#         1.1.4 וַיַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָאֹ֖ור וּבֵ֥ין הַחֹֽשֶׁךְ׃ \n",
      "\t5\n",
      "\t\t.#         1.1.5 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לָאֹור֙ יֹ֔ום \n",
      "\t\t..         1.1.5 וְלַחֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה \n",
      "\t\t.#       1.1.5.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#       1.1.5.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..       1.1.5.2 יֹ֥ום אֶחָֽד׃ פ \n",
      "\t6\n",
      "\t\t.#           1.2 וַיֹּ֣אמֶר אֱלֹהִ֔ים \n",
      "\t\t.q         1.2.1 יְהִ֥י רָקִ֖יעַ בְּתֹ֣וךְ הַמָּ֑יִם \n",
      "\t\t..         1.2.1 וִיהִ֣י מַבְדִּ֔יל בֵּ֥ין מַ֖יִם לָמָֽיִם׃ \n",
      "\t7\n",
      "\t\t.#         1.2.2 וַיַּ֣עַשׂ אֱלֹהִים֮ אֶת־הָרָקִיעַ֒ \n",
      "\t\t..         1.2.2 וַיַּבְדֵּ֗ל בֵּ֤ין הַמַּ֨יִם֙ \n",
      "\t\t.e         1.2.2 אֲשֶׁר֙ מִתַּ֣חַת לָרָקִ֔יעַ \n",
      "\t\td.         1.2.2 וּבֵ֣ין הַמַּ֔יִם \n",
      "\t\t..         1.2.2 אֲשֶׁ֖ר מֵעַ֣ל לָרָקִ֑יעַ \n",
      "\t\t..         1.2.2 וַֽיְהִי־כֵֽן׃ \n",
      "\t8\n",
      "\t\t.#       1.2.2.1 וַיִּקְרָ֧א אֱלֹהִ֛ים לָֽרָקִ֖יעַ שָׁמָ֑יִם \n",
      "\t\t.#     1.2.2.1.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#     1.2.2.1.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..     1.2.2.1.2 יֹ֥ום שֵׁנִֽי׃ פ \n",
      "\t9\n",
      "\t\t.#           1.3 וַיֹּ֣אמֶר אֱלֹהִ֗ים \n",
      "\t\t.q         1.3.1 יִקָּו֨וּ הַמַּ֜יִם מִתַּ֤חַת הַשָּׁמַ֨יִם֙ אֶל־מָקֹ֣ום אֶחָ֔ד \n",
      "\t\t..         1.3.1 וְתֵרָאֶ֖ה הַיַּבָּשָׁ֑ה \n",
      "\t\t..           1.3 וַֽיְהִי־כֵֽן׃ \n",
      "\t10\n",
      "\t\t.#         1.3.2 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לַיַּבָּשָׁה֙ אֶ֔רֶץ \n",
      "\t\t..         1.3.2 וּלְמִקְוֵ֥ה הַמַּ֖יִם קָרָ֣א יַמִּ֑ים \n",
      "\t\t.#         1.3.3 וַיַּ֥רְא אֱלֹהִ֖ים \n",
      "\t\t..         1.3.3 כִּי־טֹֽוב׃ \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Test: paragraphs of the first verses')\n",
    "\n",
    "def showParagraphs(verseNode):\n",
    "    clause_atoms = L.d(verseNode, otype='clause_atom')\n",
    "    for ca in clause_atoms:\n",
    "        utils.caption(0, '\\t\\t{:<3} {:>12} {}'.format(\n",
    "            F.instruction.v(ca),\n",
    "            F.pargr.v(ca),\n",
    "            T.text(L.d(ca, otype='word'))\n",
    "        ), continuation=True)\n",
    "\n",
    "for (i, verseNode) in enumerate(F.otype.s('verse')[0:10]):\n",
    "    verseLabel = T.sectionFromNode(verseNode)\n",
    "    verseHeading = '{} {}:{}'.format(*verseLabel) if i == 0 else verseLabel[2]\n",
    "    utils.caption(0, '\\t{}'.format(verseHeading), continuation=True)\n",
    "    showParagraphs(verseNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
