{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "\n",
    "# BHSA versions\n",
    "\n",
    "In this notebook we map the slots between the versions `3`, `4`, `4b` and 2016 of the BHSA dataset.\n",
    "In another notebook,\n",
    "[mappingNodes](https://github.com/ETCBC/bhsa/blob/master/programs/mappingNodes.ipynb),\n",
    "we extend this mapping to a mapping between *all* nodes of the versions involved, not just the slots.\n",
    "\n",
    "The resulting mappings can be used by text-fabric programs to enable themselves to\n",
    "work on different versions of the data than for which they were developed.\n",
    "\n",
    "In general, node mappings between versions can not be perfect.\n",
    "\n",
    "# Slot mappings\n",
    "We map the slots of a version to the slots of the next version.\n",
    "Mappings go from old to new, and they are between successive versions.\n",
    "\n",
    "## Mappings are edges\n",
    "We store mappings as ordinary TF edge features, so you can use the mapping in both ways, by\n",
    "\n",
    "```\n",
    "nodesInVersion4 = Es('omap@3-4').f(nodeInVersion3)\n",
    "nodesInVersion3 = Es('omap@3-4').t(nodeInVersion4)\n",
    "```\n",
    "\n",
    "respectively.\n",
    "\n",
    "## Differences\n",
    "\n",
    "When we compare versions, our aim is not to record all differences in general, but to record\n",
    "the correspondence between the slots of the versions, and exactly where and how this\n",
    "correspondence is disturbed.\n",
    "\n",
    "We use the lexeme concept as an anchor point for the correspondence.\n",
    "If we compare the two versions, slot by slot, and as long as we encounter the same lexemes,\n",
    "we have an undisturbed correspondence.\n",
    "In fact, we relax this a little bit, because the very concept of lexeme might change between versions.\n",
    "So we reduce the information in lexemes considerably, before we compare them, so that we\n",
    "do not get disturbed by petty changes.\n",
    "\n",
    "While being undisturbed, we just create an adge between the slot in the one version that we are at,\n",
    "to the node in the other version that we are at, \n",
    "and we assing no value to such an edge.\n",
    "\n",
    "But eventually, we encounter real disturbances.\n",
    "They manifest themselves in just a few situations:\n",
    "\n",
    "1. ![1](diffs/diffs.001.png)\n",
    "2. ![2](diffs/diffs.002.png)\n",
    "3. ![3](diffs/diffs.003.png)\n",
    "\n",
    "In full generality, we can say: $i$ slots in the source version correspond to $j$ slots in the\n",
    "target version, where $i$ and $j$ may be 0, but not at the same time:\n",
    "\n",
    "1. ![4](diffs/diffs.004.png)\n",
    "\n",
    "## Edges carry data\n",
    "We want to leave behind the information of what happened, and we can do so if we let the edges\n",
    "carry data.\n",
    "\n",
    "Suppose we have an edge between node $n$ in the old version and node $m$ in the new version.\n",
    "Then this is what happens in the general case:\n",
    "\n",
    "1. If there is no disturbance, we create an edge between $n$ and $m$, with no data associated.\n",
    "2. If $i$ slots in the source version, starting at $n$ \n",
    "   get replaced by $j$ slots in the target version, starting at $m$,\n",
    "   we create edges between all $n, ..., n+i-1$ on the one hand\n",
    "   and all $m, ..., m+j-1$ on the other hand,\n",
    "   and associate them all with the same number $j-i$.\n",
    "\n",
    "We have a closer look at the edge cases.\n",
    "\n",
    "### Lexeme change\n",
    "When a lexeme changes at a particular spot $n, m$, \n",
    "we have $i=j=1$, leading to exactly one edge $(n, m)$ with value $0$.\n",
    "\n",
    "### Slot deletion\n",
    "When a slot is deleted from the source, we have $i=1, j=0$, leading to \n",
    "\n",
    "## Reading an edge\n",
    "Now suppose we have an old version $V$ and and a new version $W$.\n",
    "We are processing slots in text in $W$ and want to access information from $V$.\n",
    "We do so by consulting the mapping feature `omapV-W`.\n",
    "\n",
    "Say we have arrived at slot $m\\in W$ and want to see what is happening at the corresponding place in $V$.\n",
    "\n",
    "So we retrieve \n",
    "\n",
    "```\n",
    "origins = Es(omapV-W).t(m)\n",
    "```\n",
    "\n",
    "Now origins contains the nodes $n$ in $V$ that map to $m$, with additional information.\n",
    "It is delivered as a dictionary of ($n$, $k$) values, where $k$ is either a number, or `None`.\n",
    "\n",
    "Let's see what we can deduce, depending on $k$:\n",
    "\n",
    "1. if we have ($n$, `None`), then the correspondence between $n$ and $m$ is precise.\n",
    "   Slot $m\\inW$ is not the result of a split or collapse in $V$, and both $n$ and $m$ carry the same lexeme.\n",
    "   There will be no other ($n'$, $k$)s that map to $m$.\n",
    "1. if we have ($n$, 0), then there is a change of lexeme between $n$ and $m$, but no split or collapse.\n",
    "   There cannot be other edges arriving at $m$ in this case. For:\n",
    "   1. If there was also another ($n'$, 0) linked to $m$,\n",
    "      then $n$ and $n'$ would have been involved in a collapse,\n",
    "      and the edge value should have been a negative number.\n",
    "   1. If there was another ($n'$, $k$) with $k$ negative linked to $m$,\n",
    "      then by the same reasoning the value on the edge between $n$ and $m$ should have been negative.\n",
    "   1. If there was another ($n'$, $k$) with $k$ positive linked to $m$,\n",
    "      then $m$ is a part of the result of splitting $n'$.\n",
    "1. if we have one or more ($n$, $k$)s\n",
    "   1. $k$ is negative\n",
    "      in a number of parts. We find those parts\n",
    "   No splits of collapses.\n",
    "1. if we have ($n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Strong numbers\n",
    "Stephen Ku has prepared a Strong number mapping for version `4`, based on \n",
    "[OpenScriptures Bible Lexicon](https://github.com/openscriptures/HebrewLexicon).\n",
    "\n",
    "This provides us with a nice use case:\n",
    "can we apply the Strong number mapping for version `4` to versions `3`, `4b` and `2016`\n",
    "as well?\n",
    "See notebook\n",
    "[strong](https://github.com/ETCBC/bhsa/blob/master/programs/strong.ipynb)\n",
    "for how we add Strong numbers to the BHSA dataset.\n",
    "\n",
    "Below we will get a pretty good view on the differences between the versions.\n",
    "We use the\n",
    "[BHSA transcription](https://shebanq.ancient-data.org/shebanq/static/docs/BHSA-transcription.pdf)\n",
    "to write down the diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,collections\n",
    "from utils import caption\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify our versions and the subtle differences between them as far as they are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseDir = '~/github/etcbc/bhsa/tf'\n",
    "\n",
    "versions = '''\n",
    "    3 \n",
    "    4 \n",
    "    4b \n",
    "    2016\n",
    "'''.strip().split()\n",
    "\n",
    "versionInfo = {\n",
    "    '': dict(\n",
    "            OCC='g_word',\n",
    "            LEX='lex',\n",
    "        ),\n",
    "    '3': dict(\n",
    "            OCC='text_plain',\n",
    "            LEX='lexeme',\n",
    "        ),\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all versions in one go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Version -> 3 <- loading ...                                                    .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.6\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "118 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.13s B lexeme               from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.18s B text_plain           from /Users/dirk/github/etcbc/bhsa/tf/3\n",
      "   |     0.00s Feature overview: 115 for nodes; 2 for edges; 1 configs; 7 computed\n",
      "  4.29s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".       4.36s Version -> 4 <- loading ...                                                    .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.6\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "104 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.15s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/4\n",
      "   |     0.12s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/4\n",
      "   |     0.00s Feature overview: 98 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  4.44s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".       8.81s Version -> 4b <- loading ...                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.6\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "103 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.15s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/4b\n",
      "   |     0.12s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/4b\n",
      "   |     0.00s Feature overview: 97 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  4.95s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".         14s Version -> 2016 <- loading ...                                                 .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.6\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "108 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.15s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/2016\n",
      "   |     0.13s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/2016\n",
      "   |     0.00s Feature overview: 102 for nodes; 5 for edges; 1 configs; 7 computed\n",
      "  5.15s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "TF = {}\n",
    "api = {}\n",
    "for v in versions:\n",
    "    for (param, value) in versionInfo.get(v, versionInfo['']).items():\n",
    "        globals()[param] = value\n",
    "    caption(4, 'Version -> {} <- loading ...'.format(v))\n",
    "    TF[v] = Fabric(locations='{}/{}'.format(baseDir, v), modules=[''])\n",
    "    api[v] = TF[v].load('{} {}'.format(OCC, LEX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to switch easily between the APIs for the versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def activate(v):\n",
    "    for (param, value) in versionInfo.get(v, versionInfo['']).items():\n",
    "        globals()[param] = value\n",
    "    api[v].makeAvailableIn(globals())\n",
    "    caption(4, 'Active version is now -> {} <-'.format(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the amount of slots in all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         28s Active version is now -> 3 <-                                                  .\n",
      "..............................................................................................\n",
      "|         28s \t 426499 slots\n",
      "..............................................................................................\n",
      ".         28s Active version is now -> 4 <-                                                  .\n",
      "..............................................................................................\n",
      "|         28s \t 426555 slots\n",
      "..............................................................................................\n",
      ".         28s Active version is now -> 4b <-                                                 .\n",
      "..............................................................................................\n",
      "|         28s \t 426568 slots\n",
      "..............................................................................................\n",
      ".         28s Active version is now -> 2016 <-                                               .\n",
      "..............................................................................................\n",
      "|         28s \t 426581 slots\n"
     ]
    }
   ],
   "source": [
    "nSlots = {}\n",
    "for v in versions:\n",
    "    activate(v)\n",
    "    nSlots[v] = F.otype.maxSlot\n",
    "    caption(0, '\\t {} slots'.format(nSlots[v]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "When we compare two versions, we inspect the lexemes found at corresponding positions in the versions.\n",
    "We start at the beginning, and when the lexemes do not match, we have a closer look.\n",
    "\n",
    "However, in order not to be disturbed by minor discrepancies in the lexemes, we mask the lexemes: we\n",
    "apply a few transformations to it, such as removing alefs and waws, and finally even turning them into\n",
    "ordered sets of letters, thereby loosing the order and multiplicity of letter.\n",
    "We also strip the disambiguation marks.\n",
    "\n",
    "We maintain a current mapping between the slots of the two versions, and we update it if we encounter\n",
    "disturbances. \n",
    "Initially, this map is the identity map.\n",
    "\n",
    "What we encounter as remaining differences boils down to the following:\n",
    "\n",
    "* a lexeme is split into two lexemes with the same total material, typically involving `H`, `MN`, or `B`\n",
    "* the lexeme is part of a special case, listed in the `cases` table (which has been found by repeatedly\n",
    "  chasing for the first remaining difference.\n",
    "* the both lexemes differ, but that's it, no map updates have to be done.\n",
    "  \n",
    "The first two types of cases can be solved by splitting a lexeme into `k` parts or combining `k` lexemes into one.\n",
    "After that the mapping has to be shifted to the right or to the left from a certain point onwards.\n",
    "\n",
    "The loop then is as follows:\n",
    "\n",
    "* find the first slot with a lexeme in the first version that is different from the lexeme at the mapped slot\n",
    "  in the second version\n",
    "* analyse what is the case:\n",
    "  * if the disturbance is recognized on the basis of existing patterns and cases, update the map and\n",
    "    consider this case solved\n",
    "  * if the disturbance is not recognized, the case is unsolved, and we break out of the loop.\n",
    "    More analysis is needed, and the outcome of that has to be coded as an extra pattern or case.\n",
    "* if the status is solved, go back to the first step\n",
    "\n",
    "We end up with a mapping from the slots of the first version to those of the other version that links\n",
    "slots with approximately equal lexemes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexeme masking\n",
    "We start by defining our masking function, and compile lists of all lexemes and masked lexemes for all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "masks = [\n",
    "    (lambda lex: lex.rstrip('[/='),                         'strip disambiguation'),\n",
    "    (lambda lex: lex[0:-2] if lex.endswith('JM') else lex,  'remove JM'),\n",
    "    (lambda lex: lex[0:-2] if lex.endswith('WT') else lex,  'remove WT'),\n",
    "    (lambda lex: lex.replace('J', ''),                      'remove J'),\n",
    "    (lambda lex: lex.replace('>', ''),                      'remove Alef'),\n",
    "    (lambda lex: lex.replace('W', ''),                      'remove W'),\n",
    "    (lambda lex: lex.replace('Z', 'N'),                     'identify Z and N'),\n",
    "    (lambda lex: lex.rstrip('HT'),                          'strip HT'),\n",
    "    (lambda lex: (''.join(sorted(set(set(lex)))))+'_'*lex.count('_'), 'ignore order and multiplicity'),\n",
    "]\n",
    "\n",
    "def mask(lex, trans=None):\n",
    "    if trans != None:\n",
    "        return masks[trans][0](lex)\n",
    "    for (fun, desc) in masks:\n",
    "        lex = fun(lex)\n",
    "    return lex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out the lexeme masking for all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         35s Masking lexemes                                                                .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".         35s Active version is now -> 3 <-                                                  .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".         38s Active version is now -> 4 <-                                                  .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".         41s Active version is now -> 4b <-                                                 .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".         44s Active version is now -> 2016 <-                                               .\n",
      "..............................................................................................\n",
      "|         47s Done\n"
     ]
    }
   ],
   "source": [
    "lexemes = {}\n",
    "\n",
    "caption(4, 'Masking lexemes')\n",
    "for v in versions:\n",
    "    activate(v)\n",
    "    lexemes[v] = collections.OrderedDict()\n",
    "    for n in F.otype.s('word'):\n",
    "        lex = Fs(LEX).v(n)\n",
    "        lexemes[v][n] = (lex, mask(lex, trans=0), mask(lex))\n",
    "caption(0, 'Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cases and mappings\n",
    "In `cases` we store special cases that we stumbled upon.\n",
    "Every time we encountered a disturbance which did not follow a recognized pattern,\n",
    "we turned it into a case.\n",
    "The number is the slot number in the first version where the case will be applied.\n",
    "Cases will only be applied at these exact slot number and nowhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases = {}\n",
    "mappings = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "Here is the code that directly implements the method.\n",
    "Every pair of distinct versions can be mapped.\n",
    "We store the mappings in a dictionary, keyed by tuples like `(4, 4b)`, \n",
    "for the mapping from version `4` to `4b`, for instance.\n",
    "\n",
    "The loop is in `doDiffs` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inspect(v1, v2, start, end):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "    for n in range(start, end):\n",
    "        print('{:>6}: {:<8} {:<8}'.format(\n",
    "            n, \n",
    "            api[v1].Fs(LEX).v(n),\n",
    "            api[v2].Fs(LEX).v(mp[n]),\n",
    "\n",
    "        ))\n",
    "\n",
    "def firstDiff(v1, v2, start):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "\n",
    "    fDiff = None\n",
    "    for (n, (lx1, sxl, mx1)) in lexemes[v1].items():\n",
    "        if n < start: continue\n",
    "        if mx1 != lexemes[v2][mp[n]][2]:\n",
    "            fDiff = n\n",
    "            break\n",
    "    return fDiff\n",
    "\n",
    "def printDiff(v1, v2, n):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "\n",
    "    (lx1, sx1, mx1) = lexemes[v1][n]\n",
    "    (lx2, sx2, mx2) = lexemes[v2][mp[n]]\n",
    "    if n < api[v1].F.otype.maxSlot:\n",
    "        (lx1n, sx1n, mx1n) = lexemes[v1][n+1]\n",
    "    else:\n",
    "        (lx1n, sx1n, mx1n) = ('max', 'max', 'max')\n",
    "    if mp[n] < api[v2].F.otype.maxSlot:\n",
    "        (lx2n, sx2n, mx2n) = lexemes[v2][mp[n+1]]\n",
    "    else:\n",
    "        (lx2n, sx2n, mx2n) = ('max', 'max', 'max')\n",
    "    if n > 1:\n",
    "        (lx1p, sx1p, mx1p) = lexemes[v1][n-1]\n",
    "    else:\n",
    "        (lx1p, sx1p, mx1p) = ('min', 'min', 'min')\n",
    "    if mp[n] > 1:\n",
    "        (lx2p, sx2p, mx2p) = lexemes[v2][mp[n-1]]\n",
    "    else:\n",
    "        (lx2p, sx2p, mx2p) = ('min', 'min', 'min')\n",
    "\n",
    "    #print('''{} {}:{} ==> slot {} ==> {}\n",
    "    #{:<2}: {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| {:<6}\n",
    "    #{:<2}: {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| {:<6}'''.format(\n",
    "    #    *api[v1].T.sectionFromNode(n),\n",
    "    #    n, mp[n],\n",
    "    #    v1, lx1p, lx1, lx1n, sx1p, sx1, sx1n, mx1p, mx1, mx1n,\n",
    "    #    v2, lx2p, lx2, lx2n, sx2p, sx2, sx2n, mx2p, mx2, mx2n,\n",
    "    #)) \n",
    "    print('''{} {}:{} ==> slot {} ==> {}\n",
    "    {:>4}: ┣{:<6}┫ ▷{:>10}◁▶{:>10}◀▷{:<8}◁\n",
    "    {:>4}: ┣{:<6}┫ ▷{:>10}◁▶{:>10}◀▷{:<8}◁'''.format(\n",
    "        *api[v1].T.sectionFromNode(n),\n",
    "        n, mp[n],\n",
    "        v1, mx1, lx1p, lx1, lx1n, \n",
    "        v2, mx2, lx2p, lx2, lx2n,\n",
    "    )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doDiffs\n",
    "\n",
    "This function contains the loop to walk through all differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 250\n",
    "\n",
    "def doDiffs(v1, v2):\n",
    "    mapKey = (v1, v2)\n",
    "    mappings[mapKey] = dict(((n, n) for n in api[v1].F.otype.s('word')))\n",
    "    mp = mappings[mapKey]\n",
    "    theseCases = cases.get(mapKey, {})\n",
    "    it = 0\n",
    "    start = 1\n",
    "    while True:\n",
    "        n = firstDiff(v1, v2, start)\n",
    "\n",
    "        if n == None:\n",
    "            print('No more differences.\\nFound {} points of disturbance'.format(it))\n",
    "            break\n",
    "\n",
    "        if it > MAX_ITER: \n",
    "            print('There might be more disturbances: increase MAX_ITER')\n",
    "            break\n",
    "            \n",
    "        it += 1\n",
    "\n",
    "        printDiff(v1, v2, n)\n",
    "\n",
    "        (lx1, sx1, mx1) = lexemes[v1][n]\n",
    "        (lx2, sx2, mx2) = lexemes[v2][mp[n]]\n",
    "        (lx1n, sx1n, mx1n) = lexemes[v1][n+1]\n",
    "        (lx2n, sx2n, mx2n) = lexemes[v2][mp[n+1]]\n",
    "\n",
    "        solved = None\n",
    "        skip = 0\n",
    "        if n in theseCases:\n",
    "            (action, param) = theseCases[n]\n",
    "            if action == 'collapse':\n",
    "                solved = '{} {} slots'.format(action, param)\n",
    "                skip = param\n",
    "                for m in range(api[v1].F.otype.maxSlot, n + param -1, -1):\n",
    "                    mp[m] = mp[m-param+1]\n",
    "                for m in range(n+1, n+param):\n",
    "                    mp[m] = mp[n]\n",
    "            elif action == 'split':\n",
    "                solved = '{} into {} slots'.format(action, param)\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + param -1\n",
    "            elif action == 'ok':\n",
    "                solved = 'incidental variation in lexeme'\n",
    "#        elif lx1.replace('C', 'X') == lx2:\n",
    "#            solved = 'letter C replaced by X'\n",
    "        elif lx1 in theseCases:\n",
    "            (action, param) = theseCases[lx1]\n",
    "            if action == 'ok':            \n",
    "                if lx2 == param:\n",
    "                    solved = 'systematic variation in lexeme' \n",
    "            elif action == 'split':\n",
    "                solved = 'systematic {} on _ into {} slots'.format(action, param)\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + param -1\n",
    "        elif '_' in lx1:\n",
    "            action = 'split'\n",
    "            param = lx1.count('_') + 1\n",
    "            solved = '{} on _ into {} slots'.format(action, param)\n",
    "            for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                mp[m] = mp[m] + param -1\n",
    "        elif lx1 == lx2 + lx2n:\n",
    "            if lx2 == 'H':\n",
    "                solved = 'split article off'\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + 1\n",
    "        elif set(mx1) == set(mx2) | set(mx2n):\n",
    "            if lx2 == 'B' or lx2 == 'MN':\n",
    "                solved = 'split preposition off'\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + 1\n",
    "        print('Action: {}\\n'.format(solved if solved else 'BLOCKED'))\n",
    "\n",
    "        if not solved: break\n",
    "        \n",
    "        start = n + 1 + skip\n",
    "\n",
    "    if not solved:\n",
    "        print('Blocking difference in {} iterations'.format(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mappings itself are needed elsewhere in Text-Fabric, let us write them to file.\n",
    "We write them into the dataset corresponding to the target version.\n",
    "So the map `3-4` ends up in version `4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeMaps():\n",
    "    for ((v1, v2), mp) in mappings.items():\n",
    "        fName = 'omap@{}-{}'.format(v1, v2)\n",
    "        caption(4, 'Write slot mapping {}'.format(fName))\n",
    "\n",
    "        edgeFeatures = {\n",
    "            fName: dict(((n, (mp[n],)) for n in range(1, api[v1].F.otype.maxSlot + 1)))\n",
    "        }\n",
    "        metaData = {\n",
    "            fName: {\n",
    "                'about': 'Mapping from the slots of BHSA version {} to version {}'.format(v1, v2),\n",
    "                'encoder': 'Dirk Roorda by a semi-automatic method',\n",
    "                'see': 'https://github.com/ETCBC/bhsa/blob/master/programs/evolutionVersions.ipynb',\n",
    "                'valueType': 'str',\n",
    "            }\n",
    "        }\n",
    "        TF[v2].save(\n",
    "            nodeFeatures={},\n",
    "            edgeFeatures=edgeFeatures,\n",
    "            metaData=metaData,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running\n",
    "\n",
    "Here we run the mapping between `3` and `4`.\n",
    "\n",
    "## 3 => 4\n",
    "\n",
    "Here are the special cases for this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases[('3', '4')] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('3', '4'): {\n",
    "#        7840: ('ok', None),\n",
    "        'CXH[' : ('ok', 'XWH['),\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('3', '4'): {\n",
    "        'CXH[' : ('ok', 'XWH['),\n",
    "        'MQYT/': ('split', 2),\n",
    "        28730  : ('ok', None),\n",
    "        121812 : ('ok', None),\n",
    "        174515 : ('ok', None),\n",
    "        201089 : ('ok', None),\n",
    "        218383 : ('split', 3),\n",
    "        221436 : ('ok', None),\n",
    "        247730 : ('ok', None),\n",
    "        272884 : ('collapse', 2),\n",
    "        353611 : ('ok', None),\n",
    "#        370037 : ('split', 2),\n",
    "#        370138 : ('split', 2),\n",
    "#        370329 : ('split', 2),\n",
    "    },\n",
    "})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 18:2 ==> slot 7840 ==> 7840\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷>RY/    ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷>RY/    ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 19:1 ==> slot 8447 ==> 8447\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷>P/     ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷>P/     ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 21:14 ==> slot 9856 ==> 9856\n",
      "       3: ┣<BCR__┫ ▷     MDBR/◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷     MDBR/◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 21:31 ==> slot 10174 ==> 10175\n",
      "       3: ┣<BCR__┫ ▷       HW>◁▶  B>R_CB</◀▷KJ      ◁\n",
      "       4: ┣BR    ┫ ▷       HW>◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 21:32 ==> slot 10183 ==> 10185\n",
      "       3: ┣<BCR__┫ ▷         B◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷         B◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 21:33 ==> slot 10200 ==> 10203\n",
      "       3: ┣<BCR__┫ ▷         B◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷         B◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 22:5 ==> slot 10341 ==> 10345\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷W       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷W       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 22:19 ==> slot 10641 ==> 10645\n",
      "       3: ┣<BCR__┫ ▷        >L◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷        >L◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 22:19 ==> slot 10646 ==> 10651\n",
      "       3: ┣<BCR__┫ ▷         B◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷         B◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 23:7 ==> slot 10830 ==> 10836\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 23:12 ==> slot 10933 ==> 10939\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷>BRHM/  ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷>BRHM/  ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 24:26 ==> slot 11604 ==> 11610\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 24:48 ==> slot 12051 ==> 12057\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 24:52 ==> slot 12144 ==> 12150\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷>RY/    ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷>RY/    ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 25:20 ==> slot 12724 ==> 12730\n",
      "       3: ┣DMNPR__┫ ▷        MN◁▶  PDN_>RM/◀▷>XWT/   ◁\n",
      "       4: ┣DNP   ┫ ▷        MN◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 26:23 ==> slot 13405 ==> 13412\n",
      "       3: ┣<BCR__┫ ▷        CM◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷        CM◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 26:33 ==> slot 13588 ==> 13596\n",
      "       3: ┣<BCR__┫ ▷      <JR/◁▶  B>R_CB</◀▷<D      ◁\n",
      "       4: ┣BR    ┫ ▷      <JR/◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 27:29 ==> slot 14101 ==> 14110\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 27:29 ==> slot 14109 ==> 14118\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 28:2 ==> slot 14510 ==> 14519\n",
      "       3: ┣DMNPR__┫ ▷      HLK[◁▶  PDN_>RM/◀▷BJT/    ◁\n",
      "       4: ┣DNP   ┫ ▷      HLK[◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 28:5 ==> slot 14568 ==> 14578\n",
      "       3: ┣DMNPR__┫ ▷      HLK[◁▶  PDN_>RM/◀▷>L      ◁\n",
      "       4: ┣DNP   ┫ ▷      HLK[◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 28:6 ==> slot 14592 ==> 14603\n",
      "       3: ┣DMNPR__┫ ▷        >T◁▶  PDN_>RM/◀▷L       ◁\n",
      "       4: ┣DNP   ┫ ▷        >T◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 28:7 ==> slot 14623 ==> 14635\n",
      "       3: ┣DMNPR__┫ ▷      HLK[◁▶  PDN_>RM/◀▷W       ◁\n",
      "       4: ┣DNP   ┫ ▷      HLK[◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 28:10 ==> slot 14659 ==> 14672\n",
      "       3: ┣<BCR__┫ ▷        MN◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷        MN◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 31:18 ==> slot 16687 ==> 16701\n",
      "       3: ┣DMNPR__┫ ▷         B◁▶  PDN_>RM/◀▷L       ◁\n",
      "       4: ┣DNP   ┫ ▷         B◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 33:3 ==> slot 18117 ==> 18132\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷>RY/    ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷>RY/    ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 33:6 ==> slot 18175 ==> 18190\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷W       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷W       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 33:7 ==> slot 18183 ==> 18198\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷W       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷W       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 33:7 ==> slot 18191 ==> 18206\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷W       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷W       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 33:18 ==> slot 18397 ==> 18412\n",
      "       3: ┣DMNPR__┫ ▷        MN◁▶  PDN_>RM/◀▷W       ◁\n",
      "       4: ┣DNP   ┫ ▷        MN◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 35:9 ==> slot 19216 ==> 19232\n",
      "       3: ┣DMNPR__┫ ▷        MN◁▶  PDN_>RM/◀▷W       ◁\n",
      "       4: ┣DNP   ┫ ▷        MN◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 35:26 ==> slot 19485 ==> 19502\n",
      "       3: ┣DMNPR__┫ ▷         B◁▶  PDN_>RM/◀▷W       ◁\n",
      "       4: ┣DNP   ┫ ▷         B◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 37:7 ==> slot 20271 ==> 20289\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 37:9 ==> slot 20323 ==> 20341\n",
      "       3: ┣CX    ┫ ▷     KWKB/◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷     KWKB/◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 37:10 ==> slot 20355 ==> 20373\n",
      "       3: ┣CX    ┫ ▷         L◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         L◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 42:6 ==> slot 23509 ==> 23527\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 43:26 ==> slot 24650 ==> 24668\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 43:28 ==> slot 24682 ==> 24700\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷W       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷W       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 46:1 ==> slot 25981 ==> 25999\n",
      "       3: ┣<BCR__┫ ▷      BW>[◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷      BW>[◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 46:5 ==> slot 26042 ==> 26061\n",
      "       3: ┣<BCR__┫ ▷        MN◁▶  B>R_CB</◀▷W       ◁\n",
      "       4: ┣BR    ┫ ▷        MN◁▶      B>R/◀▷CB<==/  ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 46:15 ==> slot 26201 ==> 26221\n",
      "       3: ┣DMNPR__┫ ▷         B◁▶  PDN_>RM/◀▷W       ◁\n",
      "       4: ┣DNP   ┫ ▷         B◁▶      PDN/◀▷>RM/    ◁\n",
      "Action: split on _ into 2 slots\n",
      "\n",
      "Genesis 47:31 ==> slot 27267 ==> 27288\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷JFR>L/  ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷JFR>L/  ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 48:12 ==> slot 27501 ==> 27522\n",
      "       3: ┣CX    ┫ ▷         W◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷         W◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 49:8 ==> slot 27858 ==> 27879\n",
      "       3: ┣CX    ┫ ▷      >JB[◁▶      CXH[◀▷L       ◁\n",
      "       4: ┣X     ┫ ▷      >JB[◁▶      XWH[◀▷L       ◁\n",
      "Action: systematic variation in lexeme\n",
      "\n",
      "Genesis 50:26 ==> slot 28730 ==> 28751\n",
      "       3: ┣F     ┫ ▷         W◁▶      FJM[◀▷B       ◁\n",
      "       4: ┣FM    ┫ ▷         W◁▶      JFM[◀▷B       ◁\n",
      "Action: BLOCKED\n",
      "\n",
      "Blocking difference in 45 iterations\n"
     ]
    }
   ],
   "source": [
    "doDiffs('3', '4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running\n",
    "\n",
    "Here we run the mapping between `4` and `4b`.\n",
    "The points of disturbance will be written into the output cell.\n",
    "\n",
    "## 4 => 4b\n",
    "\n",
    "Here are the special cases for this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('4', '4b'): {\n",
    "        214730: ('collapse', 4),\n",
    "        260028: ('split', 2),\n",
    "        289948: ('ok', None),\n",
    "        307578: ('split', 2),\n",
    "        323067: ('ok', None),\n",
    "        389774: ('ok', None),\n",
    "        407543: ('split', 2),\n",
    "        408429: ('split', 2),\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 24:65 ==> slot 12369 ==> 12369\n",
      "       4: ┣HLN   ┫ ▷      >JC/◁▶      HLZH◀▷H       ◁\n",
      "      4b: ┣      ┫ ▷      >JC/◁▶         H◀▷LZH     ◁\n",
      "Action: split article off\n",
      "\n",
      "Genesis 37:19 ==> slot 20514 ==> 20515\n",
      "       4: ┣HLN   ┫ ▷     XLWM/◁▶      HLZH◀▷BW>[    ◁\n",
      "      4b: ┣      ┫ ▷     XLWM/◁▶         H◀▷LZH     ◁\n",
      "Action: split article off\n",
      "\n",
      "Judges 6:20 ==> slot 130846 ==> 130848\n",
      "       4: ┣HLN   ┫ ▷      SL</◁▶       HLZ◀▷W       ◁\n",
      "      4b: ┣      ┫ ▷      SL</◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 14:1 ==> slot 148319 ==> 148322\n",
      "       4: ┣HLN   ┫ ▷      <BR/◁▶       HLZ◀▷W       ◁\n",
      "      4b: ┣      ┫ ▷      <BR/◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 17:26 ==> slot 151331 ==> 151335\n",
      "       4: ┣HLN   ┫ ▷    PLCTJ/◁▶       HLZ◀▷W       ◁\n",
      "      4b: ┣      ┫ ▷    PLCTJ/◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 20:19 ==> slot 153816 ==> 153821\n",
      "       4: ┣HLN   ┫ ▷      >BN/◁▶     H>ZL/◀▷W       ◁\n",
      "      4b: ┣      ┫ ▷      >BN/◁▶         H◀▷>ZL/    ◁\n",
      "Action: split article off\n",
      "\n",
      "2_Kings 4:25 ==> slot 196975 ==> 196981\n",
      "       4: ┣HLN   ┫ ▷    CWNMJ/◁▶       HLZ◀▷<TH     ◁\n",
      "      4b: ┣      ┫ ▷    CWNMJ/◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "2_Kings 23:17 ==> slot 210326 ==> 210333\n",
      "       4: ┣HLN   ┫ ▷    YJWN=/◁▶       HLZ◀▷>CR     ◁\n",
      "      4b: ┣      ┫ ▷    YJWN=/◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "Isaiah 8:1 ==> slot 214730 ==> 214738\n",
      "       4: ┣HMR   ┫ ▷         L◁▶      MHR[◀▷CLL/    ◁\n",
      "      4b: ┣BCHLMNRX____┫ ▷         L◁▶MHR_CLL_XC_BZ/◀▷W       ◁\n",
      "Action: collapse 4 slots\n",
      "\n",
      "Jeremiah 46:20 ==> slot 260028 ==> 260033\n",
      "       4: ┣HP    ┫ ▷     <GLH/◁▶    JPHPJ/◀▷MYRJM/  ◁\n",
      "      4b: ┣P     ┫ ▷     <GLH/◁▶      JPH/◀▷PJH/    ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Ezekiel 16:7 ==> slot 271124 ==> 271130\n",
      "       4: ┣<BD   ┫ ▷      BW>[◁▶      B<D/◀▷<DJ/    ◁\n",
      "      4b: ┣B     ┫ ▷      BW>[◁▶         B◀▷<DJ/    ◁\n",
      "Action: split preposition off\n",
      "\n",
      "Ezekiel 36:35 ==> slot 283104 ==> 283111\n",
      "       4: ┣HLN   ┫ ▷      >RY/◁▶      HLZW◀▷H       ◁\n",
      "      4b: ┣      ┫ ▷      >RY/◁▶         H◀▷LZW     ◁\n",
      "Action: split article off\n",
      "\n",
      "Ezekiel 47:13 ==> slot 289948 ==> 289956\n",
      "       4: ┣N     ┫ ▷     JHWH/◁▶        ZH◀▷GBWL/   ◁\n",
      "      4b: ┣G     ┫ ▷     JHWH/◁▶       G>/◀▷GBWL/   ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "Zechariah 2:8 ==> slot 305480 ==> 305488\n",
      "       4: ┣HLN   ┫ ▷      N<R/◁▶       HLZ◀▷L       ◁\n",
      "      4b: ┣      ┫ ▷      N<R/◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "Zechariah 9:8 ==> slot 307578 ==> 307587\n",
      "       4: ┣BMY   ┫ ▷      BJT/◁▶    MYBH=/◀▷MN      ◁\n",
      "      4b: ┣MN    ┫ ▷      BJT/◁▶        MN◀▷YB>/    ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Psalms 75:7 ==> slot 323067 ==> 323077\n",
      "       4: ┣MR    ┫ ▷     MDBR/◁▶      RWM[◀▷KJ      ◁\n",
      "      4b: ┣HR    ┫ ▷     MDBR/◁▶       HR/◀▷KJ      ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "Daniel 8:16 ==> slot 375529 ==> 375539\n",
      "       4: ┣HLN   ┫ ▷         L◁▶       HLZ◀▷>T      ◁\n",
      "      4b: ┣      ┫ ▷         L◁▶         H◀▷LZ      ◁\n",
      "Action: split article off\n",
      "\n",
      "Nehemiah 12:4 ==> slot 389774 ==> 389785\n",
      "       4: ┣GNT   ┫ ▷      <D>/◁▶    GNTWN/◀▷>BJH/   ◁\n",
      "      4b: ┣GN    ┫ ▷      <D>/◁▶    GNTWJ/◀▷>BJH/   ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "2_Chronicles 2:12 ==> slot 407543 ==> 407554\n",
      "       4: ┣BMRX__┫ ▷         L◁▶ XWRM_>BJ/◀▷BN/     ◁\n",
      "      4b: ┣MRX   ┫ ▷         L◁▶     XWRM/◀▷>B/     ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "2_Chronicles 4:16 ==> slot 408429 ==> 408441\n",
      "       4: ┣BMRX__┫ ▷      <FH[◁▶ XWRM_>BJ/◀▷L       ◁\n",
      "      4b: ┣MRX   ┫ ▷      <FH[◁▶     XWRM/◀▷>B/     ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "No more differences.\n",
      "Found 20 points of disturbance\n"
     ]
    }
   ],
   "source": [
    "doDiffs('4', '4b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just have a look at the first point of disturbance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 24:65 node 12370: H versus LZH becomes H\n"
     ]
    }
   ],
   "source": [
    "(v1, v2) = ('4', '4b')\n",
    "(n, m) = [x for x in mappings[(v1, v2)].items() if x[0] != x[1]][0]\n",
    "print('{} {}:{} node {}: {} versus {} becomes {}'.format(\n",
    "    *api[v1].T.sectionFromNode(n),\n",
    "    n,\n",
    "    api[v1].F.lex.v(n),\n",
    "    api[v2].F.lex.v(n),\n",
    "    api[v2].F.lex.v(m),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b => 2016\n",
    "\n",
    "We need other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('4b', '2016'): {\n",
    "         28423: ('split', 3),\n",
    "         28455: ('split', 3),\n",
    "         91193: ('split', 2),\n",
    "         91197: ('split', 2),\n",
    "        122218: ('split', 2),\n",
    "        122247: ('split', 2),\n",
    "        123160: ('split', 2),\n",
    "        184086: ('split', 2),\n",
    "        394186: ('collapse', 2),\n",
    "        395150: ('ok', None),\n",
    "        395190: ('ok', None),\n",
    "        401036: ('split', 3),\n",
    "        404503: ('ok', None),\n",
    "        419138: ('split', 3),\n",
    "    },    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 50:10 ==> slot 28423 ==> 28423\n",
      "      4b: ┣DGNRV__┫ ▷        <D◁▶  GRN_>VD/◀▷>CR     ◁\n",
      "    2016: ┣GNR   ┫ ▷        <D◁▶      GRN/◀▷H       ◁\n",
      "Action: split into 3 slots\n",
      "\n",
      "Genesis 50:11 ==> slot 28455 ==> 28457\n",
      "      4b: ┣DGNRV__┫ ▷         B◁▶  GRN_>VD/◀▷W       ◁\n",
      "    2016: ┣GNR   ┫ ▷         B◁▶      GRN/◀▷H       ◁\n",
      "Action: split into 3 slots\n",
      "\n",
      "Numbers 33:45 ==> slot 91193 ==> 91197\n",
      "      4b: ┣BDGN__┫ ▷         B◁▶ DJBWN_GD/◀▷W       ◁\n",
      "    2016: ┣BDN   ┫ ▷         B◁▶     DJBN/◀▷GD==/   ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Numbers 33:46 ==> slot 91197 ==> 91202\n",
      "      4b: ┣BDGN__┫ ▷        MN◁▶ DJBWN_GD/◀▷W       ◁\n",
      "    2016: ┣BDN   ┫ ▷        MN◁▶     DJBN/◀▷GD==/   ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 16:3 ==> slot 122218 ==> 122224\n",
      "      4b: ┣BNRTX___┫ ▷     GBWL/◁▶BJT_XRWN_TXTWN/◀▷W       ◁\n",
      "    2016: ┣BNRTX__┫ ▷     GBWL/◁▶BJT_XWRWN/◀▷TXTWN/  ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 16:5 ==> slot 122247 ==> 122254\n",
      "      4b: ┣<BLNRTX___┫ ▷        <D◁▶BJT_XRWN_<LJWN/◀▷W       ◁\n",
      "    2016: ┣BNRTX__┫ ▷        <D◁▶BJT_XWRWN/◀▷<LJWN/  ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 18:13 ==> slot 123160 ==> 123168\n",
      "      4b: ┣BNRTX___┫ ▷         L◁▶BJT_XRWN_TXTWN/◀▷W       ◁\n",
      "    2016: ┣BNRTX__┫ ▷         L◁▶BJT_XWRWN/◀▷TXTWN/  ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "1_Kings 9:17 ==> slot 184086 ==> 184095\n",
      "      4b: ┣BNRTX___┫ ▷        >T◁▶BJT_XRWN_TXTWN/◀▷W       ◁\n",
      "    2016: ┣BNRTX__┫ ▷        >T◁▶BJT_XWRWN/◀▷TXTWN/  ◁\n",
      "Action: split into 2 slots\n",
      "\n",
      "1_Chronicles 6:13 ==> slot 394186 ==> 394196\n",
      "      4b: ┣      ┫ ▷      BKR/◁▶         W◀▷CNJ/    ◁\n",
      "    2016: ┣CN    ┫ ▷      BKR/◁▶     WCNJ/◀▷W       ◁\n",
      "Action: collapse 2 slots\n",
      "\n",
      "1_Chronicles 7:12 ==> slot 395150 ==> 395159\n",
      "      4b: ┣CMP   ┫ ▷         W◁▶    CPM==/◀▷W       ◁\n",
      "    2016: ┣CP    ┫ ▷         W◁▶     CPJM/◀▷W       ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "1_Chronicles 7:15 ==> slot 395190 ==> 395199\n",
      "      4b: ┣CMP   ┫ ▷         L◁▶    CPM==/◀▷W       ◁\n",
      "    2016: ┣CP    ┫ ▷         L◁▶     CPJM/◀▷W       ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "1_Chronicles 18:12 ==> slot 401036 ==> 401045\n",
      "      4b: ┣GLMX__┫ ▷         B◁▶  GJ>_MLX/◀▷CMNH/   ◁\n",
      "    2016: ┣G     ┫ ▷         B◁▶      GJ>/◀▷H       ◁\n",
      "Action: split into 3 slots\n",
      "\n",
      "1_Chronicles 26:16 ==> slot 404503 ==> 404514\n",
      "      4b: ┣CMP   ┫ ▷         L◁▶    CPM==/◀▷W       ◁\n",
      "    2016: ┣CP    ┫ ▷         L◁▶     CPJM/◀▷W       ◁\n",
      "Action: incidental variation in lexeme\n",
      "\n",
      "2_Chronicles 25:11 ==> slot 419138 ==> 419149\n",
      "      4b: ┣GLMX__┫ ▷      HLK[◁▶  GJ>_MLX/◀▷W       ◁\n",
      "    2016: ┣G     ┫ ▷      HLK[◁▶      GJ>/◀▷H       ◁\n",
      "Action: split into 3 slots\n",
      "\n",
      "No more differences.\n",
      "Found 14 points of disturbance\n"
     ]
    }
   ],
   "source": [
    "doDiffs('4b', '2016')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bit below is very handy if you need a closer look to what is the case in some range of slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419135: <M/      <M/     \n",
      "419136: W        W       \n",
      "419137: HLK[     HLK[    \n",
      "419138: GJ>_MLX/ GJ>/    \n",
      "419139: W        W       \n",
      "419140: NKH[     NKH[    \n",
      "419141: >T       >T      \n",
      "419142: BN/      BN/     \n",
      "419143: F<JR====/ F<JR====/\n",
      "419144: <FRH=/   <FRH=/  \n"
     ]
    }
   ],
   "source": [
    "inspect('4b', '2016', 419135, 419145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just have a look at the first point of disturbance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 50:10 node 28424: >CR versus H becomes >CR\n"
     ]
    }
   ],
   "source": [
    "(v1, v2) = ('4b', '2016')\n",
    "(n, m) = [x for x in mappings[(v1, v2)].items() if x[0] != x[1]][0]\n",
    "print('{} {}:{} node {}: {} versus {} becomes {}'.format(\n",
    "    *api[v1].T.sectionFromNode(n),\n",
    "    n,\n",
    "    api[v1].F.lex.v(n),\n",
    "    api[v2].F.lex.v(n),\n",
    "    api[v2].F.lex.v(m),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      7m 19s Constructed mappings:                                                          .\n",
      "..............................................................................................\n",
      "|      7m 19s \t    3 ==> 4   \n",
      "|      7m 19s \t    4 ==> 4b  \n",
      "|      7m 19s \t   4b ==> 2016\n",
      "..............................................................................................\n",
      ".      7m 19s Write slot mapping omap@3-4                                                    .\n",
      "..............................................................................................\n",
      "  0.00s Exporting 0 node and 1 edge and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/4:\n",
      "   |     1.26s T omap@3-4             to /Users/dirk/github/etcbc/bhsa/tf/4\n",
      "  1.26s Exported 0 node features and 1 edge features and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/4\n",
      "..............................................................................................\n",
      ".      7m 20s Write slot mapping omap@4-4b                                                   .\n",
      "..............................................................................................\n",
      "  0.00s Exporting 0 node and 1 edge and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/4b:\n",
      "   |     1.53s T omap@4-4b            to /Users/dirk/github/etcbc/bhsa/tf/4b\n",
      "  1.53s Exported 0 node features and 1 edge features and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/4b\n",
      "..............................................................................................\n",
      ".      7m 22s Write slot mapping omap@4b-2016                                                .\n",
      "..............................................................................................\n",
      "  0.00s Exporting 0 node and 1 edge and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/2016:\n",
      "   |     1.29s T omap@4b-2016         to /Users/dirk/github/etcbc/bhsa/tf/2016\n",
      "  1.30s Exported 0 node features and 1 edge features and 0 config features to /Users/dirk/github/etcbc/bhsa/tf/2016\n"
     ]
    }
   ],
   "source": [
    "caption(4, 'Constructed mappings:')\n",
    "for (v1, v2) in sorted(mappings.keys()):\n",
    "    caption(0, '\\t {:>4} ==> {:<4}'.format(v1, v2))\n",
    "\n",
    "writeMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
